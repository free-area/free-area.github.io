const nt="ENTRIES",V="KEYS",T="VALUES",F="";class D{set;_type;_path;constructor(t,s){const n=t._tree,u=Array.from(n.keys());this.set=t,this._type=s,this._path=u.length>0?[{node:n,keys:u}]:[]}next(){const t=this.dive();return this.backtrack(),t}dive(){if(this._path.length===0)return{done:!0,value:void 0};const{node:t,keys:s}=E(this._path);if(E(s)===F)return{done:!1,value:this.result()};const n=t.get(E(s));return this._path.push({node:n,keys:Array.from(n.keys())}),this.dive()}backtrack(){if(this._path.length===0)return;const t=E(this._path).keys;t.pop(),!(t.length>0)&&(this._path.pop(),this.backtrack())}key(){return this.set._prefix+this._path.map(({keys:t})=>E(t)).filter(t=>t!==F).join("")}value(){return E(this._path).node.get(F)}result(){switch(this._type){case T:return this.value();case V:return this.key();default:return[this.key(),this.value()]}}[Symbol.iterator](){return this}}const E=e=>e[e.length-1],ut=(e,t,s)=>{const n=new Map;if(t===void 0)return n;const u=t.length+1,o=u+s,i=new Uint8Array(o*u).fill(s+1);for(let r=0;r<u;++r)i[r]=r;for(let r=1;r<o;++r)i[r*u]=r;return R(e,t,s,n,i,1,u,""),n},R=(e,t,s,n,u,o,i,r)=>{const d=o*i;t:for(const l of e.keys())if(l===F){const a=u[d-1];a<=s&&n.set(r,[e.get(l),a])}else{let a=o;for(let h=0;h<l.length;++h,++a){const m=l[h],p=i*a,f=p-i;let c=u[p];const g=Math.max(0,a-s-1),_=Math.min(i-1,a+s);for(let y=g;y<_;++y){const b=m!==t[y],z=u[f+y]+ +b,A=u[f+y+1]+1,w=u[p+y]+1,L=u[p+y+1]=Math.min(z,A,w);L<c&&(c=L)}if(c>s)continue t}R(e.get(l),t,s,n,u,a,i,r+l)}};class C{_tree;_prefix;_size=void 0;constructor(t=new Map,s=""){this._tree=t,this._prefix=s}atPrefix(t){if(!t.startsWith(this._prefix))throw new Error("Mismatched prefix");const[s,n]=x(this._tree,t.slice(this._prefix.length));if(s===void 0){const[u,o]=M(n);for(const i of u.keys())if(i!==F&&i.startsWith(o)){const r=new Map;return r.set(i.slice(o.length),u.get(i)),new C(r,t)}}return new C(s,t)}clear(){this._size=void 0,this._tree.clear()}delete(t){return this._size=void 0,ot(this._tree,t)}entries(){return new D(this,nt)}forEach(t){for(const[s,n]of this)t(s,n,this)}fuzzyGet(t,s){return ut(this._tree,t,s)}get(t){const s=I(this._tree,t);return s!==void 0?s.get(F):void 0}has(t){const s=I(this._tree,t);return s!==void 0&&s.has(F)}keys(){return new D(this,V)}set(t,s){if(typeof t!="string")throw new Error("key must be a string");return this._size=void 0,O(this._tree,t).set(F,s),this}get size(){if(this._size)return this._size;this._size=0;const t=this.entries();for(;!t.next().done;)this._size+=1;return this._size}update(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);return n.set(F,s(n.get(F))),this}fetch(t,s){if(typeof t!="string")throw new Error("key must be a string");this._size=void 0;const n=O(this._tree,t);let u=n.get(F);return u===void 0&&n.set(F,u=s()),u}values(){return new D(this,T)}[Symbol.iterator](){return this.entries()}static from(t){const s=new C;for(const[n,u]of t)s.set(n,u);return s}static fromObject(t){return C.from(Object.entries(t))}}const x=(e,t,s=[])=>{if(t.length===0||e==null)return[e,s];for(const n of e.keys())if(n!==F&&t.startsWith(n))return s.push([e,n]),x(e.get(n),t.slice(n.length),s);return s.push([e,t]),x(void 0,"",s)},I=(e,t)=>{if(t.length===0||e==null)return e;for(const s of e.keys())if(s!==F&&t.startsWith(s))return I(e.get(s),t.slice(s.length))},O=(e,t)=>{const s=t.length;t:for(let n=0;e&&n<s;){for(const o of e.keys())if(o!==F&&t[n]===o[0]){const i=Math.min(s-n,o.length);let r=1;for(;r<i&&t[n+r]===o[r];)++r;const d=e.get(o);if(r===o.length)e=d;else{const l=new Map;l.set(o.slice(r),d),e.set(t.slice(n,n+r),l),e.delete(o),e=l}n+=r;continue t}const u=new Map;return e.set(t.slice(n),u),u}return e},ot=(e,t)=>{const[s,n]=x(e,t);if(s!==void 0){if(s.delete(F),s.size===0)W(n);else if(s.size===1){const[u,o]=s.entries().next().value;q(n,u,o)}}},W=e=>{if(e.length===0)return;const[t,s]=M(e);if(t.delete(s),t.size===0)W(e.slice(0,-1));else if(t.size===1){const[n,u]=t.entries().next().value;n!==F&&q(e.slice(0,-1),n,u)}},q=(e,t,s)=>{if(e.length===0)return;const[n,u]=M(e);n.set(u+t,s),n.delete(u)},M=e=>e[e.length-1],it=(e,t)=>{const s=e._idToShortId.get(t);if(s!=null)return e._storedFields.get(s)},rt=/[\n\r -#%-*,-/:;?@[-\]_{}\u00A0\u00A1\u00A7\u00AB\u00B6\u00B7\u00BB\u00BF\u037E\u0387\u055A-\u055F\u0589\u058A\u05BE\u05C0\u05C3\u05C6\u05F3\u05F4\u0609\u060A\u060C\u060D\u061B\u061E\u061F\u066A-\u066D\u06D4\u0700-\u070D\u07F7-\u07F9\u0830-\u083E\u085E\u0964\u0965\u0970\u09FD\u0A76\u0AF0\u0C77\u0C84\u0DF4\u0E4F\u0E5A\u0E5B\u0F04-\u0F12\u0F14\u0F3A-\u0F3D\u0F85\u0FD0-\u0FD4\u0FD9\u0FDA\u104A-\u104F\u10FB\u1360-\u1368\u1400\u166E\u1680\u169B\u169C\u16EB-\u16ED\u1735\u1736\u17D4-\u17D6\u17D8-\u17DA\u1800-\u180A\u1944\u1945\u1A1E\u1A1F\u1AA0-\u1AA6\u1AA8-\u1AAD\u1B5A-\u1B60\u1BFC-\u1BFF\u1C3B-\u1C3F\u1C7E\u1C7F\u1CC0-\u1CC7\u1CD3\u2000-\u200A\u2010-\u2029\u202F-\u2043\u2045-\u2051\u2053-\u205F\u207D\u207E\u208D\u208E\u2308-\u230B\u2329\u232A\u2768-\u2775\u27C5\u27C6\u27E6-\u27EF\u2983-\u2998\u29D8-\u29DB\u29FC\u29FD\u2CF9-\u2CFC\u2CFE\u2CFF\u2D70\u2E00-\u2E2E\u2E30-\u2E4F\u3000-\u3003\u3008-\u3011\u3014-\u301F\u3030\u303D\u30A0\u30FB\uA4FE\uA4FF\uA60D-\uA60F\uA673\uA67E\uA6F2-\uA6F7\uA874-\uA877\uA8CE\uA8CF\uA8F8-\uA8FA\uA8FC\uA92E\uA92F\uA95F\uA9C1-\uA9CD\uA9DE\uA9DF\uAA5C-\uAA5F\uAADE\uAADF\uAAF0\uAAF1\uABEB\uFD3E\uFD3F\uFE10-\uFE19\uFE30-\uFE52\uFE54-\uFE61\uFE63\uFE68\uFE6A\uFE6B\uFF01-\uFF03\uFF05-\uFF0A\uFF0C-\uFF0F\uFF1A\uFF1B\uFF1F\uFF20\uFF3B-\uFF3D\uFF3F\uFF5B\uFF5D\uFF5F-\uFF65]+/u,S="or",$="and",ct="and_not",lt=(e,t)=>{e.includes(t)||e.push(t)},P=(e,t)=>{for(const s of t)e.includes(s)||e.push(s)},N=({score:e},{score:t})=>t-e,ht=()=>new Map,k=e=>{const t=new Map;for(const s of Object.keys(e))t.set(parseInt(s,10),e[s]);return t},G=(e,t)=>Object.prototype.hasOwnProperty.call(e,t)?e[t]:void 0,dt={[S]:(e,t)=>{for(const s of t.keys()){const n=e.get(s);if(n==null)e.set(s,t.get(s));else{const{score:u,terms:o,match:i}=t.get(s);n.score=n.score+u,n.match=Object.assign(n.match,i),P(n.terms,o)}}return e},[$]:(e,t)=>{const s=new Map;for(const n of t.keys()){const u=e.get(n);if(u==null)continue;const{score:o,terms:i,match:r}=t.get(n);P(u.terms,i),s.set(n,{score:u.score+o,terms:u.terms,match:Object.assign(u.match,r)})}return s},[ct]:(e,t)=>{for(const s of t.keys())e.delete(s);return e}},at=(e,t,s,n,u,o)=>{const{k:i,b:r,d}=o;return Math.log(1+(s-t+.5)/(t+.5))*(d+e*(i+1)/(e+i*(1-r+r*n/u)))},ft=e=>(t,s,n)=>{const u=typeof e.fuzzy=="function"?e.fuzzy(t,s,n):e.fuzzy||!1,o=typeof e.prefix=="function"?e.prefix(t,s,n):e.prefix===!0;return{term:t,fuzzy:u,prefix:o}},H=(e,t,s,n)=>{for(const u of Object.keys(e._fieldIds))if(e._fieldIds[u]===s){e._options.logger("warn",`SlimSearch: document with ID ${e._documentIds.get(t)} has changed before removal: term "${n}" was not present in field "${u}". Removing a document after it has changed can corrupt the index!`,"version_conflict");return}},gt=(e,t,s,n)=>{if(!e._index.has(n)){H(e,s,t,n);return}const u=e._index.fetch(n,ht),o=u.get(t);o==null||o.get(s)==null?H(e,s,t,n):o.get(s)<=1?o.size<=1?u.delete(t):o.delete(s):o.set(s,o.get(s)-1),e._index.get(n).size===0&&e._index.delete(n)},mt={k:1.2,b:.7,d:.5},pt={idField:"id",extractField:(e,t)=>e[t],tokenize:e=>e.split(rt),processTerm:e=>e.toLowerCase(),fields:void 0,searchOptions:void 0,storeFields:[],logger:(e,t)=>{typeof console?.[e]=="function"&&console[e](t)},autoVacuum:!0},J={combineWith:S,prefix:!1,fuzzy:!1,maxFuzzy:6,boost:{},weights:{fuzzy:.45,prefix:.375},bm25:mt},Ft={combineWith:$,prefix:(e,t,s)=>t===s.length-1},_t={batchSize:1e3,batchWait:10},U={minDirtFactor:.1,minDirtCount:20},yt={..._t,...U},Y=(e,t=S)=>{if(e.length===0)return new Map;const s=t.toLowerCase();return e.reduce(dt[s])||new Map},B=(e,t,s,n,u,o,i,r,d=new Map)=>{if(u==null)return d;for(const l of Object.keys(o)){const a=o[l],h=e._fieldIds[l],m=u.get(h);if(m==null)continue;let p=m.size;const f=e._avgFieldLength[h];for(const c of m.keys()){if(!e._documentIds.has(c)){gt(e,h,c,s),p-=1;continue}const g=i?i(e._documentIds.get(c),s,e._storedFields.get(c)):1;if(!g)continue;const _=m.get(c),y=e._fieldLength.get(c)[h],b=at(_,p,e._documentCount,y,f,r),z=n*a*g*b,A=d.get(c);if(A){A.score+=z,lt(A.terms,t);const w=G(A.match,s);w?w.push(l):A.match[s]=[l]}else d.set(c,{score:z,terms:[t],match:{[s]:[l]}})}}return d},At=(e,t,s)=>{const n={...e._options.searchOptions,...s},u=(n.fields||e._options.fields).reduce((c,g)=>({...c,[g]:G(n.boost,g)||1}),{}),{boostDocument:o,weights:i,maxFuzzy:r,bm25:d}=n,{fuzzy:l,prefix:a}={...J.weights,...i},h=e._index.get(t.term),m=B(e,t.term,t.term,1,h,u,o,d);let p,f;if(t.prefix&&(p=e._index.atPrefix(t.term)),t.fuzzy){const c=t.fuzzy===!0?.2:t.fuzzy,g=c<1?Math.min(r,Math.round(t.term.length*c)):c;g&&(f=e._index.fuzzyGet(t.term,g))}if(p)for(const[c,g]of p){const _=c.length-t.term.length;if(!_)continue;f?.delete(c);const y=a*c.length/(c.length+.3*_);B(e,t.term,c,y,g,u,o,d,m)}if(f)for(const c of f.keys()){const[g,_]=f.get(c);if(!_)continue;const y=l*c.length/(c.length+_);B(e,t.term,c,y,g,u,o,d,m)}return m},X=(e,t,s={})=>{if(typeof t!="string"){const a={...s,...t,queries:void 0},h=t.queries.map(m=>X(e,m,a));return Y(h,a.combineWith)}const{tokenize:n,processTerm:u,searchOptions:o}=e._options,i={tokenize:n,processTerm:u,...o,...s},{tokenize:r,processTerm:d}=i,l=r(t).flatMap(a=>d(a)).filter(a=>!!a).map(ft(i)).map(a=>At(e,a,i));return Y(l,i.combineWith)},K=(e,t,s={})=>{const n=X(e,t,s),u=[];for(const[o,{score:i,terms:r,match:d}]of n){const l=r.length,a={id:e._documentIds.get(o),score:i*l,terms:Object.keys(d),match:d};Object.assign(a,e._storedFields.get(o)),(s.filter==null||s.filter(a))&&u.push(a)}return u.sort(N),u},Ct=(e,t,s={})=>{s={...e._options.autoSuggestOptions,...s};const n=new Map;for(const{score:o,terms:i}of K(e,t,s)){const r=i.join(" "),d=n.get(r);d!=null?(d.score+=o,d.count+=1):n.set(r,{score:o,terms:i,count:1})}const u=[];for(const[o,{score:i,terms:r,count:d}]of n)u.push({suggestion:o,terms:r,score:i/d});return u.sort(N),u};class Et{_options;_index;_documentCount;_documentIds;_idToShortId;_fieldIds;_fieldLength;_avgFieldLength;_nextId;_storedFields;_dirtCount;_currentVacuum;_enqueuedVacuum;_enqueuedVacuumConditions;constructor(t){if(t?.fields==null)throw new Error('SlimSearch: option "fields" must be provided');const s=t.autoVacuum==null||t.autoVacuum===!0?yt:t.autoVacuum;this._options={...pt,...t,autoVacuum:s,searchOptions:{...J,...t.searchOptions||{}},autoSuggestOptions:{...Ft,...t.autoSuggestOptions||{}}},this._index=new C,this._documentCount=0,this._documentIds=new Map,this._idToShortId=new Map,this._fieldIds={},this._fieldLength=new Map,this._avgFieldLength=[],this._nextId=0,this._storedFields=new Map,this._dirtCount=0,this._currentVacuum=null,this._enqueuedVacuum=null,this._enqueuedVacuumConditions=U,this.addFields(this._options.fields)}get isVacuuming(){return this._currentVacuum!=null}get dirtCount(){return this._dirtCount}get dirtFactor(){return this._dirtCount/(1+this._documentCount+this._dirtCount)}get documentCount(){return this._documentCount}get termCount(){return this._index.size}toJSON(){const t=[];for(const[s,n]of this._index){const u={};for(const[o,i]of n)u[o]=Object.fromEntries(i);t.push([s,u])}return{documentCount:this._documentCount,nextId:this._nextId,documentIds:Object.fromEntries(this._documentIds),fieldIds:this._fieldIds,fieldLength:Object.fromEntries(this._fieldLength),averageFieldLength:this._avgFieldLength,storedFields:Object.fromEntries(this._storedFields),dirtCount:this._dirtCount,index:t,serializationVersion:2}}addFields(t){for(let s=0;s<t.length;s++)this._fieldIds[t[s]]=s}}const zt=({index:e,documentCount:t,nextId:s,documentIds:n,fieldIds:u,fieldLength:o,averageFieldLength:i,storedFields:r,dirtCount:d,serializationVersion:l},a)=>{if(l!==1&&l!==2)throw new Error("SlimSearch: cannot deserialize an index created with an incompatible version");const h=new Et(a);h._documentCount=t,h._nextId=s,h._documentIds=k(n),h._idToShortId=new Map,h._fieldIds=u,h._fieldLength=k(o),h._avgFieldLength=i,h._storedFields=k(r),h._dirtCount=d||0,h._index=new C;for(const[m,p]of h._documentIds)h._idToShortId.set(p,m);for(const[m,p]of e){const f=new Map;for(const c of Object.keys(p)){let g=p[c];l===1&&(g=g.ds),f.set(parseInt(c,10),k(g))}h._index.set(m,f)}return h},Q=Object.entries,wt=Object.fromEntries,j=(e,t)=>{const s=e.toLowerCase(),n=t.toLowerCase(),u=[];let o=0,i=0;const r=(l,a=!1)=>{let h="";i===0?h=l.length>20?`… ${l.slice(-20)}`:l:a?h=l.length+i>100?`${l.slice(0,100-i)}… `:l:h=l.length>20?`${l.slice(0,20)} … ${l.slice(-20)}`:l,h&&u.push(h),i+=h.length,a||(u.push(["mark",t]),i+=t.length,i>=100&&u.push(" …"))};let d=s.indexOf(n,o);if(d===-1)return null;for(;d>=0;){const l=d+n.length;if(r(e.slice(o,d)),o=l,i>100)break;d=s.indexOf(n,o)}return i<100&&r(e.slice(o),!0),u},Z=/[\u4e00-\u9fa5]/g,tt=(e={})=>({fuzzy:.2,prefix:!0,processTerm:t=>{const s=t.match(Z)||[],n=t.replace(Z,"").toLowerCase();return n?[n,...s]:[...s]},...e}),xt=(e,t)=>t.contents.reduce((s,[,n])=>s+n,0)-e.contents.reduce((s,[,n])=>s+n,0),kt=(e,t)=>Math.max(...t.contents.map(([,s])=>s))-Math.max(...e.contents.map(([,s])=>s)),et=(e,t,s={})=>{const n={};return K(t,e,tt({boost:{h:2,t:1,c:4},...s})).forEach(u=>{const{id:o,terms:i,score:r}=u,d=o.includes("@"),l=o.includes("#"),[a,h]=o.split(/[#@]/),m=i.sort((f,c)=>f.length-c.length).filter((f,c)=>i.slice(c+1).every(g=>!g.includes(f))),{contents:p}=n[a]??={title:"",contents:[]};if(d)p.push([{type:"customField",key:a,index:h,display:m.map(f=>u.c.map(c=>j(c,f))).flat().filter(f=>f!==null)},r]);else{const f=m.map(c=>j(u.h,c)).filter(c=>c!==null);if(f.length&&p.push([{type:l?"heading":"title",key:a,...l&&{anchor:h},display:f},r]),"t"in u)for(const c of u.t){const g=m.map(_=>j(c,_)).filter(_=>_!==null);g.length&&p.push([{type:"text",key:a,...l&&{anchor:h},display:g},r])}}}),Q(n).sort(([,u],[,o])=>"max"==="total"?xt(u,o):kt(u,o)).map(([u,{title:o,contents:i}])=>{if(!o){const r=it(t,u);r&&(o=r.h)}return{title:o,contents:i.map(([r])=>r)}})},st=(e,t,s={})=>Ct(t,e,tt(s)).map(({suggestion:n})=>n),v=wt(Q(JSON.parse("{\"/\":{\"documentCount\":285,\"nextId\":285,\"documentIds\":{\"0\":\"v-8daa1a0e\",\"1\":\"v-184f4da6\",\"2\":\"v-2e3eac9e\",\"3\":\"v-2e3eac9e#幻灯片演示\",\"4\":\"v-2e3eac9e#标注幻灯片\",\"5\":\"v-2e3eac9e#标注幻灯片-1\",\"6\":\"v-2e3eac9e#markdown\",\"7\":\"v-2e3eac9e#markdown-1\",\"8\":\"v-2e3eac9e#这是一个-h3\",\"9\":\"v-2e3eac9e#markdown-2\",\"10\":\"v-2e3eac9e#markdown-3\",\"11\":\"v-2e3eac9e#markdown-4\",\"12\":\"v-2e3eac9e#markdown-5\",\"13\":\"v-2e3eac9e#布局\",\"14\":\"v-2e3eac9e#布局-1\",\"15\":\"v-2e3eac9e#布局-2\",\"16\":\"v-2e3eac9e#布局-3\",\"17\":\"v-2e3eac9e#背景\",\"18\":\"v-2e3eac9e#动画片段\",\"19\":\"v-2e3eac9e#动画片段-1\",\"20\":\"v-2e3eac9e#动画片段-2\",\"21\":\"v-2e3eac9e#动画-class\",\"22\":\"v-2e3eac9e#动画片段-3\",\"23\":\"v-2e3eac9e#动画-class-1\",\"24\":\"v-2e3eac9e#动画片段-4\",\"25\":\"v-2e3eac9e#多个动画片段\",\"26\":\"v-2e3eac9e#动画片段-5\",\"27\":\"v-2e3eac9e#顺序\",\"28\":\"v-2e3eac9e#渐变\",\"29\":\"v-2e3eac9e#渐变-1\",\"30\":\"v-2e3eac9e#渐变-2\",\"31\":\"v-2e3eac9e#过渡动画\",\"32\":\"v-2e3eac9e#功能\",\"33\":\"v-2e3eac9e#功能-1\",\"34\":\"v-2e3eac9e#代码\",\"35\":\"v-2e3eac9e#功能-2\",\"36\":\"v-2e3eac9e#预览模式\",\"37\":\"v-2e3eac9e#功能-3\",\"38\":\"v-2e3eac9e#全屏模式\",\"39\":\"v-2e3eac9e#功能-4\",\"40\":\"v-2e3eac9e#缩放\",\"41\":\"v-2e3eac9e#结束\",\"42\":\"v-a94a8cca\",\"43\":\"v-62633a0e\",\"44\":\"v-2d0a830e\",\"45\":\"v-1473bf53\",\"46\":\"v-1473bf53#目录\",\"47\":\"v-1473bf53@0\",\"48\":\"v-4e65ec78\",\"49\":\"v-4e65ec78@0\",\"50\":\"v-4e65ec78@1\",\"51\":\"v-c151bf32\",\"52\":\"v-c151bf32@0\",\"53\":\"v-c151bf32@1\",\"54\":\"v-438ffe52\",\"55\":\"v-438ffe52#markdown-介绍\",\"56\":\"v-438ffe52#markdown-配置\",\"57\":\"v-438ffe52#markdown-扩展\",\"58\":\"v-438ffe52#vuepress-扩展\",\"59\":\"v-438ffe52#主题扩展\",\"60\":\"v-438ffe52#提示容器\",\"61\":\"v-438ffe52#代码块\",\"62\":\"v-438ffe52#上下角标\",\"63\":\"v-438ffe52#自定义对齐\",\"64\":\"v-438ffe52#attrs\",\"65\":\"v-438ffe52#脚注\",\"66\":\"v-438ffe52#标记\",\"67\":\"v-438ffe52#任务列表\",\"68\":\"v-438ffe52#图片增强\",\"69\":\"v-438ffe52#组件\",\"70\":\"v-438ffe52#导入文件\",\"71\":\"v-438ffe52#代码演示\",\"72\":\"v-438ffe52#样式化\",\"73\":\"v-438ffe52#交互演示\",\"74\":\"v-438ffe52#图表\",\"75\":\"v-438ffe52#echarts\",\"76\":\"v-438ffe52#流程图\",\"77\":\"v-438ffe52#mermaid\",\"78\":\"v-438ffe52#tex-语法\",\"79\":\"v-438ffe52#vue-交互演示\",\"80\":\"v-438ffe52@0\",\"81\":\"v-438ffe52@1\",\"82\":\"v-6e19edb7\",\"83\":\"v-6e19edb7#页面信息\",\"84\":\"v-6e19edb7#页面内容\",\"85\":\"v-6e19edb7#页面结构\",\"86\":\"v-6e19edb7@0\",\"87\":\"v-6e19edb7@1\",\"88\":\"v-19d854d8\",\"89\":\"v-19d854d8#提示容器\",\"90\":\"v-19d854d8#信息容器\",\"91\":\"v-19d854d8#提示容器-1\",\"92\":\"v-19d854d8#警告容器\",\"93\":\"v-19d854d8#危险容器\",\"94\":\"v-19d854d8#重要容器\",\"95\":\"v-19d854d8#详情容器\",\"96\":\"v-19d854d8#选项卡\",\"97\":\"v-19d854d8#对齐\",\"98\":\"v-19d854d8#属性支持\",\"99\":\"v-19d854d8#id\",\"100\":\"v-19d854d8#脚注\",\"101\":\"v-19d854d8#任务列表\",\"102\":\"v-19d854d8@0\",\"103\":\"v-19d854d8@1\",\"104\":\"v-14f0dace\",\"105\":\"v-030f8c47\",\"106\":\"v-2bc6566a\",\"107\":\"v-2bc6566a#标题-2\",\"108\":\"v-2bc6566a#标题-3\",\"109\":\"v-2bc6566a@0\",\"110\":\"v-2bc6566a@1\",\"111\":\"v-24b7c48d\",\"112\":\"v-24b7c48d#标题-2\",\"113\":\"v-24b7c48d#标题-3\",\"114\":\"v-24b7c48d@0\",\"115\":\"v-24b7c48d@1\",\"116\":\"v-f0ec4556\",\"117\":\"v-f0ec4556#标题-2\",\"118\":\"v-f0ec4556#标题-3\",\"119\":\"v-f0ec4556@0\",\"120\":\"v-f0ec4556@1\",\"121\":\"v-df8b6e0c\",\"122\":\"v-df8b6e0c#标题-2\",\"123\":\"v-df8b6e0c#标题-3\",\"124\":\"v-df8b6e0c@0\",\"125\":\"v-df8b6e0c@1\",\"126\":\"v-3f615d37\",\"127\":\"v-3f615d37#分发饼干\",\"128\":\"v-3f615d37#排序-贪心法-双指针\",\"129\":\"v-3f615d37#代码\",\"130\":\"v-3f615d37#注意事项\",\"131\":\"v-3f615d37#其他\",\"132\":\"v-3f615d37#有效的山脉数组\",\"133\":\"v-3f615d37#寻找数组的中心下标\",\"134\":\"v-3f615d37#按奇偶排序数组ii\",\"135\":\"v-3f615d37#旋转数组\",\"136\":\"v-3f615d37#使用额外的空间\",\"137\":\"v-3f615d37#数组反转\",\"138\":\"v-3f615d37#区间问题\",\"139\":\"v-3f615d37#插入区间\",\"140\":\"v-3f615d37#模拟法\",\"141\":\"v-3f615d37#环形数组\",\"142\":\"v-3f615d37#矩阵\",\"143\":\"v-3f615d37#螺旋矩阵\",\"144\":\"v-3f615d37#螺旋矩阵-ii\",\"145\":\"v-3f615d37#旋转图像\",\"146\":\"v-3f615d37#矩阵置零\",\"147\":\"v-3f615d37#扑克牌中的顺子\",\"148\":\"v-9a72c052\",\"149\":\"v-9a72c052#目录\",\"150\":\"v-64a42731\",\"151\":\"v-12210fd9\",\"152\":\"v-12210fd9#目录\",\"153\":\"v-6d2b83a6\",\"154\":\"v-6d2b83a6#向量和向量空间\",\"155\":\"v-6d2b83a6#向量\",\"156\":\"v-6d2b83a6#向量空间\",\"157\":\"v-2d035e0f\",\"158\":\"v-2d035e0f#容器\",\"159\":\"v-2d035e0f#信息容器\",\"160\":\"v-2d035e0f#提示容器\",\"161\":\"v-2d035e0f#警告容器\",\"162\":\"v-2d035e0f#危险容器\",\"163\":\"v-2d035e0f#详情容器\",\"164\":\"v-2d035e0f#选项卡\",\"165\":\"v-2d035e0f#对齐\",\"166\":\"v-2d035e0f#属性支持\",\"167\":\"v-2d035e0f#id\",\"168\":\"v-2d035e0f#脚注\",\"169\":\"v-2d035e0f#任务列表\",\"170\":\"v-3f2786dc\",\"171\":\"v-475db5be\",\"172\":\"v-6cedb9f8\",\"173\":\"v-6cedb9f8#图模型的基本问题\",\"174\":\"v-6cedb9f8#图模型与机器学习\",\"175\":\"v-6cedb9f8#本章目录\",\"176\":\"v-6cedb9f8#资料\",\"177\":\"v-32a05752\",\"178\":\"v-32a05752#有向图模型\",\"179\":\"v-32a05752#常见的有向图模型\",\"180\":\"v-32a05752#sigmoid信念网络\",\"181\":\"v-32a05752#朴素贝叶斯分类器\",\"182\":\"v-32a05752#隐马尔可夫模型\",\"183\":\"v-32a05752#无向图模型\",\"184\":\"v-32a05752#无向图模型的概率分解\",\"185\":\"v-32a05752#常见的无向图模型\",\"186\":\"v-32a05752#对数线性模型\",\"187\":\"v-32a05752#条件随机场\",\"188\":\"v-32a05752#参考\",\"189\":\"v-2ff46f0a\",\"190\":\"v-2ff46f0a#基本概念\",\"191\":\"v-2ff46f0a#对抗鲁棒性\",\"192\":\"v-2ff46f0a#对抗攻击的分类\",\"193\":\"v-2ff46f0a#fgsm\",\"194\":\"v-2ff46f0a#简介\",\"195\":\"v-2ff46f0a#对抗样本的线性解释\",\"196\":\"v-2ff46f0a#非线性模型的线性扰动\",\"197\":\"v-2ff46f0a#线性模型的对抗训练与权重衰减的对比研究\",\"198\":\"v-2ff46f0a#pgd\",\"199\":\"v-6e796960\",\"200\":\"v-6e796960#notation\",\"201\":\"v-6e796960#激活函数的线性上上下界\",\"202\":\"v-6e796960#定理中涉及的符号\",\"203\":\"v-2d88cdd0\",\"204\":\"v-e1a99a1e\",\"205\":\"v-4ed6beed\",\"206\":\"v-4ed6beed#相平面\",\"207\":\"v-0815c951\",\"208\":\"v-39fc050c\",\"209\":\"v-39fc050c#预备知识\",\"210\":\"v-39fc050c#euler法\",\"211\":\"v-39fc050c#talyot法\",\"212\":\"v-39fc050c#runge-kutta法\",\"213\":\"v-67b8c712\",\"214\":\"v-67b8c712#标题-2\",\"215\":\"v-67b8c712#标题-3\",\"216\":\"v-67b8c712@0\",\"217\":\"v-67b8c712@1\",\"218\":\"v-696d9fb1\",\"219\":\"v-696d9fb1#标题-2\",\"220\":\"v-696d9fb1#标题-3\",\"221\":\"v-696d9fb1@0\",\"222\":\"v-696d9fb1@1\",\"223\":\"v-6b227850\",\"224\":\"v-6b227850#标题-2\",\"225\":\"v-6b227850#标题-3\",\"226\":\"v-6b227850@0\",\"227\":\"v-6b227850@1\",\"228\":\"v-6cd750ef\",\"229\":\"v-6cd750ef#标题-2\",\"230\":\"v-6cd750ef#标题-3\",\"231\":\"v-6cd750ef@0\",\"232\":\"v-6cd750ef@1\",\"233\":\"v-7a07405d\",\"234\":\"v-7a07405d#标题-2\",\"235\":\"v-7a07405d#标题-3\",\"236\":\"v-7a07405d@0\",\"237\":\"v-7a07405d@1\",\"238\":\"v-7bbc18fc\",\"239\":\"v-7bbc18fc#标题-2\",\"240\":\"v-7bbc18fc#标题-3\",\"241\":\"v-7bbc18fc@0\",\"242\":\"v-7bbc18fc@1\",\"243\":\"v-7d70f19b\",\"244\":\"v-7d70f19b#标题-2\",\"245\":\"v-7d70f19b#标题-3\",\"246\":\"v-7d70f19b@0\",\"247\":\"v-7d70f19b@1\",\"248\":\"v-7f25ca3a\",\"249\":\"v-7f25ca3a#标题-2\",\"250\":\"v-7f25ca3a#标题-3\",\"251\":\"v-7f25ca3a@0\",\"252\":\"v-7f25ca3a@1\",\"253\":\"v-7f8139e0\",\"254\":\"v-ea40b9d6\",\"255\":\"v-ea40b9d6#重参数化技巧\",\"256\":\"v-48487511\",\"257\":\"v-42d90fba\",\"258\":\"v-42d90fba#自适应检查点伴随法\",\"259\":\"v-42d90fba@1\",\"260\":\"v-4c4a0803\",\"261\":\"v-3c543444\",\"262\":\"v-1d45d382\",\"263\":\"v-1d45d382#增维的的node\",\"264\":\"v-1d45d382#对输入做仿射变换\",\"265\":\"v-1d45d382#随机化额外维度的初始值\",\"266\":\"v-1d45d382#分段的node\",\"267\":\"v-a8d6da06\",\"268\":\"v-a8d6da06#notation\",\"269\":\"v-a8d6da06#同胚和流形假设\",\"270\":\"v-a8d6da06#增维的node\",\"271\":\"v-a8d6da06@1\",\"272\":\"v-10859c10\",\"273\":\"v-56238b0d\",\"274\":\"v-56238b0d#介绍\",\"275\":\"v-56238b0d#详情\",\"276\":\"v-558b68aa\",\"277\":\"v-562590ba\",\"278\":\"v-562590ba#介绍\",\"279\":\"v-562590ba#详情\",\"280\":\"v-8ff76cae\",\"281\":\"v-0011afe4\",\"282\":\"v-e1e3da16\",\"283\":\"v-08f42f4a\",\"284\":\"v-30be3cd5\"},\"fieldIds\":{\"h\":0,\"t\":1,\"c\":2},\"fieldLength\":{\"0\":[1,11],\"1\":[1,2],\"2\":[1,2],\"3\":[1,5],\"4\":[1,2],\"5\":[1,12],\"6\":[1,4],\"7\":[1,4],\"8\":[2,11],\"9\":[1,11],\"10\":[1,12],\"11\":[1,10],\"12\":[1,8],\"13\":[1,1],\"14\":[1,7],\"15\":[1,8],\"16\":[1],\"17\":[1,5],\"18\":[1,1],\"19\":[1,6],\"20\":[1],\"21\":[2,10],\"22\":[1],\"23\":[2,9],\"24\":[1],\"25\":[1,8],\"26\":[1],\"27\":[1,9],\"28\":[1,1],\"29\":[1,15],\"30\":[1],\"31\":[1,8],\"32\":[1,1],\"33\":[1],\"34\":[1,20],\"35\":[1],\"36\":[1,6],\"37\":[1],\"38\":[1,6],\"39\":[1],\"40\":[1,9],\"41\":[1,2],\"42\":[1],\"43\":[1],\"44\":[1],\"45\":[1],\"46\":[1,5],\"47\":[null,null,1],\"48\":[1,18],\"49\":[null,null,1],\"50\":[null,null,1],\"51\":[1,7],\"52\":[null,null,1],\"53\":[null,null,1],\"54\":[2,11],\"55\":[2,8],\"56\":[2,13],\"57\":[2,11],\"58\":[2,10],\"59\":[1,10],\"60\":[1,19],\"61\":[1,1],\"62\":[1,3],\"63\":[1,3],\"64\":[1,5],\"65\":[1,3],\"66\":[1,3],\"67\":[1,5],\"68\":[1,2],\"69\":[1,23],\"70\":[1,6],\"71\":[1,1],\"72\":[1,5],\"73\":[1,1],\"74\":[1,25],\"75\":[1,26],\"76\":[1,12],\"77\":[1,19],\"78\":[2,1],\"79\":[2,7],\"80\":[null,null,1],\"81\":[null,null,1],\"82\":[1,3],\"83\":[1,20],\"84\":[1,17],\"85\":[1,16],\"86\":[null,null,1],\"87\":[null,null,2],\"88\":[2],\"89\":[1],\"90\":[1,16],\"91\":[1,4],\"92\":[1,4],\"93\":[1,4],\"94\":[1,4],\"95\":[1,4],\"96\":[1,16],\"97\":[1,5],\"98\":[1],\"99\":[1,10],\"100\":[1,3],\"101\":[1,6],\"102\":[null,null,1],\"103\":[null,null,1],\"104\":[1],\"105\":[1],\"106\":[1],\"107\":[2,2],\"108\":[2,2],\"109\":[null,null,1],\"110\":[null,null,3],\"111\":[1],\"112\":[2,2],\"113\":[2,2],\"114\":[null,null,2],\"115\":[null,null,2],\"116\":[1],\"117\":[2,2],\"118\":[2,2],\"119\":[null,null,2],\"120\":[null,null,2],\"121\":[1,1],\"122\":[2,2],\"123\":[2,2],\"124\":[null,null,1],\"125\":[null,null,2],\"126\":[1],\"127\":[1,5],\"128\":[1,22],\"129\":[1,39],\"130\":[1,46],\"131\":[1,28],\"132\":[1],\"133\":[1,7],\"134\":[1,74],\"135\":[1,5],\"136\":[1,23],\"137\":[1,19],\"138\":[1],\"139\":[1,30],\"140\":[1,40],\"141\":[1,6],\"142\":[1],\"143\":[1],\"144\":[2],\"145\":[1],\"146\":[1],\"147\":[1,7],\"148\":[1],\"149\":[1,2],\"150\":[1],\"151\":[1],\"152\":[1,5],\"153\":[1,5],\"154\":[1],\"155\":[1,26],\"156\":[1],\"157\":[1],\"158\":[1],\"159\":[1,16],\"160\":[1,4],\"161\":[1,4],\"162\":[1,4],\"163\":[1,4],\"164\":[1,16],\"165\":[1,5],\"166\":[1],\"167\":[1,5],\"168\":[1,3],\"169\":[1,6],\"170\":[1,5],\"171\":[1,1],\"172\":[1,111],\"173\":[1,14],\"174\":[1,10],\"175\":[1,1],\"176\":[1,11],\"177\":[1,35],\"178\":[1,104],\"179\":[1,5],\"180\":[1,50],\"181\":[1,40],\"182\":[1,29],\"183\":[1,40],\"184\":[1,68],\"185\":[1,7],\"186\":[1,29],\"187\":[1],\"188\":[1,37],\"189\":[1],\"190\":[1,8],\"191\":[1,8],\"192\":[1,21],\"193\":[1,21],\"194\":[1,5],\"195\":[1,40],\"196\":[1,166],\"197\":[1],\"198\":[1,13],\"199\":[1,7],\"200\":[1,29],\"201\":[1,30],\"202\":[1],\"203\":[1,2],\"204\":[1],\"205\":[1,55],\"206\":[1,10],\"207\":[1],\"208\":[1],\"209\":[1,83],\"210\":[1,46],\"211\":[1,15],\"212\":[2,5],\"213\":[2],\"214\":[2,2],\"215\":[2,2],\"216\":[null,null,1],\"217\":[null,null,3],\"218\":[2,2],\"219\":[2,2],\"220\":[2,2],\"221\":[null,null,1],\"222\":[null,null,3],\"223\":[2],\"224\":[2,2],\"225\":[2,2],\"226\":[null,null,2],\"227\":[null,null,3],\"228\":[2],\"229\":[2,2],\"230\":[2,2],\"231\":[null,null,2],\"232\":[null,null,3],\"233\":[2],\"234\":[2,2],\"235\":[2,2],\"236\":[null,null,2],\"237\":[null,null,3],\"238\":[2,4],\"239\":[2,2],\"240\":[2,2],\"241\":[null,null,2],\"242\":[null,null,3],\"243\":[2],\"244\":[2,2],\"245\":[2,2],\"246\":[null,null,1],\"247\":[null,null,3],\"248\":[2],\"249\":[2,2],\"250\":[2,2],\"251\":[null,null,1],\"252\":[null,null,3],\"253\":[1,13],\"254\":[1,5],\"255\":[1,14],\"256\":[1,40],\"257\":[1],\"258\":[1,5],\"259\":[null,null,1],\"260\":[1,103],\"261\":[1,1],\"262\":[1],\"263\":[1,14],\"264\":[1,55],\"265\":[1,59],\"266\":[1,58],\"267\":[1],\"268\":[1,33],\"269\":[1,78],\"270\":[1,72],\"271\":[null,null,1],\"272\":[1,36],\"273\":[2],\"274\":[1,4],\"275\":[1,2],\"276\":[1,2],\"277\":[2],\"278\":[1,4],\"279\":[1,2],\"280\":[1,2],\"281\":[1,20],\"282\":[1],\"283\":[1],\"284\":[1]},\"averageFieldLength\":[1.1831030662482829,13.53961891664752,0.4120398715687713],\"storedFields\":{\"0\":{\"h\":\"博客主页\",\"t\":[\"这是一个博客主页的案例。\",\"要使用此布局，你应该在页面前端设置 layout: BlogHome 和 home: true。\",\"相关配置文档请见 博客主页。\"]},\"1\":{\"h\":\"个人介绍\",\"t\":[\"是最爱聪聪园的笨丁呢！\"]},\"2\":{\"h\":\"幻灯片页\",\"t\":[\"@slidestart\"]},\"3\":{\"h\":\"幻灯片演示\",\"t\":[\"一个简单的幻灯片演示与各种小贴士。\",\"作者 Mr.Hope. 请滚动鼠标滚轮进入下一页\"]},\"4\":{\"h\":\"标注幻灯片\",\"t\":[\"👇\",\"--\"]},\"5\":{\"h\":\"标注幻灯片\",\"t\":[\"使用 --- 标注水平幻灯片\",\"在水平幻灯片中使用 -- 分割垂直幻灯片\",\"使用 <!-- .slide: ... --> 在幻灯片上添加属性\",\"使用 <!-- .element: ... --> 在前一个 HTML 元素上添加属性\"]},\"6\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\",\"--\"]},\"7\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\"]},\"8\":{\"h\":\"这是一个 H3\",\"t\":[\"标题默认会自动转换为大写。\",\"这是一个有着 粗体, 斜体, 删除线 文字并包含 一个链接 的段落，并且它会自动换行。所以你无需担心它的长度。\",\"--\"]},\"9\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\",\"列表默认为 inline-block\",\"项目\",\"项目\",\"项目\",\"项目 1\",\"项目 2\",\"项目 3\",\"--\"]},\"10\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\",\"在你启用 highlight 插件后，代码块会自动高亮。\",\"const a = 1; \",\"--\"]},\"11\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\",\"在你启用 math 插件后，你也可以使用 TEX 格式使用数学公式。\",\"--\"]},\"12\":{\"h\":\"Markdown\",\"t\":[\"你可以在幻灯片中使用 Markdown 语法的各种标记.\",\"⚠请注意: 表格和分割线，以及所有不在 Markdown 标准语法中的内容均不受支持。\"]},\"13\":{\"h\":\"布局\",\"t\":[\"--\"]},\"14\":{\"h\":\"布局\",\"t\":[\"👆 r-fit-text class 会让文字在不超出幻灯片范围的情况下尽可能大。\",\"--\"]},\"15\":{\"h\":\"布局\",\"t\":[\"Logo\",\"👆 r-stretch class 帮助你控制注入图片或视频的大小，使它们填充满幻灯片垂直方向上的剩余空间。\",\"--\"]},\"16\":{\"h\":\"布局\"},\"17\":{\"h\":\"背景\",\"t\":[\"你可以通过向特定幻灯片添加 data-background 属性自定义幻灯片背景.\"]},\"18\":{\"h\":\"动画片段\",\"t\":[\"--\"]},\"19\":{\"h\":\"动画片段\",\"t\":[\"动画片段用于高亮或显隐幻灯片中的元素。\",\"你需要在元素上添加 fragment 和动画 class。\",\"--\"]},\"20\":{\"h\":\"动画片段\"},\"21\":{\"h\":\"动画 class\",\"t\":[\"fade-in\",\"fade-out\",\"fade-up\",\"fade-down\",\"fade-left\",\"fade-right\",\"fade-in-then-out\",\"fade-in-then-semi-out\",\"--\"]},\"22\":{\"h\":\"动画片段\"},\"23\":{\"h\":\"动画 class\",\"t\":[\"grow\",\"shrink\",\"strike\",\"highlight-red\",\"highlight-green\",\"highlight-blue\",\"highlight-current-red\",\"highlight-current-green\",\"highlight-current-blue\",\"--\"]},\"24\":{\"h\":\"动画片段\"},\"25\":{\"h\":\"多个动画片段\",\"t\":[\"你可以按照顺序包裹一个 HTML 元素使其拥有多个动画片段 渐入 > 变红 > 渐出 \",\"--\"]},\"26\":{\"h\":\"动画片段\"},\"27\":{\"h\":\"顺序\",\"t\":[\"你可以使用 data-fragment-index 属性改变元素的动画顺序。\",\"不同元素可以有相同的动画顺序。\",\"最后显示\",\"第二个显示\",\"第一个显示\",\"第二个显示\"]},\"28\":{\"h\":\"渐变\",\"t\":[\"--\"]},\"29\":{\"h\":\"渐变\",\"t\":[\"Transition 可以通过配置中的 transition 选项全局设置，也可以通过在特定幻灯片添加 data-transition 属性局部设置.\",\"可能的值:\",\"none\",\"fade\",\"slide\",\"convex\",\"concave\",\"zoom\",\"--\"]},\"30\":{\"h\":\"渐变\"},\"31\":{\"h\":\"过渡动画\",\"t\":[\"你可以在相邻的幻灯片上添加 data-auto-animate 使相同的 HTML 元素产生过渡动画效果。\"]},\"32\":{\"h\":\"功能\",\"t\":[\"--\"]},\"33\":{\"h\":\"功能\"},\"34\":{\"h\":\"代码\",\"t\":[\"通过启用 highlight 插件，你可以对代码块进行高亮。\",\"你可以使用 [a-b|c-d] 语法来分布高亮特定行。\",\"let a = 1; let b = 2; let c = (x) => 1 + 2 + x; c(3); \",\"--\"]},\"35\":{\"h\":\"功能\"},\"36\":{\"h\":\"预览模式\",\"t\":[\"按下 Esc 或 O 即可在幻灯片获得焦点时进入预览模式。\",\"--\"]},\"37\":{\"h\":\"功能\"},\"38\":{\"h\":\"全屏模式\",\"t\":[\"按下 F 或 F11 即可在幻灯片获得焦点时进入全屏模式。\",\"--\"]},\"39\":{\"h\":\"功能\"},\"40\":{\"h\":\"缩放\",\"t\":[\"按下 alt (Linux 上使用 ctrl) 的同时点击幻灯片的任何元素，即可以向此元素进行放大。\",\"再次点击即可缩小。\"]},\"41\":{\"h\":\"结束\",\"t\":[\"@slideend\"]},\"42\":{\"h\":\"计算机\"},\"43\":{\"h\":\"基础概论\"},\"44\":{\"h\":\"深度学习\"},\"45\":{\"h\":\"主要功能与配置演示\"},\"46\":{\"h\":\"目录\",\"t\":[\"Markdown 展示\",\"页面展示\",\"禁用展示\",\"加密展示\"]},\"47\":{\"c\":[\"使用指南\"]},\"48\":{\"h\":\"布局与功能禁用\",\"t\":[\"你可以通过设置页面的 Frontmatter，在页面禁用功能与布局。\",\"本页面就是一个示例，禁用了如下功能:\",\"导航栏\",\"侧边栏\",\"路径导航\",\"页面信息\",\"贡献者\",\"编辑此页链接\",\"更新时间\",\"上一篇/下一篇 链接\",\"评论\",\"页脚\",\"返回顶部按钮\"]},\"49\":{\"c\":[\"使用指南\"]},\"50\":{\"c\":[\"禁用\"]},\"51\":{\"h\":\"密码加密的文章\",\"t\":[\"实际的文章内容。\",\"段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字段落 1 文字。\",\"段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字段落 2 文字。\"]},\"52\":{\"c\":[\"使用指南\"]},\"53\":{\"c\":[\"文章加密\"]},\"54\":{\"h\":\"Markdown 展示\",\"t\":[\"VuePress 主要从 Markdown 文件生成页面。因此，你可以使用它轻松生成文档或博客站点。\",\"你应该创建和编写 Markdown 文件，以便 VuePress 可以根据文件结构将它们转换为不同的页面。\"]},\"55\":{\"h\":\"Markdown 介绍\",\"t\":[\"如果你是一个新手，还不会编写 Markdown，请先阅读 Markdown 介绍 和 Markdown 演示。\"]},\"56\":{\"h\":\"Markdown 配置\",\"t\":[\"VuePress 通过 Frontmatter 为每个 Markdown 页面引入配置。\",\"相关信息\",\"Frontmatter 是 VuePress 中很重要的一个概念，如果你不了解它，你需要阅读 Frontmatter 介绍。\"]},\"57\":{\"h\":\"Markdown 扩展\",\"t\":[\"VuePress 会使用 markdown-it 来解析 Markdown 内容，因此可以借助于 markdown-it 插件来实现 语法扩展 。\"]},\"58\":{\"h\":\"VuePress 扩展\",\"t\":[\"为了丰富文档写作，VuePress 对 Markdown 语法进行了扩展。\",\"关于这些扩展，请阅读 VuePress 中的 Markdown 扩展。\"]},\"59\":{\"h\":\"主题扩展\",\"t\":[\"通过 vuepress-plugin-md-enhance，主题扩展了更多 Markdown 语法，提供更加丰富的写作功能。\"]},\"60\":{\"h\":\"提示容器\",\"t\":[\"安全的在 Markdown 中使用 {{ variable }}。\",\"自定义标题\",\"信息容器，包含 代码 与 链接。\",\"const a = 1; \",\"自定义标题\",\"提示容器\",\"自定义标题\",\"警告容器\",\"自定义标题\",\"危险容器\",\"自定义标题\",\"详情容器\",\"查看详情\"]},\"61\":{\"h\":\"代码块\",\"t\":[\"查看详情\"]},\"62\":{\"h\":\"上下角标\",\"t\":[\"19th H2O\",\"查看详情\"]},\"63\":{\"h\":\"自定义对齐\",\"t\":[\"我是居中的\",\"我在右对齐\",\"查看详情\"]},\"64\":{\"h\":\"Attrs\",\"t\":[\"一个拥有 ID 的 单词。\",\"查看详情\"]},\"65\":{\"h\":\"脚注\",\"t\":[\"此文字有脚注[1].\",\"查看详情\"]},\"66\":{\"h\":\"标记\",\"t\":[\"你可以标记 重要的内容 。\",\"查看详情\"]},\"67\":{\"h\":\"任务列表\",\"t\":[\" 计划 1\",\" 计划 2\",\"查看详情\"]},\"68\":{\"h\":\"图片增强\",\"t\":[\"支持为图片设置颜色模式和大小\",\"查看详情\"]},\"69\":{\"h\":\"组件\",\"t\":[\"title: Mr.Hope desc: Where there is light, there is hope logo: https://mister-hope.com/logo.svg link: https://mister-hope.com color: rgba(253, 230, 138, 0.15) \",\"查看详情\"]},\"70\":{\"h\":\"导入文件\",\"t\":[\"Markdown 展示\",\"页面展示\",\"禁用展示\",\"加密展示\",\"查看详情\"]},\"71\":{\"h\":\"代码演示\",\"t\":[\"查看详情\"]},\"72\":{\"h\":\"样式化\",\"t\":[\"向 Mr.Hope 捐赠一杯咖啡。 \",\"查看详情\"]},\"73\":{\"h\":\"交互演示\",\"t\":[\"查看详情\"]},\"74\":{\"h\":\"图表\",\"t\":[\"::: chart 一个散点图案例\",\"{ \\\"type\\\": \\\"scatter\\\", \\\"data\\\": { \\\"datasets\\\": [ { \\\"label\\\": \\\"散点数据集\\\", \\\"data\\\": [ { \\\"x\\\": -10, \\\"y\\\": 0 }, { \\\"x\\\": 0, \\\"y\\\": 10 }, { \\\"x\\\": 10, \\\"y\\\": 5 }, { \\\"x\\\": 0.5, \\\"y\\\": 5.5 } ], \\\"backgroundColor\\\": \\\"rgb(255, 99, 132)\\\" } ] }, \\\"options\\\": { \\\"scales\\\": { \\\"x\\\": { \\\"type\\\": \\\"linear\\\", \\\"position\\\": \\\"bottom\\\" } } } } \",\":::\",\"查看详情\"]},\"75\":{\"h\":\"Echarts\",\"t\":[\"::: echarts 一个折线图案例\",\"{ \\\"xAxis\\\": { \\\"type\\\": \\\"category\\\", \\\"data\\\": [\\\"Mon\\\", \\\"Tue\\\", \\\"Wed\\\", \\\"Thu\\\", \\\"Fri\\\", \\\"Sat\\\", \\\"Sun\\\"] }, \\\"yAxis\\\": { \\\"type\\\": \\\"value\\\" }, \\\"series\\\": [ { \\\"data\\\": [150, 230, 224, 218, 135, 147, 260], \\\"type\\\": \\\"line\\\" } ] } \",\":::\",\"查看详情\"]},\"76\":{\"h\":\"流程图\",\"t\":[\"cond=>condition: 是否执行操作? process=>operation: 操作 e=>end: 结束 cond(yes)->process->e cond(no)->e \",\"查看详情\"]},\"77\":{\"h\":\"Mermaid\",\"t\":[\"--- title: Flowchart --- flowchart TB c1-->a2 subgraph one a1-->a2 end subgraph two b1-->b2 end subgraph three c1-->c2 end one --> two three --> two two --> c2 \",\"查看详情\"]},\"78\":{\"h\":\"Tex 语法\",\"t\":[\"查看详情\"]},\"79\":{\"h\":\"Vue 交互演示\",\"t\":[\"::: vue-playground Vue 交互演示\",\"这是脚注内容 ↩︎\"]},\"80\":{\"c\":[\"使用指南\"]},\"81\":{\"c\":[\"Markdown\"]},\"82\":{\"h\":\"页面配置\",\"t\":[\"more 注释之前的内容被视为文章摘要。\"]},\"83\":{\"h\":\"页面信息\",\"t\":[\"你可以在 Markdown 的 Frontmatter 中设置页面信息。\",\"作者设置为 Ms.Hope。\",\"写作日期为 2020 年 1 月 1 日\",\"分类为 “使用指南”\",\"标签为 “页面配置” 和 “使用指南”\"]},\"84\":{\"h\":\"页面内容\",\"t\":[\"你可以自由在这里书写你的 Markdown。\",\"提示\",\"你可以将图片和 Markdown 文件放置在一起，但是你需要使用相对链接./ 进行引用。\",\"对于 .vuepress/public 文件夹的图片，请使用绝对链接 / 进行引用。\",\"主题包含了一个自定义徽章可以使用:\",\"文字结尾应该有深蓝色的 徽章文字 徽章。 \"]},\"85\":{\"h\":\"页面结构\",\"t\":[\"此页面应当包含:\",\"路径导航\",\"标题和页面信息\",\"TOC (文章标题列表)\",\"贡献者、更新时间等页面元信息\",\"评论\",\"导航栏\",\"侧边栏\",\"页脚\",\"返回顶部按钮\",\"你可以通过主题选项和页面 Frontmatter 自定义它们。\"]},\"86\":{\"c\":[\"使用指南\"]},\"87\":{\"c\":[\"页面配置\",\"使用指南\"]},\"88\":{\"h\":\"Markdown 测试\"},\"89\":{\"h\":\"提示容器\"},\"90\":{\"h\":\"信息容器\",\"t\":[\"::: info 自定义标题 信息容器，包含 `代码` 与 [链接](#提示容器)。 ```js const a = 1; ``` ::: \",\"自定义标题\",\"信息容器，包含 代码 与 链接。\",\"const a = 1; \"]},\"91\":{\"h\":\"提示容器\",\"t\":[\"::: tip 自定义标题 提示容器 ::: \",\"自定义标题\",\"提示容器\"]},\"92\":{\"h\":\"警告容器\",\"t\":[\"::: warning 自定义标题 警告容器 ::: \",\"自定义标题\",\"警告容器\"]},\"93\":{\"h\":\"危险容器\",\"t\":[\"::: caution 自定义标题 危险容器 ::: \",\"自定义标题\",\"危险容器\"]},\"94\":{\"h\":\"重要容器\",\"t\":[\"::: important 重要信息 ::: \",\"重要\",\"重要信息\"]},\"95\":{\"h\":\"详情容器\",\"t\":[\"::: details 自定义标题 详情容器 ::: \",\"自定义标题\",\"详情容器\"]},\"96\":{\"h\":\"选项卡\",\"t\":[\"::: code-tabs @tab pnpm ```bash pnpm add -D vuepress-theme-hope ``` @tab yarn ```bash yarn add -D vuepress-theme-hope ``` @tab:active npm ```bash npm i -D vuepress-theme-hope ``` ::: \"]},\"97\":{\"h\":\"对齐\",\"t\":[\"::: center 我是居中的 ::: ::: right 我在右对齐 ::: \",\"我是居中的\",\"我在右对齐\"]},\"98\":{\"h\":\"属性支持\"},\"99\":{\"h\":\"id\",\"t\":[\"一个拥有 ID 的 **单词**{#word}。 \",\"一个拥有 ID 的 单词。\",\"\\\\\",\"\\\\\",\"\\\\\",\"\\\\\",\"<a href=\\\"#word\\\">跳转单词</a> \",\"跳转单词\"]},\"100\":{\"h\":\"脚注\",\"t\":[\"此文字有脚注[1].\",\"\\\\\",\"\\\\\",\"\\\\\"]},\"101\":{\"h\":\"任务列表\",\"t\":[\" 计划1\",\" 计划二\",\"- 查看详情\",\"这是脚注内容 ↩︎\"]},\"102\":{\"c\":[\"使用指南\"]},\"103\":{\"c\":[\"Markdown\"]},\"104\":{\"h\":\"数学\"},\"105\":{\"h\":\"\"},\"106\":{\"h\":\"樱桃\"},\"107\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"108\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"109\":{\"c\":[\"樱桃\"]},\"110\":{\"c\":[\"红\",\"小\",\"圆\"]},\"111\":{\"h\":\"火龙果\"},\"112\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"113\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"114\":{\"c\":[\"火龙果\",\"水果\"]},\"115\":{\"c\":[\"红\",\"大\"]},\"116\":{\"h\":\"草莓\"},\"117\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"118\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"119\":{\"c\":[\"水果\",\"草莓\"]},\"120\":{\"c\":[\"红\",\"小\"]},\"121\":{\"h\":\"番茄\",\"t\":[\"本文摘要\"]},\"122\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"123\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"124\":{\"c\":[\"蔬菜\"]},\"125\":{\"c\":[\"红\",\"圆\"]},\"126\":{\"h\":\"数组\"},\"127\":{\"h\":\"分发饼干\",\"t\":[\"455. 分发饼干 - 力扣（LeetCode）\"]},\"128\":{\"h\":\"排序+贪心法+双指针\",\"t\":[\"代码随想录 (programmercarl.com)\",\"为了满足更多的小孩，就不要造成饼干尺寸的浪费。\",\"大尺寸的饼干既可以满足胃口大的孩子也可以满足胃口小的孩子，那么就应该优先满足胃口大的。\",\"这里的局部最优就是大饼干喂给胃口大的，充分利用饼干尺寸喂饱一个，全局最优就是喂饱尽可能多的小孩。\",\"可以尝试使用贪心策略，先将饼干数组和小孩数组排序。\",\"然后从后向前遍历小孩数组，用大饼干优先满足胃口大的，并统计满足小孩数量。\",\"如图：\",\"img\",\"这个例子可以看出饼干9只有喂给胃口为7的小孩，这样才是整体最优解，并想不出反例，那么就可以撸代码了。\"]},\"129\":{\"h\":\"代码\",\"t\":[\"// 版本一 // 时间复杂度：O(nlogn) // 空间复杂度：O(1) class Solution { public: int findContentChildren(vector<int>& g, vector<int>& s) { sort(g.begin(), g.end()); sort(s.begin(), s.end()); int index = s.size() - 1; // 饼干数组的下标 int result = 0; for (int i = g.size() - 1; i >= 0; i--) { // 遍历胃口 if (index >= 0 && s[index] >= g[i]) { // 遍历饼干 result++; index--; } } return result; } }; \",\"从代码中可以看出我用了一个index来控制饼干数组的遍历，遍历饼干并没有再起一个for循环，而是采用自减的方式，这也是常用的技巧。\",\"有的同学看到要遍历两个数组，就想到用两个for循环，那样逻辑其实就复杂了\"]},\"130\":{\"h\":\"注意事项\",\"t\":[\"注意版本一的代码中，可以看出来，是先遍历的胃口，在遍历的饼干，那么可不可以 先遍历 饼干，在遍历胃口呢？\",\"其实是不可以的。\",\"外面的for 是里的下标i 是固定移动的，而if里面的下标 index 是符合条件才移动的。\",\"如果 for 控制的是饼干， if 控制胃口，就是出现如下情况 ：\",\"img\",\"if 里的 index 指向 胃口 10， for里的i指向饼干9，因为 饼干9 满足不了 胃口10，所以 i 持续向前移动，而index 走不到s[index] >= g[i] 的逻辑，所以index不会移动，那么当i 持续向前移动，最后所有的饼干都匹配不上。\",\"所以 一定要for 控制 胃口，里面的if控制饼干。\"]},\"131\":{\"h\":\"其他\",\"t\":[\"也可以换一个思路，小饼干先喂饱小胃口\",\"class Solution { public: int findContentChildren(vector<int>& g, vector<int>& s) { sort(g.begin(),g.end()); sort(s.begin(),s.end()); int index = 0; for(int i = 0; i < s.size(); i++) { // 饼干 if(index < g.size() && g[index] <= s[i]){ // 胃口 index++; } } return index; } }; \"]},\"132\":{\"h\":\"有效的山脉数组\"},\"133\":{\"h\":\"寻找数组的中心下标\",\"t\":[\"[数组]\",\"力扣题目链接(opens new window)a\"]},\"134\":{\"h\":\"按奇偶排序数组II\",\"t\":[\"922. 按奇偶排序数组 II - 力扣（LeetCode）\",\"给定一个非负整数数组 A， A 中一半整数是奇数，一半整数是偶数。\",\"对数组进行排序，以便当 A[i] 为奇数时，i 也是奇数；当 A[i] 为偶数时， i 也是偶数。\",\"你可以返回任何满足上述条件的数组作为答案。\",\"示例：\",\"输入：[4,2,5,7]\",\"输出：[4,5,2,7]\",\"解释：[4,7,2,5]，[2,5,4,7]，[2,7,4,5] 也会被接受。\",\"优化版本\",\"class Solution { public: vector<int> sortArrayByParityII(vector<int>& A) { vector<int> result(A.size()); int evenIndex = 0; // 偶数下标 int oddIndex = 1; // 奇数下标 for (int i = 0; i < A.size(); i++) { if (A[i] % 2 == 0) { result[evenIndex] = A[i]; evenIndex += 2; } else { result[oddIndex] = A[i]; oddIndex += 2; } } return result; } }; \",\"空间复杂度o(1)\",\"class Solution { public: bool validMountainArray(vector<int>& arr) { int index=0; for(int i=1;i<arr.size();i++){ if(arr[i]==arr[i-1])return false; if(arr[i]>arr[i-1]){ index++; } else{ break; } } cout<<index<<endl; //index==0表明arr[1]<arrp[0]导致推出循环 //index=arr.size()-1;一直到最后也没有找到index if(index==0||index==arr.size()-1){ return false; } for(int i=index+1;i<arr.size();i++){ if(arr[i]>=arr[i-1])return false; } return true; } }; \"]},\"135\":{\"h\":\"旋转数组\",\"t\":[\"189. 轮转数组 - 力扣（LeetCode）\"]},\"136\":{\"h\":\"使用额外的空间\",\"t\":[\"class Solution { public: void rotate(vector<int>& nums, int k) { vector<int> temp=nums; int n=k%nums.size(); for(int i=0;i<nums.size();i++){ int index=(i+n)%(nums.size()); nums[index]=temp[i]; } return ; } }; \"]},\"137\":{\"h\":\"数组反转\",\"t\":[\"class Solution { public: void rotate(vector<int>& nums, int k) { if(nums.size()<=1)return; k=k%nums.size(); reverse(nums.begin(),nums.end()); reverse(nums.begin(),nums.begin()+k); reverse(nums.begin()+k,nums.end()); } }; \"]},\"138\":{\"h\":\"区间问题\"},\"139\":{\"h\":\"插入区间\",\"t\":[\"给你一个 无重叠的 *，*按照区间起始端点排序的区间列表。\",\"在列表中插入一个新的区间，你需要确保列表中的区间仍然有序且不重叠（如果有必要的话，可以合并区间）\",\"示例 1：\",\"输入：intervals = [[1,3],[6,9]], newInterval = [2,5] 输出：[[1,5],[6,9]] \",\"示例 2：\",\"输入：intervals = [[1,2],[3,5],[6,7],[8,10],[12,16]], newInterval = [4,8] 输出：[[1,2],[3,10],[12,16]] 解释：这是因为新的区间 [4,8] 与 [3,5],[6,7],[8,10] 重叠。 \",\"示例 3：\",\"输入：intervals = [], newInterval = [5,7] 输出：[[5,7]] \",\"示例 4：\",\"输入：intervals = [[1,5]], newInterval = [2,3] 输出：[[1,5]] \",\"示例 5：\",\"输入：intervals = [[1,5]], newInterval = [2,7] 输出：[[1,7]] \"]},\"140\":{\"h\":\"模拟法\",\"t\":[\"class Solution { public: vector<vector<int>> insert(vector<vector<int>>& intervals, vector<int>& newInterval) { int left=newInterval[0]; int right=newInterval[1]; bool placed=false; vector<vector<int>> res; for(const auto interval:intervals){ if(placed){ res.push_back(interval); continue; } if(interval[1]<left){//interval在左边，不用管，直接加入 res.push_back(interval); } else if(interval[0]>right){ res.push_back({left,right}); placed=true; res.push_back(interval); } else{//有重叠，开始合并 left=min(left,interval[0]); right=max(right,interval[1]); } } if(!placed){ res.push_back({left,right}); } return res; } }; \"]},\"141\":{\"h\":\"环形数组\",\"t\":[\"环形子数组的最大和\",\"189. 轮转数组 - 力扣（LeetCode）\"]},\"142\":{\"h\":\"矩阵\"},\"143\":{\"h\":\"螺旋矩阵\"},\"144\":{\"h\":\"螺旋矩阵 II\"},\"145\":{\"h\":\"旋转图像\"},\"146\":{\"h\":\"矩阵置零\"},\"147\":{\"h\":\"扑克牌中的顺子\",\"t\":[\"剑指 Offer 61. 扑克牌中的顺子 - 力扣（LeetCode）、\"]},\"148\":{\"h\":\"数据结构与算法\"},\"149\":{\"h\":\"目录\",\"t\":[\"数组\",\"字符串\"]},\"150\":{\"h\":\"字符串\"},\"151\":{\"h\":\"数学基础\"},\"152\":{\"h\":\"目录\",\"t\":[\"线性代数.md\",\"微积分.md\",\"概率论.md\",\"优化.md\"]},\"153\":{\"h\":\"线性代数\",\"t\":[\"线性代数主要包含向量、向量空间（或称线性空间）以及向量的线性变换和有限维的线性方程组.\"]},\"154\":{\"h\":\"向量和向量空间\"},\"155\":{\"h\":\"向量\",\"t\":[\"标量 (Scalar) 是一个实数, 只有大小, 没有方向. 标量一般用斜体小写英文字母 来表示. 向量 (Vector) 是由一组实数组成的有序数组, 同时具有大小和方向. 一个 维向量 是由 个有序实数组成, 表示为\",\"其中 称为向量 的第 个分量, 或第 维. 向量符号一般用黑斜体小写英文字母 , 或小写希腊字母 等来表示.\"]},\"156\":{\"h\":\"向量空间\"},\"157\":{\"h\":\"介绍\"},\"158\":{\"h\":\"容器\"},\"159\":{\"h\":\"信息容器\",\"t\":[\"::: info 自定义标题 信息容器，包含 `代码` 与 [链接](#提示容器)。 ```js const a = 1; ``` ::: \",\"自定义标题\",\"信息容器，包含 代码 与 链接。\",\"const a = 1; \"]},\"160\":{\"h\":\"提示容器\",\"t\":[\"::: tip 自定义标题 提示容器 ::: \",\"自定义标题\",\"提示容器\"]},\"161\":{\"h\":\"警告容器\",\"t\":[\"::: warning 自定义标题 警告容器 ::: \",\"自定义标题\",\"警告容器\"]},\"162\":{\"h\":\"危险容器\",\"t\":[\"::: caution 自定义标题 危险容器 ::: \",\"自定义标题\",\"危险容器\"]},\"163\":{\"h\":\"详情容器\",\"t\":[\"::: details 自定义标题 详情容器 ::: \",\"自定义标题\",\"详情容器\"]},\"164\":{\"h\":\"选项卡\",\"t\":[\"::: code-tabs @tab pnpm ```bash pnpm add -D vuepress-theme-hope ``` @tab yarn ```bash yarn add -D vuepress-theme-hope ``` @tab:active npm ```bash npm i -D vuepress-theme-hope ``` ::: \"]},\"165\":{\"h\":\"对齐\",\"t\":[\"::: center 我是居中的 ::: ::: right 我在右对齐 ::: \",\"我是居中的\",\"我在右对齐\"]},\"166\":{\"h\":\"属性支持\"},\"167\":{\"h\":\"id\",\"t\":[\"一个拥有 ID 的 单词。\",\"\\\\\",\"\\\\\",\"\\\\\",\"\\\\\",\"跳转单词\"]},\"168\":{\"h\":\"脚注\",\"t\":[\"此文字有脚注[1].\",\"\\\\\",\"\\\\\",\"\\\\\"]},\"169\":{\"h\":\"任务列表\",\"t\":[\" 计划1\",\" 计划二\",\"- 查看详情\",\"这是脚注内容 ↩︎\"]},\"170\":{\"h\":\"神经微分方程\",\"t\":[\"绪论.md\",\"神经常微分方程.md\",\"连续归一化流.md\",\"不规则序列建模.md\"]},\"171\":{\"h\":\"绪论\",\"t\":[\"介绍\"]},\"172\":{\"h\":\"概率图\",\"t\":[\"概率图模型（Probabilistic Graphical Model，PGM），简称图模型（Graphical Model，GM），是指一种用图结构来描述多元随机变量之间条件独立关系的概率模型，从而给研究高维空间中的概率模型带来了很大的便捷性．\",\"对于一个 维随机向量 , 其联合概率为高维空间中的分布, 一般难以直接建模. 假设每个变量为离散变量并有 个取值, 在不作任何独立假设条件下, 则需要 个参数才能表示其概率分布. 当 时, 参数量约为 , 远远超出了目前计算机的存储能力.\",\"一种有效减少参数量的方法是独立性假设. 一个 维随机向量 的联合概率分解为 个条件概率的乘积,\",\"其中 表示变量 的取值. 如果某些变量之间存在条件独立, 其参数量就可以大幅减少.\",\"假设有四个二值变量 , 在不知道这几个变量依赖关系的情况下, 可以用一个联合概率表来记录每一种取值的概率 , 共需要 个参数. 假设在已知 时, 和 独立, 即有\",\"在已知 和 时, 也和 独立, 即有\",\"那么其联合概率 可以分解为\",\"即 4 个局部条件概率的乘积. 如果分别用 4 个表格来记录这 4 个条件概率的话, 只需要 个独立参数，计算过程如下：\",\"计算过程：\",\"我们将分别计算每个条件概率所需的参数数量，并将它们相加以得到总数。首先，让我们确定每个条件概率所需的参数。\",\": 这是一个二值变量，所以它可以取两个值（比如0或1）。但是，由于概率总和必须为1，我们只需要知道其中一个值（例如），就可以推断出另一个值（）。因此，只需要1个参数。\",\": 这是一个条件概率，也是二值变量，而且它的概率依赖于的值。对于的每个值，都有一个概率分布，所以我们需要2个值（和）来描述这个条件概率。但是，对于每个的值，只需要知道的一个值的条件概率，因为另一个可以通过1减去已知的条件概率来得到。所以，需要2个参数。\",\": 这个条件概率与类似，因为也是二值变量，并且它的概率只依赖于的值。因此，也需要2个参数。\",\": 这是一个条件概率，的概率依赖于和的组合。由于和都是二值变量，所以有4种组合（00、01、10、11）。对于每种组合，我们需要知道的一个值的概率，因为另一个值的概率可以通过1减去已知的概率来得到。因此，需要4个参数。\",\"现在，我们将这些参数加起来得到总数：,所以，总共需要9个参数来描述这个系统的联合概率分布。\",\"当概率模型中的变量数量比较多时, 其条件依赖关系也比较复杂. 我们可以使用图结构的方式将概率模型可视化, 以一种直观、简单的方式描述随机变量之间的条件独立性, 并可以将一个复杂的联合概率模型分解为一些简单条件概率模型的组合. 图11.1给出了上述例子中 4 个变量之间的条件独立性的图形化描述. 图中每个节点表示一个变量, 每条连边表示变量之间的依赖关系.\",\"变量 之间条件独立性的图形化表示\"]},\"173\":{\"h\":\"图模型的基本问题\",\"t\":[\"图模型有三个基本问题：\",\"表示问题：对于一个概率模型，如何通过图结构来描述变量之间的依\",\"赖关系．\",\"学习问题：图模型的学习包括图结构的学习和参数的学习．在本章中，\",\"我们只关注在给定图结构时的参数学习，即参数估计问题．\",\"推断问题：在已知部分变量时，计算其他变量的条件概率分布．\"]},\"174\":{\"h\":\"图模型与机器学习\",\"t\":[\"很多机器学习模型都可以归结为概率模型，即建模输入和输出之间的条件概率分布．因此，图模型提供了一种新的角度来解释机器学习模型，并且这种角度有很多优点，比如了解不同机器学习模型之间的联系，方便设计新模型等．在机器学习中，图模型越来越多地用来设计和分析各种学习算法．\"]},\"175\":{\"h\":\"本章目录\",\"t\":[\"模型表示\"]},\"176\":{\"h\":\"资料\",\"t\":[\"机器学习-白板推导系列(九)-概率图模型基础_哔哩哔哩_bilibili\",\"机器学习-白板推导系列(九)-概率图模型基础笔记 - 知乎 (zhihu.com)\"]},\"177\":{\"h\":\"模型表示\",\"t\":[\" headerDepth: 2 sidebar: heading \",\"图由一组节点和节点之间的边组成．在概率图模型中，每个节点都表示一个随机变量（或一组随机变量），边表示这些随机变量之间的概率依赖关系．\",\"常见的概率图模型可以分为两类: 有向图模型和无向图模型.\",\"有向图模型使用有向非循环图 (Directed Acyclic Graph, DAG) 来描述变量之间的关系. 如果两个节点之间有连边, 表示对应的两个变量为因果关系,即不存在其他变量使得这两个节点对应的变 量条件独立.\",\"无向图模型使用无向图 (Undirected Graph) 来描述变量之间的关系.每条边代表两个变量之间有概率依赖关系, 但是并不一定是因果关系.\",\"图1给出了两个代表性图模型 (有向图和无向图) 的示例, 分别表示了四个变量 之间的依赖关系. 图中带阴影的节点表示可观测到的变量, 不带阴影的节点表示隐变量,连边表示两变量间的条件依赖关系.\",\"有向图和无向图示例\"]},\"178\":{\"h\":\"有向图模型\",\"t\":[\"有向图模型（Directed Graphical Model），也称为贝叶斯网络（BayesianNetwork）或信念网络（Belief Network，BN），是一类用有向图来描述随机向量概率分布的模型．\",\"下图中 表示 的父类：\",\"img\",\"定义（贝叶斯网络）\",\"对于一个 维随机向量 和一个有 个节点的有向非循环图 中的每个节点都对应一个随机变量, 每个连接 表示两个随机变量 和 之间具有非独立的因果关系. 令 表示变量 的所有父节点变量集合, 表示每个随机变量的局部条件概率分布 ( Local Conditional Probability Distribution). 如果 的联合概率分布可以分解为每个随机变量 的局部条件概率的连乘形式, 即\",\"那么 构成了一个贝叶斯网络.\",\"因此可以根据有向图写出因子分解的结果。以下，有三种情况：\",\"共因关系（tail2tail）\",\"img\",\"可以写出其因子分解的结果：\",\"同时我们可以根据链式法则写出联合概率:\",\"因此:\",\"所以可知: 与 独立 (在 已知的条件下)\",\"若 被观测，则路径被堵塞，即 与 独立 \",\"image-20231216143312896\",\"注意\",\"此规则并不是强加上去的，是我们用概率图的因子分解表示联合概率后，本身存在的现象，我们在证明此现象存在后，总结出的规律，根据此规律可以直接看图得出结论。\",\"间接因果关系（head2tail）\",\"img\",\"如图可以写出其因子分解的结果：\",\"同时我们可以根据链式法则写出联合概率:\",\"因此:\",\"所以可知： 与 独立 (在 已知的条件下) 从 的角度来看，是 的头和 的尾巴相连，所以称为head-to-tail\",\"image-20231216143808424\",\"共果关系（head2head)\",\"img\",\"如图可以写出其因子分解的结果:\",\"同时我们可以根据链式法则写出联合概率:\",\"因此:\",\"所以可知: 与 独立 (在 不知的情况下)\",\"由此，我们可以总结一个规律：\",\"从 的角度来看，是 的头和 的头相连，所以称为head-to-head 默认情况下， ，路径是阻塞的\",\"特殊情况：若 被观测，则路径是通的， 和 不独立\",\"这种情况中，在给定 时， 和 反而不独立了，与前两种情况刚好相反，我们举个例子说明一下:\",\"局部马尔可夫性质\",\"局部马尔可夫性质 对一个更一般的贝叶斯网络, 其局部马尔可夫性质为: 每个随机变量在给定父节点的情况下, 条件独立于它的非后代节点.\",\"其中 为 的非后代变量.\"]},\"179\":{\"h\":\"常见的有向图模型\",\"t\":[\"很多经典的机器学习模型可以使用有向图模型来描述，比如朴素贝叶斯分类器、隐马尔可夫模型、深度信念网络等．\"]},\"180\":{\"h\":\"Sigmoid信念网络\",\"t\":[\"为了减少模型参数，可以使用参数化模型来建模有向图模型中的条件概率分布．一种简单的参数化模型为Sigmoid信念网络[1]\",\"Sigmoid 信念网络 (Sigmoid Belief Network, SBN) 中的变量取值为 .对于变量 和它的父节点集合 , 其条件概率分布表示为\",\"其中 是 Logistic 函数, 是可学习的参数. 假设变量 的父节点数量为 ,如果使用表格来记录条件概率需要 个参数, 如果使用参数化模型只需要 1 个参数. 如果对不同的变量的条件概率都共享使用一个参数化模型, 其参数数量又可以大幅减少.\",\"值得一提的是, Sigmoid 信念网络与 Logistic 回归模型都采用 Logistic 函数来计算条件概率. 如果假设 Sigmoid 信念网络中只有一个叶子节点, 其所有的父节点之间没有连接, 且取值为实数, 那么 Sigmoid 信念网络的网络结构和 Logistic 回归模型类似, 如图11.4所示. 但是, 这两个模型的区别在于, Logistic 回归模型中的 作为一种确定性的参数, 而非变量. 因此, Logistic 回归模型只建模条件概率 , 是一种判别模型; 而 Sigmoid 信念网络建模联合概率 , 是一种生成模型.\",\"Sigmoid信念网络和Logistic回归模型的比较\"]},\"181\":{\"h\":\"朴素贝叶斯分类器\",\"t\":[\"朴素贝叶斯 ( Naive Bayes, NB) 分类器是一类简单的概率分类器, 在强 (朴素 ) 独立性假设的条件下运用贝叶斯公式来计算每个类别的条件概率. 给定一个有 维特征的样本 和类别 , 类别 的条件概率为\",\"其中 为概率分布的参数. 在朴素贝叶斯分类器中, 假设在给定 的情况下, 之间是条件独立的, 即 . 下图给出了朴素贝叶斯分类器的图模型表示.\",\"image-20231216150648772\",\"条件概率分布 可以分解为\",\"其中 是 的先验概率分布的参数, 是条件概率分布 的参数. 若 为连续值, 可以用高斯分布建模; 若 为离散值, 可以用多项分布建模.\",\"虽然朴素贝叶斯分类器的条件独立性假设太强, 但是在实际应用中, 朴素贝叶斯分类器在很多任务上也能得到很好的结果, 并且模型简单, 可以有效防止过拟合.\"]},\"182\":{\"h\":\"隐马尔可夫模型\",\"t\":[\"隐马尔可夫模型 ( Hidden Markov Model, HMM ) [Baum et al., 1966] 是用来表示一种含有隐变量的马尔可夫过程.\",\"图11.6给出隐马尔可夫模型的图模型表示, 其中 为可观测变量, 为隐变量. 所有的隐变量构成一个马尔可夫链, 每个可观测标量 依赖当前时刻的隐变量 .\",\"隐马尔可夫模型的联合概率可以分解为\",\"为了描述方便, 这里用 表示 .\",\"其中 和 分别为可观测变量和隐变量的取值, 条件概率 称为输出概率, 条件概率 称为转移概率, 和 分别表示两类条件概率的参数.\"]},\"183\":{\"h\":\"无向图模型\",\"t\":[\"无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF）或马尔可夫网络（Markov Network），是一类用无向图来描述一组具有局部马尔可夫性质的随机向量 的联合概率分布的模型．\",\"定义（马尔可夫随机场）\",\"对于一个随机向量 和一个有 个节点的无向图 ( 可以存在循环), 图 中的节点 表示随机变量 . 如果 满足局部马尔可夫性质, 即一个变量 在给定它的邻居的情况下独立于所有其他变量,\",\"其中 为变量 的邻居集合, 为除 外其他变量的集合, 那么 就构成了一个马尔可夫随机场.\",\"向图中的局部马尔可夫性质可以表示为\",\"其中 表示除 和 外的其他变量. 对于图中的 个变量, 根据马尔可夫性质, 可以得到 和 \",\"image-20231216152932251\"]},\"184\":{\"h\":\"无向图模型的概率分解\",\"t\":[\"团\",\"由于无向图模型并不提供一个变量的拓扑顺序, 因此无法用链式法则对 进行逐一分解. 无向图模型的联合概率一般以全连通子图为单位进行分解.无向图中的一个全连通子图, 称为团 (Clique), 即团内的所有节点之间都连边.在下图所示的无向图中共有 7 个团, 包括 , .\",\"在所有团中, 如果一个团不能被其他的团包含, 这 个团就是一个最大团 ( Maximal Clique).\",\"image-20231216153149245\",\"无向图中的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式．\",\"Hammersley-Clifford定理\",\"如果一个分布 满足无向图 中的局部马尔可夫性质, 当且仅当 可以表示为一系列定义在最大团上的非负函数的乘积形式, 即\",\"其中 为 中的最大团集合, 是定义在团 上的势能函数 (Potential Function ), 是配分函数 (Partition Function), 用来将乘积归一化为概率形式:\",\"其中 为随机向量 的取值空间.\",\"Hammersley-Clifford 定理的证明可以参考 [2]．无向图模型与有向图模型的一个重要区别是有配分函数𝑍．配分函数的计算复杂度是指数的，因此在推断和参数学习时都需要重点考虑．\",\"吉布斯分布\",\"公式 中定义的分布形式也称为吉布斯分布（Gibbs Distribution）．根据 Hammersley-Clifford 定理，无向图模型和吉布斯分布是一致的．吉布斯分布一定满足马尔可夫随机场的条件独立性质，并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布．\",\"由于势能函数必须为正,因此我们一般定义为\",\"其中 为能量函数 (Energy Function).\",\"因此,无向图上定义的概率分布可以表示为\",\"这种形式的分布又称为玻尔兹曼分布 (Boltzmann Distribution). 任何一个无向图模型都可以用公式 来表示其联合概率.\"]},\"185\":{\"h\":\"常见的无向图模型\",\"t\":[\"很多经典的机器学习模型可以使用无向图模型来描述，比如对数线性模型（也叫最大熵模型）、条件随机场、玻尔兹曼机、受限玻尔兹曼机等．\"]},\"186\":{\"h\":\"对数线性模型\",\"t\":[\"势能函数一般定义为\",\"其中函数 为定义在 上的特征向量, 为权重向量. 这样联合概率 的对数形式为\",\"其中 代表所有势能函数中的参数 . 这种形式的无向图模型也称为对数线性模型 ( Log-Linear Model) 或最大熵模型 (Maximum Entropy Model) [Berger et al., 1996; Della Pietra et al., 1997]. 图11.8a所示是一个常用的最大熵模型. 如果用对数线性模型来建模条件概率 ,\",\"其中 . 对数线性模型也称为条件最大熵模型或Softmax 回归模型.\"]},\"187\":{\"h\":\"条件随机场\"},\"188\":{\"h\":\"参考\",\"t\":[\"[PII: 0004-3702(92)90065-6 (toronto.edu)](https://www.cs.toronto.edu/~bonner/courses/2016s/csc321/readings/Connectionist learning of belief networks.pdf) ↩︎\",\"Koller D, Friedman N, 2009. Probabilistic graphical models: principles and techniques[M]. MITpress. ↩︎\"]},\"189\":{\"h\":\"对抗攻击\"},\"190\":{\"h\":\"基本概念\",\"t\":[\"深度学习中的神经网络在精心训练后，其分类准确性可以非常出色，但其的鲁棒性却可能很差，可能会轻易被对抗攻击打破。即通过对输入图片进行一个微小的扰动，就可以在几乎肉眼看不出差距的前提下，让神经网络的分类准确率大幅下降。\",\"img\"]},\"191\":{\"h\":\"对抗鲁棒性\",\"t\":[\"【金山文档】 PGD https://kdocs.cn/l/csBKPtHtET4R\"]},\"192\":{\"h\":\"对抗攻击的分类\",\"t\":[\"白箱攻击（white-box attack）：在白箱攻击中攻击者知道目标模型的所有信息，包括模型的训练集、类型、结构以及参数。\",\"黑箱攻击（black-box attack）：在黑箱攻击中，攻击者不知道目标模型的内部细节，只能够观察目标模型对输入样本的输出结果。\",\"定向攻击（target attack）：对于一个多分类网络，把输入分类误判到一个某个特定的错误类别上\",\"非定向攻击（non-target attack）：只需要生成对抗样本，可以引入任意一个错误类别\"]},\"193\":{\"h\":\"FGSM\",\"t\":[\"白盒非指向性\",\"论文地址\",\"对抗样本（三）FGSM | BaiDing's blog (baidinghub.github.io)\",\"对抗攻击篇：FGSM 与 PGD 攻击算法 | Just for Life. (muyuuuu.github.io)\"]},\"194\":{\"h\":\"简介\",\"t\":[\"早期对对抗样本产生的原因的猜测集中于神经网络的非线性性和过拟合, 但是这篇论文证明神经网络的线性性质是造成神经网络具有对抗样本的主要原因. 同时, 该篇论文提出了一个能供更简单与更快速的生成对抗样本的方法。\"]},\"195\":{\"h\":\"对抗样本的线性解释\",\"t\":[\"我们知道，输入图像通常都是8bits的，这也就丟失了输入图像的1/255之间的信息。而如果对抗扰动足够小的话，是会被忽略的，因此作者猜测，是由于模型的线性所导致的。作者通过数学公式来解释。一个网络模型的权重为 \",\"对抗扰动让网络的激励增加了 ，我们只要将 ，就可以最大化的增加模型的激励，当 具有 维，平均权重值为 ，那么激励就会增长 ，但是 却并不会因为维度的增加而增加，这样，当我们增加一个很小的扰动的时候，就会产生很大的改变。这被称为\\\"accidental steganography\\\"，这种隐藏术的意思是，一个线性模型被迫只关注与权重相接近的信号，却会忽略那些权重大但不相关的振幅(像素点)。\",\"上述的解释说明，对一个简单的线性网络来说，如果他的输入有着足够的维度，那么他就会有对抗样本。先前对对抗样本的解释引用了了神经网络的假设特性，例如它们假定的高度非线性性质。我们基于线性的假设更简单，也可以解释为什么 softmax回归容易受到对抗性例子的影响。\"]},\"196\":{\"h\":\"非线性模型的线性扰动\",\"t\":[\"从对抗样本的线性视角来看，我们得出了一个很快的生成对抗样本的方法。我们假设神经网络是十分线性的。\",\"我们已知的一些模型，LSTM、ReLU、maxout网络都是被设计用线性的方式来运作的，所以比较容易优化，而非线性的模型，比如Sigmoid网络，我们会很难优化。但是线性，会让模型更容易受到攻击。\",\"模型的参数设为 记为模型的输入， 记为模型得到的标签， 记为神经网络使用的损失函数，同门可以通过以下的公式来得到对抗扰动:\",\"我们把这个叫做FGSM (fast gradient sign method)\",\"损失函数 衡量了网络预测 时的错误程度，其中 是网络参数， 是真实标签。当我们计算这个损失函数关于输入 的梯度时， 指示了哪个方向的微小变化会导致损失最大的增加。\",\"在机器学习中，梯度的数学定义告诉我们在多维空间中函数增长最快的方向。具体来说，对于一个可微分函数 ，其在点 处的梯度 指向函数值增长最快的方向。这是梯度的基本性质。\",\"现在，我们来形式化这个直觉：\",\"假设我们有一个小的扰动 加到输入 上，损失函数 在 处的一阶泰勒展开大约为：\",\"为了最大化损失增量，我们希望 尽可能大。根据柯西-施瓦茨不等式（Cauchy-Schwarz inequality），两个向量的点积的最大值是当它们是平行时取得的，即：\",\"等号成立当且仅当 是 的正比例，因此，损失增加最快的方向就是梯度的方向。\",\"然而，我们通常希望对输入的扰动 有一个大小限制，以确保扰动是微小的。FGSM 通过选择 来实现这一点，其中 是一个小常数。这样，每个元素的扰动都受到限制，并且整个扰动的 范数不超过 。\",\"因此， 是在给定大小限制下，使得损失函数增加最快的方向。这就是为什么 FGSM 使用这种特定形式的扰动来生成对抗样本的原因。\",\"这个公式是快速梯度符号方法（Fast Gradient Sign Method, 简称 FGSM）的核心，它是一种生成对抗性样本的技术。这个方法由 Ian Goodfellow 等人在 2014 年提出，旨在通过执行单步梯度更新来生成对抗性样本，具体来说是沿着使损失最大化的方向。\",\"在这个公式中：\",\" 是一个小的扰动量，它控制了对抗性扰动的强度。\",\" 是损失函数 关于输入 的梯度，这里 表示模型参数， 表示输入样本， 表示目标输出。\",\" 函数取梯度的符号，为每个元素返回 或 （或 ，如果梯度为零）。\",\"FGSM 的设计基于以下直觉：\",\"梯度方向：损失函数的梯度指向了损失增加最快的方向。在对抗性攻击的背景下，目标是找到一个小的扰动 ，使得当它加到输入样本 上时，会导致模型的损失增加，从而降低模型的性能。\",\"符号函数：使用 函数是为了得到一个大小为 的扰动，而不是直接使用梯度值。这确保了每个元素的扰动都是等量的，并且扰动的 范数（无穷范数，即向量中的最大元素）不超过 。这样的扰动通常很小，对人类的感知影响不大，但足以欺骗神经网络。\",\"效率：FGSM 是一种快速而简单的方法，因为它只需要计算一次输入 的梯度，然后应用符号函数和扰动系数 。这使得 FGSM 成为一种计算高效的对抗性攻击方法，尤其适合于生成大量对抗性样本。\",\"FGSM 生成的对抗性样本可以用来测试模型的鲁棒性或用于对抗性训练，后者是一种通过在训练过程中引入对抗性样本来提高模型鲁棒性的方法。\",\"作者在使用中，使用了 ，在MINST测试集上，对softmax分类器攻击达到了99.9%的攻击成功率，平均置信度为79.3%。使用相同的配置，对maxout网络，能达到89.4%的攻击成功率，平均置信度为97.6%。当使用卷积maxout网络与CIFAR-10数据集时，使用，达到了87.15%的攻击成功率，以及96.6%的平均置信度。同时，作者发现，使用其他的简单的方法也可以产生对抗样本，比如使x在梯度方向上旋转一定的角度，就可以产生对抗样本。\"]},\"197\":{\"h\":\"线性模型的对抗训练与权重衰减的对比研究\"},\"198\":{\"h\":\"PGD\",\"t\":[\"[1706.06083] Towards Deep Learning Models Resistant to Adversarial Attacks (arxiv.org)\"]},\"199\":{\"h\":\"抗扰性验证\",\"t\":[\"【金山文档】 Efficient Neural Network Robustness Certification\"]},\"200\":{\"h\":\"Notation\",\"t\":[\"假设神经网络一共有 层，输入 ,每一层神经元数量为 ,这里 。\",\"第 层到 层的权值矩阵为 ，偏置 。\",\" 表示第 层的激活值，， 其中，， 。\",\"那么对于第 层的第 个神经元，设它的预激活值为 , ， 表示矩阵 的第 行，\",\"让输入 的扰动值，限制在内，当 , let 是预激活值 的上界和下界 i.e. 。\"]},\"201\":{\"h\":\"激活函数的线性上上下界\",\"t\":[\"定义两个线性函数 : ,\",\"使得 其中.\",\" 依赖 and , 也就是说对于不同的 and 可以选择不同的参数。\",\"Also, for ease of exposition, in this paper we restrict . However, Theorem 3.2 can be easily generalized to the case of negative .\"]},\"202\":{\"h\":\"定理中涉及的符号\"},\"203\":{\"h\":\"抗扰性\",\"t\":[\"对抗样本\",\"抗扰性验证\"]},\"204\":{\"h\":\"动力系统\"},\"205\":{\"h\":\"动力系统的稳定性\",\"t\":[\"定义 如果对任意给定的 , 存在 一般与 和 有关), 使当任一 满足\",\"时, 方程组 (6.8) 的由初始条件 确定的解 均有\",\"则称方程组 (6.8) 的零解 为稳定的.\",\"如果零解 稳定, 且存在这样的 使当\",\"时, 满足初始条仵 的解 均有\",\"则称零解 为渐近稳定的.\",\"如果 渐近稳定, 且存在域 , 当且仅当 时满足初始条件 的解 约有 , 则域 称为 (渐近) 稳定域或吸引域. 若稳定域为全空间, 即 , 则称零解 为全局渐近稳定的或简称全局稳定的.\",\"当零解 不是稳定时, 称它是不稳定的. 即是说: 如果对某个给定的 不管 怎样小, 总有一个 满足 , 使由初始条件 所确定的解 , 至少存在某个 。使得\",\"则称方程组 (6.8) 的零解 为不稳定的.\",\"在二维情形零解的稳定形态，在平面上的示意图如下图\",\"零解的稳定形态\"]},\"206\":{\"h\":\"相平面\",\"t\":[\"现在讨论二阶微分方程组\",\"它的解\",\"在以  为坐标的 (欧氏)空间中决定了一条曲线, 这曲线称为积分曲线。假设方程右端的函数满足解的存在唯一性和连续性定理的条件, 例如存在连续偏导数, 此时空间的每一点都有一条且只有一条积分曲线经过\"]},\"207\":{\"h\":\"常微分方程\"},\"208\":{\"h\":\"常微分方程数值解\"},\"209\":{\"h\":\"预备知识\",\"t\":[\"术语截断误差指的是使用被截的即有限的和来近似计算无穷级数的和所产生的误差。\",\"舍入误差是计算器或计算机进行实数计算时所产生的。之所以产生舍人误差是因为机器中进行的算术运算所涉及的数是有限位的，从而导致计算只能用实际数值的近似表示式来完成。在典型的计算机中，仅实数系统的一个相对小的子集用于表示所有的实数。这个子集仅包含了正/负有理数，且存储了小数部分和指数部分。\",\"定义 1.17 假设 表示初始误差, 表示在以后的 步运算之后误差的大小。如果 (这里 是一个不依赖于 的常数), 则误差的增长称为是线性的。如果 (对某个 ), 则误差的增长称为是指数的。\",\"定义 1.18 设 是一个收玫于 0 的已知序列, 收敛于数 。如果存在一个正常数 使得\",\"对大的 成立, 则称 以收玫速度 (此表达式读作 “ 的大 oh”) 收玫于 。记为 \",\"虽然定义 1.18 允许将 与任意序列 进行比较, 但是几乎在每一种情况下都使用\",\"其中 为大于零的某个数。人们通常对于使 成立的最大的 值感兴趣。\",\"初值问题\",\"称为是一个适定的问题,如果:\",\"问题存在一个唯一的解 ;\",\"对任何 , 存在一个正常数 , 使得只要当 是连续的且在 上 时, 就有问题\",\"存在唯一解 , 且\",\"对一切 成立。 由式 所定义的问题称作和原问题 相伴的摄动问题。它假定微分方程有可能有误差 以及初值条件也有可能存在误差 。\",\"因为表示式中的任何舍人误差都使原问题摄动,所以数值方法总与求解摄动问题有关。如果原问题不是适定的，则没有理由期望摄动问题的数值解会精确地近原问题的解。\",\"定理 5.6 假设 。如果 是连续的, 且在 上关于变量 满足 条件, 则初值问题\",\"是适定的。\"]},\"210\":{\"h\":\"Euler法\",\"t\":[\"虽然Euler法的精确性不足以保证它在实际中的使用，但是在分析从它的应用所产生的误差方面它是一个重要的基础。在下面各节所考虑的更精确方法的误差分析按照同样的模式，只不过更复杂一些。\",\"为推导 Euler 法的误差界, 需要两个计算引理。\",\"引理 5.7 对所有 和任何正整数 , 有 。\",\"证明 对 和 , 应用 Taylor 定理得\",\"其中, 位于 和 0 之间。从而,有\",\"又因为 , 所以\",\"定理 5.9 假设 是连续的, 且在\",\"上满足常数为 的 条件, 又假设存在常数 使得\",\"对一切 成立。设 表示初值问题\",\"的唯一解, 是由 Euler 法对某个正整数 产生的近似。则对于 ,有\"]},\"211\":{\"h\":\"Talyot法\",\"t\":[\"定义 5.11 差分法\",\"有局部截断误差\",\"对 成立。 对于 Euler 法,在第 步对问题\",\"的局部截断误差是\",\"image-20231211151256664\"]},\"212\":{\"h\":\"runge-kutta法\",\"t\":[\"image-20231211152044454\",\"image-20231211152029421\",\"image-20231211152930899\",\"​\"]},\"213\":{\"h\":\"苹果 1\"},\"214\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"215\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"216\":{\"c\":[\"苹果\"]},\"217\":{\"c\":[\"红\",\"大\",\"圆\"]},\"218\":{\"h\":\"苹果 2\",\"t\":[\"一个被星标了的苹果文章。\"]},\"219\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"220\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"221\":{\"c\":[\"苹果\"]},\"222\":{\"c\":[\"红\",\"大\",\"圆\"]},\"223\":{\"h\":\"苹果 3\"},\"224\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"225\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"226\":{\"c\":[\"苹果\",\"水果\"]},\"227\":{\"c\":[\"红\",\"大\",\"圆\"]},\"228\":{\"h\":\"苹果 4\"},\"229\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"230\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"231\":{\"c\":[\"苹果\",\"水果\"]},\"232\":{\"c\":[\"红\",\"大\",\"圆\"]},\"233\":{\"h\":\"香蕉 1\"},\"234\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"235\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"236\":{\"c\":[\"香蕉\",\"水果\"]},\"237\":{\"c\":[\"黄\",\"弯曲的\",\"长\"]},\"238\":{\"h\":\"香蕉 2\",\"t\":[\"一个被数字 10 星标了的香蕉文章。\"]},\"239\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"240\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"241\":{\"c\":[\"香蕉\",\"水果\"]},\"242\":{\"c\":[\"黄\",\"弯曲的\",\"长\"]},\"243\":{\"h\":\"香蕉 3\"},\"244\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"245\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"246\":{\"c\":[\"香蕉\"]},\"247\":{\"c\":[\"黄\",\"弯曲的\",\"长\"]},\"248\":{\"h\":\"香蕉 4\"},\"249\":{\"h\":\"标题 2\",\"t\":[\"这里是内容。\"]},\"250\":{\"h\":\"标题 3\",\"t\":[\"这里是内容。\"]},\"251\":{\"c\":[\"香蕉\"]},\"252\":{\"c\":[\"黄\",\"弯曲的\",\"长\"]},\"253\":{\"h\":\"连续归一化流\",\"t\":[\"标准化流Normalizing flows (NF) 是一系列高维数据上灵活可重参数化概率分布的方法。它通过构造一系列可逆映射（通常由可逆神经网络参数化）将将任意复杂的数据分布变换为一个基本的简单分布（如单高斯分布、均匀分布等），通过巧妙设计的模型结构，模型可以对数据样本进行精确的最大似然估计,最终分布的概率密度由变量变换公式给出。\"]},\"254\":{\"h\":\"Preliminaries\",\"t\":[\"重参数化技巧 - 知乎 (zhihu.com)\"]},\"255\":{\"h\":\"重参数化技巧\",\"t\":[\"重参数化技巧，就是从一个分布  中进行采样，而该分布是带有参数  的，如果直接进行采样 (采样动作是离散的，其不可微），是没有梯度信息的，那么在BP反向传播的时候就不会对参数梯度进行更新。重参数化技巧可以保证我们从  进行采样，同时又能保留梯度信息。\"]},\"256\":{\"h\":\"神经常微分方程\",\"t\":[\"神经常微分方程（简称：NeuralODE）是一种通过使用神经网络参数化向量场来结合常微分方程和神经网络的一种全新的深度学习模型。在2018年首次被提出和使用[1]，它将传统的有限层神经网络架构转变为参数共享的无限层神经网络架构，弥合了深度学习和动态系统的差距。NODE从网络架构，训练方法，超参数选择，表示能力等均和传统的神经网络例如CNN,MLP，RNN等有所不同。\",\"本章首先给出神经常微分方程(以后简称NODE)的定义，NODE模型的思想来源。然后介绍针对NODE的一种全新的反向传播方法-adjoint sensitivity 方法和相应的更广义的证明，对于NODE的表示能力用严格的数学理论进行详细论述，同时对训练用到的超参数的选择，网络架构的选取进行讨论。\",\"预备知识.md\",\"定义.md\",\"表示和逼近能力.md\",\"优化算法.md\",\"设计网络架构.md\",\"[1806.07366] Neural Ordinary Differential Equations (arxiv.org)↩︎\"]},\"257\":{\"h\":\"优化算法\"},\"258\":{\"h\":\"自适应检查点伴随法\",\"t\":[\"我们证明了其性能较差的一个原因是现有的梯度估计方法的不准确性：伴随方法在反模态积分中存在数值误差；\",\"由于正模和反模轨迹被视为两个独立的ivp，它们并不准确相等，导致梯度估计的误差\"]},\"259\":{\"c\":[\"神经微分方程\"]},\"260\":{\"h\":\"定义\",\"t\":[\"首先给出NODE的定义： 设有如下高阶常微分方程和初始条件：\",\"定义\",\"其中是神经网络架构（比如全连接神经网络），称该微分方程为神经常微分方程，简称NeuralODE。在上关于 是连续的， 是该网络架构的参数，根据picard存在定理， 初值问题有唯一解，当固定时,函数以作为特征输入可以看成一个神经网络，称为终止时间,表示网络的深度。\",\"这里 假设全局 关于 是连续是非常合理的，因为最常见和有效的激活函数和网络例如ReLUs，CNN，max,全连接网络等都是全局连续的。\",\"Lemma 7.1 Suppose is composed of a finite number of ReLU activations and linear transforms,\",\"假设 由有限的激活函数为ReLU的仿射层组成，其中仿射层有界 ,即：\",\"那么初值问题 有唯一解。\",\"证明： 不依赖与 ，所以关于 连续，ReLU（或者其他激活函数例如sigmoid）是一制度\",\"回顾下一个resnet网络架构中的resnet块：\",\"函数是带参数的神 经网络函数，是网络层数。 将区间分割为为单位,通过使用euler法来可以求得的每个时刻， 那么就有\",\"观察和可以发现每个resnet块类似于欧拉法求数值解微分方程时步长为1的情形（）。\",\"例如：一个resnet块具体定义为\",\"Consider now the Neural ODE\",\"在常规神经网络中，我们从输出出发得到隐状态层(假设是层神经网络)， 每层参数化，参数量随着层数的增加而增加。 所以若我们在renet层级间加入更多的层，且最终趋向于添加了无穷层时，残差神经网络架构就与欧拉法解方程统一起来：resnet前向传播可以看做时欧拉法解神经微分方程，而神经微分方程就是参数共享的resnet网络模型的连续化。 后面还会从rnn的角度和ode进行统一建模，其实目前大部分有效的流行的深度学习框架都类似于微分方程，若干个世纪以来，微分方程一直被用来做应用建模。\",\"目前可以看出研究和使用node的一个好处在于ode的理论优势，数学领域，对ode的研究不管是理论还是数值分析，建模方法，训练思路都是丰富且先进，可以帮助我们更好的进行深度学习的研究。 由于ode的求解比较难，虽然可以使用ode求解器，但是由于维度巨大（例如一个1080p像素点有个），计算的时间复杂仍然很高，一般将node作为深度学习网络框架中的一部分，node的输入是被前神经网络处理过的维度较低的数据，同时对node的输出再进行处理，例如添加一层全连接层或者非线性层，这也大幅提高NeuralODE的表达能力。 下面给出更一般形式的含有node的网络架构：\",\"注意\",\"虽然NODE中的输入和输出是固定的维度，但是网络架构是任意的，可以出现更高维度。在后续会深入讨论网络架构的选择和设计。\"]},\"261\":{\"h\":\"神经微分方程的稳定性\",\"t\":[\"神经微分方程稳定性概念\"]},\"262\":{\"h\":\"网络设计\"},\"263\":{\"h\":\"增维的的NODE\",\"t\":[\"再 表示和逼近.md 中提到过对输入进行维度增加可以提高模型的表达能力，再 表示和逼近.md 中采用的方法非常简单：将输入的维度增加一倍 ，然后在额外的维度上补0， 这个理论上可以表示任何同胚映射，但是它也有很大的缺陷，在 表示和逼近.md 中已经表述过。下面子节是其他的用于增维的方法来解决 表示和逼近.md 中描述的缺陷。\"]},\"264\":{\"h\":\"对输入做仿射变换\",\"t\":[\"对于给定的初值 , 设 是一个含参的仿射变换，那么将 作为微分方程的初值，然后的到 作为NODE的输出，其中参数是需要学习的。\",\"采用仿射的目的是 提高模型的表达能力的同时，做到高效的训练，不需要增加一倍的维度，更具体点可以设 ,这就更进一步降低参数量了,同时也保证了前 维的结构。当然这种增强破坏了NODE的双射的性质，那么下一章节的连续归一化流就不能使用，因为它要求可逆。\",\"Lifting into a higher-dimensional space may be regarded as a relaxation of the Markov property[1]. For then the output does not completely determine . In contrast does determine . (Whether is the output of an unaugmented neural or the latent value of an augmented neural ODE.)\"]},\"265\":{\"h\":\"随机化额外维度的初始值\",\"t\":[\"也可以使用服从某个随机分布（正太分布或区间分布）的随机变量来初始化额外维度的初始值，和是直接设为0相比，他的优势如下\",\"在数学上阐述为什么使用随机噪声初始化增广维度比使用零初始化更有利的原因可以从以下几个角度来考虑：\",\"非线性系统的敏感性：对于非线性系统，初始条件的微小变化可能会导致长期行为的显著不同。这是混沌理论的一个关键观点，即初始条件的微小扰动可能导致完全不同的轨迹。在数学上，这可以通过Lyapunov指数来量化，它度量了相邻轨迹随时间分离的速率。随机噪声可以使得系统从一系列不同的初始条件开始演化，从而能够探索状态空间中的更多区域。\",\"打破对称性：如果增广的维度被初始化为零，它们的行为会是对称的，因为在没有额外信息的情况下，它们会接收到相同的梯度更新。这在数学上意味着，如果我们有一个向量场 ，那么对于所有的初始点 ，如果它们的增广部分是相同的，那么它们的轨迹也将是相同的。随机噪声打破了这种对称性，使得即使是相同的原始输入，也能够在增广空间中产生不同的轨迹。\",\"增加状态空间的覆盖：从概率论的角度来看，随机噪声允许系统在整个状态空间中以某种概率分布进行采样。如果增广维度总是初始化为零，那么系统的状态将始终局限于一个低维的子空间，从而限制了网络能够学习的功能。随机噪声初始化允许网络在训练过程中探索更多的状态组合。\",\"局部最小和鞍点：在优化理论中，初始化可以极大地影响优化算法的收敛性。如果所有的路径都从相同的点开始，那么它们可能会陷入相同的局部最小或鞍点。通过随机初始化，我们可以提高找到全局最小或更好局部最小的机会，因为不同的路径可能会避开某些不良的局部最小。\",\"正则化效果：在统计学习理论中，添加随机性可以看作是一种隐式的正则化。这有助于防止过拟合，因为它限制了模型在训练数据上的完美拟合能力，从而提高了模型在未见数据上的泛化能力。\",\"尽管从理论上有这些考虑，但在实际操作中，是否使用随机噪声以及具体的噪声水平通常是基于经验和实验调整的。一些问题可能会从零初始化中受益，而其他问题则可能需要随机噪声来提高性能。因此，实践者通常会尝试不同的初始化策略，以找到最适合他们特定问题的方法。\"]},\"266\":{\"h\":\"分段的NODE\",\"t\":[\"可以让一个NODE由若干的不同范围的的NODE表示,例如：\",\"其中参数 , s都表示不同的网络，但是为了表示，研究和训练的方便，所有的 的基本架构是一样的, 唯一的区别就是依赖的向量 。 关于这种形式的微分方程，训练方式有两种：\",\"调用一次ODESolver直接在 上计算，那么如果采用的是自适应步长的ODE求解器，那么需要提前告知分段点，否则求解器会在分段点减速再缓慢返回。\",\"调用次ODESolver，分别计算在每个求解相应的ODE，这会需要额外的 来存储前向计算中的 用来做反向传播。\",\"根据灵敏度公式，他的参数梯度如下：\",\"Proof. The proof follows from the one of Theorems 1 and 1 by recalling the solution of the stacked neural ODEs:\",\"We can recover a relation similar to (12)\",\"Since\",\"we have\",\"which leads to the result by assuming to satisfy\",\"Neural综述 ↩︎\"]},\"267\":{\"h\":\"表示和逼近能力\"},\"268\":{\"h\":\"Notation\",\"t\":[\"定义：p,sup范数\",\"设 ， . 对于可测映射 ，子集 , 设\",\"其中 是Euclidean 范数 . 定义 .\",\"定义：通用逼近器\",\"设, 令 由可测函数 构成, 其中 是 的可测子集， 依赖， 称 是的意义下的通用逼近器，如果 , , ,其中是紧集， 那么 ,s.t. .\",\"设\",\"下一节中证明，中的都是同胚映射。因此如果作为假设空间表示能力和逼近能力都非常有限，下面给出Neural更一般形式的假设空间：\",\"在这个更加广义的集合中，将终止时间也作为了一个参数，同时在后添加了一层终端函数（以为输入），用来提高模型的表达能力。\"]},\"269\":{\"h\":\"同胚和流形假设\",\"t\":[\"引理1\",\"设 和 分别是初值问题和的两个解， 那么 ​.\",\"定理1\",\", 是同胚映射，保留了对输入空间的拓扑结构。\",\"证明：\",\"证明分为三个部分：\",\"是连续的： , 根据 Gronwall's 引理：\",\"​ 令 , 那么 ， 是连续的。\",\"是双射：由引理得出。\",\"是连续的:\",\"构造一个新的初值问题：\",\"然后根据连续和双射的证明得出。\",\"​\",\"下面给出一个最简单的一维上不能表示的函数。\",\"注意\",\"函数不能被表示。\",\"证明：\",\"​ 假设存在微分方程有两个解和满足：\",\"​ 定义函数，那么h(0)=2,h(T)=-2 ,连续函数介质定理，一定存在着,使得,根据\\\\ref{ode_bi},同一个微分方程的两个轨迹是不想交的，所以矛盾，因此不存在能表示函数。 ​\",\"流形假设(manifold hypothesis) 是机器学习和模式识别领域中的一个重要概念。它提出了一个假设，即高维数据通常存在于低维流形中。 简而言之，流形是一种具有局部线性结构的几何对象。在高维空间中，数据点可能分布在一个比观察到的维度更低的流形上。这意味着，尽管数据点在高维空间中可能看起来很复杂，但它们实际上可以由较少的自由度来描述。流形假设的核心思想是，学习算法可以通过寻找数据的低维表示来更好地理解和处理高维数据。通过将高维数据映射到低维流形上，可以减少数据的维度，并且可以更好地表示数据的内在结构和特征。流形假设在降维、特征提取、聚类和分类等机器学习任务中具有重要的应用。它为我们提供了一种理解高维数据的方法，并且可以帮助我们设计更有效的学习算法。\",\"定理\\\\ref{tongpei}表明：NODE会连续的变形输入空间而不会撕裂一个连接的区域。所以NODE能与流行假设优雅的进行交互：NODE描述了输入的流形如何随着深度流动到输出流形，这也对于部分任务例如图形生成任务来，机器学习可解释化是优势，但对某些任务来说是劣势。因此假设空间 对模型的表达能力很低，下面个各小节介绍一些方法来提高模型的表达能力。\"]},\"270\":{\"h\":\"增维的NODE\",\"t\":[\"并不能表示所有的同胚，但是可以通过增加维度来做到，下面这个定理说明通过将维度增加一倍数可以表示任何同胚映射。\",\"定理2\",\"对任何同胚映射,都存在NeuralODE，维度为,使得：，有。\",\"在增加维度的NeuralODE后添加一个线性层，那么可以逼近任何函数。\",\"定理3\",\"​设, ,函数 的形式如下\",\"​ 要满足微分方程解的唯一性 ,那么\",\"​ 在意义上逼近 .\",\"证明：\",\"​ 考虑如下的微分方程组：\",\"​ 每一组都可以单独求解：\",\"​\",\"​ 不妨设,那么得到了直到阶的单项式：\",\"​ ​ ​ ​ ​ 根据 Stone-Weierstrass theorem 定理： , ,足够大, 可以找到仿射函数 ,使得 ​\",\"令 ， 由堆叠而层， 用来对输入 补零， 对单项式进行组合以逼近目标连续函数.\",\"​ ​ ​ \\\\end\",\"定理从和定理虽然从理论上证明通过增维可以让模型具有通用逼近的能力，但是在训练过程中，会带来如下问题：\",\"\\\\begin{enumerate}\\n\\\\item 训练成本过高：如果维度增加倍，那么显存占比也将翻倍，还有训练时间指数级增加等；\\n\\\\item 训练过程不可控：在定理中虽然对的要求降低了，但是维数也变成了一个不可控量，造成训练的混乱，模型的解释性差等。\\n\\\\item 造成参数冗余：NeuralODE的一个优点就在于，参数共享，一般将Neural以图像或者词向量作为输入在增加维度，那么会大幅度降低参数有效性；\\n\\\\item 破坏可逆性：只要在最理想的训练情况下，才能在输出的填充维上的值全为0。\\n\\\\end{enumerate}\\n因此定理从和定理实际上只是一种理论上表达通过提高维度可以模型的表达能力，但实际定理只是给出了充分条件，我们可以减少增加维数，改变增加维数的方式（替换直接对输入额外的维度补0来增维）来提高训练的高效性。在$\\\\ref{sec:design} $中会介绍几种增加维度的NeuralODE网络架构。\"]},\"271\":{\"c\":[\"神经微分方程\"]},\"272\":{\"h\":\"预备知识\",\"t\":[\"定义\",\"设函数,其中是一个维向量，设未知函数满足方程\",\"称该微分方程为一阶标准方程。如果与时间无关，那么称微分方程是自治的，否则为非自治的。\",\"本文只讨论基于一阶标准微分方程的神经网络架构，原因在于一阶标准方程具有良好表示能力，在优化算法上有丰富的理论来源，有各种高效的数值解和现成的计算框架，而且模型简单更容易设计，根据机器学习中的奥卡姆剃刀原理： 需要假设最少的解释往往是最接近真相解释。\",\"定义\",\"方程的初值问题就是在未知函数有初值条件的条件下，求出未知函数，它在包含的某个区间上可微，且满足。\",\"任何初值问题记为,解记为,如果微分方程是自治的，那么根据积分曲线的平移不变形，取，,相应的解记作。\",\"定义\",\"设开集 是一个 映射 映射, , 且满足性质：\",\";\",\"。\",\"则对给定的  是一个  映射  映射) ，  称为  上的  动力系统 (  动力系统) 或  流 (  流)。\"]},\"273\":{\"h\":\"Bar 功能\"},\"274\":{\"h\":\"介绍\",\"t\":[\"我们支持 bar 功能，...\"]},\"275\":{\"h\":\"详情\",\"t\":[\"baz\",\"...\"]},\"276\":{\"h\":\"Baz\",\"t\":[\"功能详情...\"]},\"277\":{\"h\":\"Foo 功能\"},\"278\":{\"h\":\"介绍\",\"t\":[\"我们支持 foo 功能，...\"]},\"279\":{\"h\":\"详情\",\"t\":[\"ray\",\"...\"]},\"280\":{\"h\":\"Ray\",\"t\":[\"功能详情...\"]},\"281\":{\"h\":\"\",\"t\":[\"Alessio Quaglino, Marco Gallieri, Jonathan Masci, and Jan Koutn´ık. Accelerating neural odes with spectral elements. arXiv preprint arXiv:1906.07038, 2019\"]},\"282\":{\"h\":\"Posts\"},\"283\":{\"h\":\"Apple\"},\"284\":{\"h\":\"Banana\"}},\"dirtCount\":0,\"index\":[[\"jan\",{\"1\":{\"281\":1}}],[\"jonathan\",{\"1\":{\"281\":1}}],[\"just\",{\"1\":{\"193\":1}}],[\"quaglino\",{\"1\":{\"281\":1}}],[\"详情\",{\"0\":{\"275\":1,\"279\":1}}],[\"详情容器\",{\"0\":{\"95\":1,\"163\":1},\"1\":{\"60\":1,\"95\":2,\"163\":2}}],[\"映射\",{\"1\":{\"272\":4}}],[\"取\",{\"1\":{\"272\":1}}],[\"解记为\",{\"1\":{\"272\":1}}],[\"解释\",{\"1\":{\"134\":1,\"139\":1}}],[\"求出未知函数\",{\"1\":{\"272\":1}}],[\"原因在于一阶标准方程具有良好表示能力\",{\"1\":{\"272\":1}}],[\"否则为非自治的\",{\"1\":{\"272\":1}}],[\"否则求解器会在分段点减速再缓慢返回\",{\"1\":{\"266\":1}}],[\"$中会介绍几种增加维度的neuralode网络架构\",{\"1\":{\"270\":1}}],[\"替换直接对输入额外的维度补0来增维\",{\"1\":{\"270\":1}}],[\"改变增加维数的方式\",{\"1\":{\"270\":1}}],[\"才能在输出的填充维上的值全为0\",{\"1\":{\"270\":1}}],[\"破坏可逆性\",{\"1\":{\"270\":1}}],[\"造成参数冗余\",{\"1\":{\"270\":1}}],[\"造成训练的混乱\",{\"1\":{\"270\":1}}],[\"还有训练时间指数级增加等\",{\"1\":{\"270\":1}}],[\"还不会编写\",{\"1\":{\"55\":1}}],[\"补零\",{\"1\":{\"270\":1}}],[\"足够大\",{\"1\":{\"270\":1}}],[\"考虑如下的微分方程组\",{\"1\":{\"270\":1}}],[\"要满足微分方程解的唯一性\",{\"1\":{\"270\":1}}],[\"要使用此布局\",{\"1\":{\"0\":1}}],[\"都存在neuralode\",{\"1\":{\"270\":1}}],[\"都有一个概率分布\",{\"1\":{\"172\":1}}],[\"聚类和分类等机器学习任务中具有重要的应用\",{\"1\":{\"269\":1}}],[\"特征提取\",{\"1\":{\"269\":1}}],[\"特殊情况\",{\"1\":{\"178\":1}}],[\"学习算法可以通过寻找数据的低维表示来更好地理解和处理高维数据\",{\"1\":{\"269\":1}}],[\"学习问题\",{\"1\":{\"173\":1}}],[\"流\",{\"1\":{\"272\":2}}],[\"流形是一种具有局部线性结构的几何对象\",{\"1\":{\"269\":1}}],[\"流形假设在降维\",{\"1\":{\"269\":1}}],[\"流形假设的核心思想是\",{\"1\":{\"269\":1}}],[\"流形假设\",{\"1\":{\"269\":1}}],[\"流程图\",{\"0\":{\"76\":1}}],[\"构造一个新的初值问题\",{\"1\":{\"269\":1}}],[\"构成\",{\"1\":{\"268\":1}}],[\"构成了一个贝叶斯网络\",{\"1\":{\"178\":1}}],[\"保留了对输入空间的拓扑结构\",{\"1\":{\"269\":1}}],[\"子集\",{\"1\":{\"268\":1}}],[\"他的参数梯度如下\",{\"1\":{\"266\":1}}],[\"他的优势如下\",{\"1\":{\"265\":1}}],[\"调用次odesolver\",{\"1\":{\"266\":1}}],[\"调用一次odesolver直接在\",{\"1\":{\"266\":1}}],[\"唯一的区别就是依赖的向量\",{\"1\":{\"266\":1}}],[\"研究和训练的方便\",{\"1\":{\"266\":1}}],[\"实践者通常会尝试不同的初始化策略\",{\"1\":{\"265\":1}}],[\"实际的文章内容\",{\"1\":{\"51\":1}}],[\"尽管数据点在高维空间中可能看起来很复杂\",{\"1\":{\"269\":1}}],[\"尽管从理论上有这些考虑\",{\"1\":{\"265\":1}}],[\"尽可能大\",{\"1\":{\"196\":1}}],[\"添加随机性可以看作是一种隐式的正则化\",{\"1\":{\"265\":1}}],[\"正则化效果\",{\"1\":{\"265\":1}}],[\"正太分布或区间分布\",{\"1\":{\"265\":1}}],[\"局部最小和鞍点\",{\"1\":{\"265\":1}}],[\"局部马尔可夫性质\",{\"1\":{\"178\":2}}],[\"增维的node\",{\"0\":{\"270\":1}}],[\"增维的的node\",{\"0\":{\"263\":1}}],[\"增加状态空间的覆盖\",{\"1\":{\"265\":1}}],[\"打破对称性\",{\"1\":{\"265\":1}}],[\"随机噪声初始化允许网络在训练过程中探索更多的状态组合\",{\"1\":{\"265\":1}}],[\"随机噪声允许系统在整个状态空间中以某种概率分布进行采样\",{\"1\":{\"265\":1}}],[\"随机噪声打破了这种对称性\",{\"1\":{\"265\":1}}],[\"随机噪声可以使得系统从一系列不同的初始条件开始演化\",{\"1\":{\"265\":1}}],[\"随机化额外维度的初始值\",{\"0\":{\"265\":1}}],[\"初始化可以极大地影响优化算法的收敛性\",{\"1\":{\"265\":1}}],[\"初始条件的微小变化可能会导致长期行为的显著不同\",{\"1\":{\"265\":1}}],[\"初值问题有唯一解\",{\"1\":{\"260\":1}}],[\"初值问题\",{\"1\":{\"209\":1}}],[\"更具体点可以设\",{\"1\":{\"264\":1}}],[\"更新时间等页面元信息\",{\"1\":{\"85\":1}}],[\"更新时间\",{\"1\":{\"48\":1}}],[\"做到高效的训练\",{\"1\":{\"264\":1}}],[\"采用仿射的目的是\",{\"1\":{\"264\":1}}],[\"采样动作是离散的\",{\"1\":{\"255\":1}}],[\"再\",{\"1\":{\"263\":2}}],[\"再次点击即可缩小\",{\"1\":{\"40\":1}}],[\"网络设计\",{\"0\":{\"262\":1}}],[\"网络架构的选取进行讨论\",{\"1\":{\"256\":1}}],[\"训练过程不可控\",{\"1\":{\"270\":1}}],[\"训练成本过高\",{\"1\":{\"270\":1}}],[\"训练方式有两种\",{\"1\":{\"266\":1}}],[\"训练方法\",{\"1\":{\"256\":1}}],[\"训练思路都是丰富且先进\",{\"1\":{\"260\":1}}],[\"建模方法\",{\"1\":{\"260\":1}}],[\"微分方程一直被用来做应用建模\",{\"1\":{\"260\":1}}],[\"微积分\",{\"1\":{\"152\":1}}],[\"后面还会从rnn的角度和ode进行统一建模\",{\"1\":{\"260\":1}}],[\"后者是一种通过在训练过程中引入对抗性样本来提高模型鲁棒性的方法\",{\"1\":{\"196\":1}}],[\"残差神经网络架构就与欧拉法解方程统一起来\",{\"1\":{\"260\":1}}],[\"观察和可以发现每个resnet块类似于欧拉法求数值解微分方程时步长为1的情形\",{\"1\":{\"260\":1}}],[\"将终止时间也作为了一个参数\",{\"1\":{\"268\":1}}],[\"将输入的维度增加一倍\",{\"1\":{\"263\":1}}],[\"将区间分割为为单位\",{\"1\":{\"260\":1}}],[\"将将任意复杂的数据分布变换为一个基本的简单分布\",{\"1\":{\"253\":1}}],[\"经网络函数\",{\"1\":{\"260\":1}}],[\"回顾下一个resnet网络架构中的resnet块\",{\"1\":{\"260\":1}}],[\"回归模型\",{\"1\":{\"186\":1}}],[\"回归模型只建模条件概率\",{\"1\":{\"180\":1}}],[\"回归模型中的\",{\"1\":{\"180\":1}}],[\"回归模型类似\",{\"1\":{\"180\":1}}],[\"回归模型都采用\",{\"1\":{\"180\":1}}],[\"伴随方法在反模态积分中存在数值误差\",{\"1\":{\"258\":1}}],[\"自适应检查点伴随法\",{\"0\":{\"258\":1}}],[\"自定义它们\",{\"1\":{\"85\":1}}],[\"自定义对齐\",{\"0\":{\"63\":1}}],[\"自定义标题\",{\"1\":{\"60\":5,\"90\":2,\"91\":2,\"92\":2,\"93\":2,\"95\":2,\"159\":2,\"160\":2,\"161\":2,\"162\":2,\"163\":2}}],[\"超参数选择\",{\"1\":{\"256\":1}}],[\"弥合了深度学习和动态系统的差距\",{\"1\":{\"256\":1}}],[\"最终分布的概率密度由变量变换公式给出\",{\"1\":{\"253\":1}}],[\"最后所有的饼干都匹配不上\",{\"1\":{\"130\":1}}],[\"最后显示\",{\"1\":{\"27\":1}}],[\"均匀分布等\",{\"1\":{\"253\":1}}],[\"均有\",{\"1\":{\"205\":2}}],[\"通用逼近器\",{\"1\":{\"268\":1}}],[\"通常由可逆神经网络参数化\",{\"1\":{\"253\":1}}],[\"通过将高维数据映射到低维流形上\",{\"1\":{\"269\":1}}],[\"通过随机初始化\",{\"1\":{\"265\":1}}],[\"通过使用euler法来可以求得的每个时刻\",{\"1\":{\"260\":1}}],[\"通过巧妙设计的模型结构\",{\"1\":{\"253\":1}}],[\"通过选择\",{\"1\":{\"196\":1}}],[\"通过\",{\"1\":{\"56\":1,\"59\":1}}],[\"通过启用\",{\"1\":{\"34\":1}}],[\"星标了的香蕉文章\",{\"1\":{\"238\":1}}],[\"长\",{\"2\":{\"237\":1,\"242\":1,\"247\":1,\"252\":1}}],[\"弯曲的\",{\"2\":{\"237\":1,\"242\":1,\"247\":1,\"252\":1}}],[\"黄\",{\"2\":{\"237\":1,\"242\":1,\"247\":1,\"252\":1}}],[\"香蕉\",{\"0\":{\"233\":1,\"238\":1,\"243\":1,\"248\":1},\"2\":{\"236\":1,\"241\":1,\"246\":1,\"251\":1}}],[\"苹果\",{\"0\":{\"213\":1,\"218\":1,\"223\":1,\"228\":1},\"2\":{\"216\":1,\"221\":1,\"226\":1,\"231\":1}}],[\"​设\",{\"1\":{\"270\":1}}],[\"​\",{\"1\":{\"212\":1,\"269\":6,\"270\":15}}],[\"步对问题\",{\"1\":{\"211\":1}}],[\"步运算之后误差的大小\",{\"1\":{\"209\":1}}],[\"差分法\",{\"1\":{\"211\":1}}],[\"产生的近似\",{\"1\":{\"210\":1}}],[\"法\",{\"1\":{\"211\":1}}],[\"法对某个正整数\",{\"1\":{\"210\":1}}],[\"法的误差界\",{\"1\":{\"210\":1}}],[\"又假设存在常数\",{\"1\":{\"210\":1}}],[\"又因为\",{\"1\":{\"210\":1}}],[\"位于\",{\"1\":{\"210\":1}}],[\"应用\",{\"1\":{\"210\":1}}],[\"证明分为三个部分\",{\"1\":{\"269\":1}}],[\"证明\",{\"1\":{\"210\":1,\"260\":1,\"269\":2,\"270\":1}}],[\"引理1\",{\"1\":{\"269\":1}}],[\"引理\",{\"1\":{\"210\":1,\"269\":1}}],[\"问题存在一个唯一的解\",{\"1\":{\"209\":1}}],[\"值感兴趣\",{\"1\":{\"209\":1}}],[\"值得一提的是\",{\"1\":{\"180\":1}}],[\"人们通常对于使\",{\"1\":{\"209\":1}}],[\"允许将\",{\"1\":{\"209\":1}}],[\"虽然node中的输入和输出是固定的维度\",{\"1\":{\"260\":1}}],[\"虽然可以使用ode求解器\",{\"1\":{\"260\":1}}],[\"虽然euler法的精确性不足以保证它在实际中的使用\",{\"1\":{\"210\":1}}],[\"虽然定义\",{\"1\":{\"209\":1}}],[\"虽然朴素贝叶斯分类器的条件独立性假设太强\",{\"1\":{\"181\":1}}],[\"收玫于\",{\"1\":{\"209\":1}}],[\"收敛于数\",{\"1\":{\"209\":1}}],[\"成立的最大的\",{\"1\":{\"209\":1}}],[\"成立\",{\"1\":{\"209\":2,\"210\":1,\"211\":1}}],[\"成为一种计算高效的对抗性攻击方法\",{\"1\":{\"196\":1}}],[\"设开集\",{\"1\":{\"272\":1}}],[\"设未知函数满足方程\",{\"1\":{\"272\":1}}],[\"设函数\",{\"1\":{\"272\":1}}],[\"设有如下高阶常微分方程和初始条件\",{\"1\":{\"260\":1}}],[\"设计网络架构\",{\"1\":{\"256\":1}}],[\"设\",{\"1\":{\"209\":1,\"210\":1,\"264\":1,\"268\":4,\"269\":1}}],[\"设它的预激活值为\",{\"1\":{\"200\":1}}],[\"负有理数\",{\"1\":{\"209\":1}}],[\"仅实数系统的一个相对小的子集用于表示所有的实数\",{\"1\":{\"209\":1}}],[\"之所以产生舍人误差是因为机器中进行的算术运算所涉及的数是有限位的\",{\"1\":{\"209\":1}}],[\"之间\",{\"1\":{\"210\":1}}],[\"之间是条件独立的\",{\"1\":{\"181\":1}}],[\"之间具有非独立的因果关系\",{\"1\":{\"178\":1}}],[\"之间的依赖关系\",{\"1\":{\"177\":1}}],[\"之间条件独立性的图形化表示\",{\"1\":{\"172\":1}}],[\"舍入误差是计算器或计算机进行实数计算时所产生的\",{\"1\":{\"209\":1}}],[\"术语截断误差指的是使用被截的即有限的和来近似计算无穷级数的和所产生的误差\",{\"1\":{\"209\":1}}],[\"预备知识\",{\"0\":{\"209\":1,\"272\":1},\"1\":{\"256\":1}}],[\"预览模式\",{\"0\":{\"36\":1}}],[\"常微分方程数值解\",{\"0\":{\"208\":1}}],[\"常微分方程\",{\"0\":{\"207\":1}}],[\"常见的无向图模型\",{\"0\":{\"185\":1}}],[\"常见的有向图模型\",{\"0\":{\"179\":1}}],[\"常见的概率图模型可以分为两类\",{\"1\":{\"177\":1}}],[\"空间中决定了一条曲线\",{\"1\":{\"206\":1}}],[\"空间复杂度o\",{\"1\":{\"134\":1}}],[\"空间复杂度\",{\"1\":{\"129\":1}}],[\"欧氏\",{\"1\":{\"206\":1}}],[\"相应的解记作\",{\"1\":{\"272\":1}}],[\"相伴的摄动问题\",{\"1\":{\"209\":1}}],[\"相平面\",{\"0\":{\"206\":1}}],[\"相关信息\",{\"1\":{\"56\":1}}],[\"相关配置文档请见\",{\"1\":{\"0\":1}}],[\"零解的稳定形态\",{\"1\":{\"205\":1}}],[\"至少存在某个\",{\"1\":{\"205\":1}}],[\"怎样小\",{\"1\":{\"205\":1}}],[\"称该微分方程为一阶标准方程\",{\"1\":{\"272\":1}}],[\"称该微分方程为神经常微分方程\",{\"1\":{\"260\":1}}],[\"称\",{\"1\":{\"268\":1}}],[\"称它是不稳定的\",{\"1\":{\"205\":1}}],[\"称为终止时间\",{\"1\":{\"260\":1}}],[\"称为是一个适定的问题\",{\"1\":{\"209\":1}}],[\"称为\",{\"1\":{\"205\":1,\"272\":1}}],[\"称为团\",{\"1\":{\"184\":1}}],[\"称为转移概率\",{\"1\":{\"182\":1}}],[\"称为输出概率\",{\"1\":{\"182\":1}}],[\"称为向量\",{\"1\":{\"155\":1}}],[\"约有\",{\"1\":{\"205\":1}}],[\"且满足性质\",{\"1\":{\"272\":1}}],[\"且满足\",{\"1\":{\"272\":1}}],[\"且最终趋向于添加了无穷层时\",{\"1\":{\"260\":1}}],[\"且在\",{\"1\":{\"209\":1,\"210\":1}}],[\"且\",{\"1\":{\"209\":1}}],[\"且存储了小数部分和指数部分\",{\"1\":{\"209\":1}}],[\"且存在域\",{\"1\":{\"205\":1}}],[\"且存在这样的\",{\"1\":{\"205\":1}}],[\"且取值为实数\",{\"1\":{\"180\":1}}],[\"稳定域或吸引域\",{\"1\":{\"205\":1}}],[\"稳定\",{\"1\":{\"205\":1}}],[\"确定的解\",{\"1\":{\"205\":1}}],[\"方程的初值问题就是在未知函数有初值条件的条件下\",{\"1\":{\"272\":1}}],[\"方程组\",{\"1\":{\"205\":1}}],[\"方法和相应的更广义的证明\",{\"1\":{\"256\":1}}],[\"方便设计新模型等\",{\"1\":{\"174\":1}}],[\"存在唯一解\",{\"1\":{\"209\":1}}],[\"存在一个正常数\",{\"1\":{\"209\":1}}],[\"存在\",{\"1\":{\"205\":1}}],[\"动力系统的稳定性\",{\"0\":{\"205\":1}}],[\"动力系统\",{\"0\":{\"204\":1},\"1\":{\"272\":2}}],[\"动画\",{\"0\":{\"21\":1,\"23\":1}}],[\"动画片段用于高亮或显隐幻灯片中的元素\",{\"1\":{\"19\":1}}],[\"动画片段\",{\"0\":{\"18\":1,\"19\":1,\"20\":1,\"22\":1,\"24\":1,\"26\":1}}],[\"抗扰性\",{\"0\":{\"203\":1}}],[\"抗扰性验证\",{\"0\":{\"199\":1},\"1\":{\"203\":1}}],[\"依赖\",{\"1\":{\"201\":1,\"268\":1}}],[\"依赖当前时刻的隐变量\",{\"1\":{\"182\":1}}],[\"激活函数的线性上上下界\",{\"0\":{\"201\":1}}],[\"限制在内\",{\"1\":{\"200\":1}}],[\"行\",{\"1\":{\"200\":1}}],[\"偏置\",{\"1\":{\"200\":1}}],[\"层的第\",{\"1\":{\"200\":1}}],[\"层的激活值\",{\"1\":{\"200\":1}}],[\"层的权值矩阵为\",{\"1\":{\"200\":1}}],[\"层到\",{\"1\":{\"200\":1}}],[\"层\",{\"1\":{\"200\":1}}],[\"线性模型的对抗训练与权重衰减的对比研究\",{\"0\":{\"197\":1}}],[\"线性代数主要包含向量\",{\"1\":{\"153\":1}}],[\"线性代数\",{\"0\":{\"153\":1},\"1\":{\"152\":1}}],[\"达到了87\",{\"1\":{\"196\":1}}],[\"能达到89\",{\"1\":{\"196\":1}}],[\"平均置信度为97\",{\"1\":{\"196\":1}}],[\"平均置信度为79\",{\"1\":{\"196\":1}}],[\"平均权重值为\",{\"1\":{\"195\":1}}],[\"生成的对抗性样本可以用来测试模型的鲁棒性或用于对抗性训练\",{\"1\":{\"196\":1}}],[\"尤其适合于生成大量对抗性样本\",{\"1\":{\"196\":1}}],[\"效率\",{\"1\":{\"196\":1}}],[\"范数\",{\"1\":{\"196\":1,\"268\":1}}],[\"范数不超过\",{\"1\":{\"196\":1}}],[\"符号函数\",{\"1\":{\"196\":1}}],[\"目前可以看出研究和使用node的一个好处在于ode的理论优势\",{\"1\":{\"260\":1}}],[\"目标是找到一个小的扰动\",{\"1\":{\"196\":1}}],[\"目录\",{\"0\":{\"46\":1,\"149\":1,\"152\":1}}],[\"梯度方向\",{\"1\":{\"196\":1}}],[\"梯度的数学定义告诉我们在多维空间中函数增长最快的方向\",{\"1\":{\"196\":1}}],[\"关于这种形式的微分方程\",{\"1\":{\"266\":1}}],[\"关于这些扩展\",{\"1\":{\"58\":1}}],[\"关于\",{\"1\":{\"260\":1}}],[\"关于输入\",{\"1\":{\"196\":1}}],[\"它在包含的某个区间上可微\",{\"1\":{\"272\":1}}],[\"它为我们提供了一种理解高维数据的方法\",{\"1\":{\"269\":1}}],[\"它提出了一个假设\",{\"1\":{\"269\":1}}],[\"它们会接收到相同的梯度更新\",{\"1\":{\"265\":1}}],[\"它们的行为会是对称的\",{\"1\":{\"265\":1}}],[\"它们并不准确相等\",{\"1\":{\"258\":1}}],[\"它度量了相邻轨迹随时间分离的速率\",{\"1\":{\"265\":1}}],[\"它将传统的有限层神经网络架构转变为参数共享的无限层神经网络架构\",{\"1\":{\"256\":1}}],[\"它通过构造一系列可逆映射\",{\"1\":{\"253\":1}}],[\"它假定微分方程有可能有误差\",{\"1\":{\"209\":1}}],[\"它的解\",{\"1\":{\"206\":1}}],[\"它控制了对抗性扰动的强度\",{\"1\":{\"196\":1}}],[\"它是一种生成对抗性样本的技术\",{\"1\":{\"196\":1}}],[\"旨在通过执行单步梯度更新来生成对抗性样本\",{\"1\":{\"196\":1}}],[\"然后根据连续和双射的证明得出\",{\"1\":{\"269\":1}}],[\"然后的到\",{\"1\":{\"264\":1}}],[\"然后在额外的维度上补0\",{\"1\":{\"263\":1}}],[\"然后介绍针对node的一种全新的反向传播方法\",{\"1\":{\"256\":1}}],[\"然后应用符号函数和扰动系数\",{\"1\":{\"196\":1}}],[\"然后从后向前遍历小孩数组\",{\"1\":{\"128\":1}}],[\"然而\",{\"1\":{\"196\":1}}],[\"损失增加最快的方向就是梯度的方向\",{\"1\":{\"196\":1}}],[\"损失函数的梯度指向了损失增加最快的方向\",{\"1\":{\"196\":1}}],[\"损失函数\",{\"1\":{\"196\":2}}],[\"等人在\",{\"1\":{\"196\":1}}],[\"等号成立当且仅当\",{\"1\":{\"196\":1}}],[\"等来表示\",{\"1\":{\"155\":1}}],[\"两个向量的点积的最大值是当它们是平行时取得的\",{\"1\":{\"196\":1}}],[\"施瓦茨不等式\",{\"1\":{\"196\":1}}],[\"处的一阶泰勒展开大约为\",{\"1\":{\"196\":1}}],[\"处的梯度\",{\"1\":{\"196\":1}}],[\"加到输入\",{\"1\":{\"196\":1}}],[\"加密展示\",{\"1\":{\"46\":1,\"70\":1}}],[\"具体来说是沿着使损失最大化的方向\",{\"1\":{\"196\":1}}],[\"具体来说\",{\"1\":{\"196\":1}}],[\"具有\",{\"1\":{\"195\":1}}],[\"指示了哪个方向的微小变化会导致损失最大的增加\",{\"1\":{\"196\":1}}],[\"指向函数值增长最快的方向\",{\"1\":{\"196\":1}}],[\"指向\",{\"1\":{\"130\":1}}],[\"衡量了网络预测\",{\"1\":{\"196\":1}}],[\"同一个微分方程的两个轨迹是不想交的\",{\"1\":{\"269\":1}}],[\"同胚和流形假设\",{\"0\":{\"269\":1}}],[\"同门可以通过以下的公式来得到对抗扰动\",{\"1\":{\"196\":1}}],[\"同时在后添加了一层终端函数\",{\"1\":{\"268\":1}}],[\"同时也保证了前\",{\"1\":{\"264\":1}}],[\"同时对node的输出再进行处理\",{\"1\":{\"260\":1}}],[\"同时对训练用到的超参数的选择\",{\"1\":{\"256\":1}}],[\"同时又能保留梯度信息\",{\"1\":{\"255\":1}}],[\"同时\",{\"1\":{\"194\":1,\"196\":1}}],[\"同时我们可以根据链式法则写出联合概率\",{\"1\":{\"178\":3}}],[\"同时具有大小和方向\",{\"1\":{\"155\":1}}],[\"记为\",{\"1\":{\"209\":1}}],[\"记为神经网络使用的损失函数\",{\"1\":{\"196\":1}}],[\"记为模型得到的标签\",{\"1\":{\"196\":1}}],[\"记为模型的输入\",{\"1\":{\"196\":1}}],[\"非线性系统的敏感性\",{\"1\":{\"265\":1}}],[\"非线性模型的线性扰动\",{\"0\":{\"196\":1}}],[\"非定向攻击\",{\"1\":{\"192\":1}}],[\"像素点\",{\"1\":{\"195\":1}}],[\"却会忽略那些权重大但不相关的振幅\",{\"1\":{\"195\":1}}],[\"却并不会因为维度的增加而增加\",{\"1\":{\"195\":1}}],[\"该篇论文提出了一个能供更简单与更快速的生成对抗样本的方法\",{\"1\":{\"194\":1}}],[\"早期对对抗样本产生的原因的猜测集中于神经网络的非线性性和过拟合\",{\"1\":{\"194\":1}}],[\"攻击算法\",{\"1\":{\"193\":1}}],[\"攻击者不知道目标模型的内部细节\",{\"1\":{\"192\":1}}],[\"|\",{\"1\":{\"193\":2}}],[\"三\",{\"1\":{\"193\":1}}],[\"论文地址\",{\"1\":{\"193\":1}}],[\"把输入分类误判到一个某个特定的错误类别上\",{\"1\":{\"192\":1}}],[\"黑箱攻击\",{\"1\":{\"192\":1}}],[\"结构以及参数\",{\"1\":{\"192\":1}}],[\"结束\",{\"0\":{\"41\":1},\"1\":{\"76\":1}}],[\"类型\",{\"1\":{\"192\":1}}],[\"类别\",{\"1\":{\"181\":1}}],[\"白盒非指向性\",{\"1\":{\"193\":1}}],[\"白箱攻击\",{\"1\":{\"192\":1}}],[\"白板推导系列\",{\"1\":{\"176\":2}}],[\"金山文档\",{\"1\":{\"191\":1,\"199\":1}}],[\"让输入\",{\"1\":{\"200\":1}}],[\"让神经网络的分类准确率大幅下降\",{\"1\":{\"190\":1}}],[\"让我们确定每个条件概率所需的参数\",{\"1\":{\"172\":1}}],[\"但实际定理只是给出了充分条件\",{\"1\":{\"270\":1}}],[\"但对某些任务来说是劣势\",{\"1\":{\"269\":1}}],[\"但它们实际上可以由较少的自由度来描述\",{\"1\":{\"269\":1}}],[\"但在实际操作中\",{\"1\":{\"265\":1}}],[\"但足以欺骗神经网络\",{\"1\":{\"196\":1}}],[\"但其的鲁棒性却可能很差\",{\"1\":{\"190\":1}}],[\"但是维数也变成了一个不可控量\",{\"1\":{\"270\":1}}],[\"但是可以通过增加维度来做到\",{\"1\":{\"270\":1}}],[\"但是为了表示\",{\"1\":{\"266\":1}}],[\"但是它也有很大的缺陷\",{\"1\":{\"263\":1}}],[\"但是网络架构是任意的\",{\"1\":{\"260\":1}}],[\"但是由于维度巨大\",{\"1\":{\"260\":1}}],[\"但是在训练过程中\",{\"1\":{\"270\":1}}],[\"但是在分析从它的应用所产生的误差方面它是一个重要的基础\",{\"1\":{\"210\":1}}],[\"但是在实际应用中\",{\"1\":{\"181\":1}}],[\"但是几乎在每一种情况下都使用\",{\"1\":{\"209\":1}}],[\"但是线性\",{\"1\":{\"196\":1}}],[\"但是这篇论文证明神经网络的线性性质是造成神经网络具有对抗样本的主要原因\",{\"1\":{\"194\":1}}],[\"但是并不一定是因果关系\",{\"1\":{\"177\":1}}],[\"但是\",{\"1\":{\"172\":2,\"180\":1,\"195\":1}}],[\"但是你需要使用相对链接\",{\"1\":{\"84\":1}}],[\"基本概念\",{\"0\":{\"190\":1}}],[\"基础概论\",{\"0\":{\"43\":1}}],[\"~bonner\",{\"1\":{\"188\":1}}],[\"参数共享\",{\"1\":{\"270\":1}}],[\"参数量随着层数的增加而增加\",{\"1\":{\"260\":1}}],[\"参数量约为\",{\"1\":{\"172\":1}}],[\"参考\",{\"0\":{\"188\":1}}],[\"代表所有势能函数中的参数\",{\"1\":{\"186\":1}}],[\"代码随想录\",{\"1\":{\"128\":1}}],[\"代码演示\",{\"0\":{\"71\":1}}],[\"代码块\",{\"0\":{\"61\":1}}],[\"代码块会自动高亮\",{\"1\":{\"10\":1}}],[\"代码\",{\"0\":{\"34\":1,\"129\":1},\"1\":{\"60\":1,\"90\":1,\"159\":1}}],[\"势能函数一般定义为\",{\"1\":{\"186\":1}}],[\"受限玻尔兹曼机等\",{\"1\":{\"185\":1}}],[\"玻尔兹曼机\",{\"1\":{\"185\":1}}],[\"任何初值问题记为\",{\"1\":{\"272\":1}}],[\"任何一个无向图模型都可以用公式\",{\"1\":{\"184\":1}}],[\"任务列表\",{\"0\":{\"67\":1,\"101\":1,\"169\":1}}],[\"公式\",{\"1\":{\"184\":1}}],[\"吉布斯分布一定满足马尔可夫随机场的条件独立性质\",{\"1\":{\"184\":1}}],[\"吉布斯分布\",{\"1\":{\"184\":1}}],[\"配分函数的计算复杂度是指数的\",{\"1\":{\"184\":1}}],[\"配置\",{\"0\":{\"56\":1}}],[\"定向攻击\",{\"1\":{\"192\":1}}],[\"定理从和定理虽然从理论上证明通过增维可以让模型具有通用逼近的能力\",{\"1\":{\"270\":1}}],[\"定理3\",{\"1\":{\"270\":1}}],[\"定理2\",{\"1\":{\"270\":1}}],[\"定理1\",{\"1\":{\"269\":1}}],[\"定理得\",{\"1\":{\"210\":1}}],[\"定理中涉及的符号\",{\"0\":{\"202\":1}}],[\"定理\",{\"1\":{\"184\":1,\"209\":1,\"210\":1,\"269\":1,\"270\":1}}],[\"定理的证明可以参考\",{\"1\":{\"184\":1}}],[\"定义函数\",{\"1\":{\"269\":1}}],[\"定义两个线性函数\",{\"1\":{\"201\":1}}],[\"定义\",{\"0\":{\"260\":1},\"1\":{\"178\":1,\"183\":1,\"205\":1,\"209\":2,\"211\":1,\"256\":1,\"260\":1,\"268\":3,\"272\":3}}],[\"用来对输入\",{\"1\":{\"270\":1}}],[\"用来提高模型的表达能力\",{\"1\":{\"268\":1}}],[\"用来做反向传播\",{\"1\":{\"266\":1}}],[\"用来将乘积归一化为概率形式\",{\"1\":{\"184\":1}}],[\"用大饼干优先满足胃口大的\",{\"1\":{\"128\":1}}],[\"包括模型的训练集\",{\"1\":{\"192\":1}}],[\"包括\",{\"1\":{\"184\":1}}],[\"包含\",{\"1\":{\"60\":1,\"90\":2,\"159\":2}}],[\"进行采样\",{\"1\":{\"255\":1}}],[\"进行比较\",{\"1\":{\"209\":1}}],[\"进行逐一分解\",{\"1\":{\"184\":1}}],[\"进行引用\",{\"1\":{\"84\":2}}],[\"团\",{\"1\":{\"184\":1}}],[\"根据机器学习中的奥卡姆剃刀原理\",{\"1\":{\"272\":1}}],[\"根据灵敏度公式\",{\"1\":{\"266\":1}}],[\"根据picard存在定理\",{\"1\":{\"260\":1}}],[\"根据柯西\",{\"1\":{\"196\":1}}],[\"根据\",{\"1\":{\"184\":1,\"269\":2,\"270\":1}}],[\"根据马尔可夫性质\",{\"1\":{\"183\":1}}],[\"根据此规律可以直接看图得出结论\",{\"1\":{\"178\":1}}],[\"外的其他变量\",{\"1\":{\"183\":1}}],[\"外其他变量的集合\",{\"1\":{\"183\":1}}],[\"外面的for\",{\"1\":{\"130\":1}}],[\"满足初始条仵\",{\"1\":{\"205\":1}}],[\"满足\",{\"1\":{\"205\":2,\"209\":1}}],[\"满足无向图\",{\"1\":{\"184\":1}}],[\"满足局部马尔可夫性质\",{\"1\":{\"183\":1}}],[\"满足不了\",{\"1\":{\"130\":1}}],[\"马尔可夫随机场\",{\"1\":{\"183\":1}}],[\"所有的\",{\"1\":{\"266\":1}}],[\"所有的隐变量构成一个马尔可夫链\",{\"1\":{\"182\":1}}],[\"所定义的问题称作和原问题\",{\"1\":{\"209\":1}}],[\"所确定的解\",{\"1\":{\"205\":1}}],[\"所以node能与流行假设优雅的进行交互\",{\"1\":{\"269\":1}}],[\"所以矛盾\",{\"1\":{\"269\":1}}],[\"所以若我们在renet层级间加入更多的层\",{\"1\":{\"260\":1}}],[\"所以关于\",{\"1\":{\"260\":1}}],[\"所以数值方法总与求解摄动问题有关\",{\"1\":{\"209\":1}}],[\"所以比较容易优化\",{\"1\":{\"196\":1}}],[\"所以称为head\",{\"1\":{\"178\":2}}],[\"所以可知\",{\"1\":{\"178\":3}}],[\"所以有4种组合\",{\"1\":{\"172\":1}}],[\"所以我们需要2个值\",{\"1\":{\"172\":1}}],[\"所以它可以取两个值\",{\"1\":{\"172\":1}}],[\"所以index不会移动\",{\"1\":{\"130\":1}}],[\"所以\",{\"1\":{\"130\":2,\"172\":2,\"210\":1}}],[\"所以你无需担心它的长度\",{\"1\":{\"8\":1}}],[\"条件\",{\"1\":{\"209\":1,\"210\":1}}],[\"条件随机场\",{\"0\":{\"187\":1},\"1\":{\"185\":1}}],[\"条件概率\",{\"1\":{\"182\":2}}],[\"条件概率分布\",{\"1\":{\"181\":1}}],[\"条件独立于它的非后代节点\",{\"1\":{\"178\":1}}],[\"朴素\",{\"1\":{\"181\":1}}],[\"朴素贝叶斯\",{\"1\":{\"181\":1}}],[\"朴素贝叶斯分类器在很多任务上也能得到很好的结果\",{\"1\":{\"181\":1}}],[\"朴素贝叶斯分类器\",{\"0\":{\"181\":1}}],[\"作为node的输出\",{\"1\":{\"264\":1}}],[\"作为微分方程的初值\",{\"1\":{\"264\":1}}],[\"作为一种确定性的参数\",{\"1\":{\"180\":1}}],[\"作者发现\",{\"1\":{\"196\":1}}],[\"作者在使用中\",{\"1\":{\"196\":1}}],[\"作者通过数学公式来解释\",{\"1\":{\"195\":1}}],[\"作者设置为\",{\"1\":{\"83\":1}}],[\"作者\",{\"1\":{\"3\":1}}],[\"函数不能被表示\",{\"1\":{\"269\":1}}],[\"函数是带参数的神\",{\"1\":{\"260\":1}}],[\"函数是为了得到一个大小为\",{\"1\":{\"196\":1}}],[\"函数以作为特征输入可以看成一个神经网络\",{\"1\":{\"260\":1}}],[\"函数取梯度的符号\",{\"1\":{\"196\":1}}],[\"函数来计算条件概率\",{\"1\":{\"180\":1}}],[\"函数\",{\"1\":{\"180\":1,\"270\":1}}],[\"信念网络建模联合概率\",{\"1\":{\"180\":1}}],[\"信念网络的网络结构和\",{\"1\":{\"180\":1}}],[\"信念网络中只有一个叶子节点\",{\"1\":{\"180\":1}}],[\"信念网络与\",{\"1\":{\"180\":1}}],[\"信念网络\",{\"1\":{\"180\":1}}],[\"信息容器\",{\"0\":{\"90\":1,\"159\":1},\"1\":{\"60\":1,\"90\":2,\"159\":2}}],[\"深度信念网络等\",{\"1\":{\"179\":1}}],[\"深度学习中的神经网络在精心训练后\",{\"1\":{\"190\":1}}],[\"深度学习\",{\"0\":{\"44\":1}}],[\"隐马尔可夫模型的联合概率可以分解为\",{\"1\":{\"182\":1}}],[\"隐马尔可夫模型\",{\"0\":{\"182\":1},\"1\":{\"179\":1,\"182\":1}}],[\"很多经典的机器学习模型可以使用无向图模型来描述\",{\"1\":{\"185\":1}}],[\"很多经典的机器学习模型可以使用有向图模型来描述\",{\"1\":{\"179\":1}}],[\"很多机器学习模型都可以归结为概率模型\",{\"1\":{\"174\":1}}],[\"反而不独立了\",{\"1\":{\"178\":1}}],[\"路径是阻塞的\",{\"1\":{\"178\":1}}],[\"路径导航\",{\"1\":{\"48\":1,\"85\":1}}],[\"默认情况下\",{\"1\":{\"178\":1}}],[\"由堆叠而层\",{\"1\":{\"270\":1}}],[\"由引理得出\",{\"1\":{\"269\":1}}],[\"由可测函数\",{\"1\":{\"268\":1}}],[\"由有限的激活函数为relu的仿射层组成\",{\"1\":{\"260\":1}}],[\"由式\",{\"1\":{\"209\":1}}],[\"由此\",{\"1\":{\"178\":1}}],[\"由于ode的求解比较难\",{\"1\":{\"260\":1}}],[\"由于正模和反模轨迹被视为两个独立的ivp\",{\"1\":{\"258\":1}}],[\"由于势能函数必须为正\",{\"1\":{\"184\":1}}],[\"由于无向图模型并不提供一个变量的拓扑顺序\",{\"1\":{\"184\":1}}],[\"由于和都是二值变量\",{\"1\":{\"172\":1}}],[\"由于概率总和必须为1\",{\"1\":{\"172\":1}}],[\"间接因果关系\",{\"1\":{\"178\":1}}],[\"总有一个\",{\"1\":{\"205\":1}}],[\"总结出的规律\",{\"1\":{\"178\":1}}],[\"总共需要9个参数来描述这个系统的联合概率分布\",{\"1\":{\"172\":1}}],[\"则对给定的\",{\"1\":{\"272\":1}}],[\"则对于\",{\"1\":{\"210\":1}}],[\"则初值问题\",{\"1\":{\"209\":1}}],[\"则没有理由期望摄动问题的数值解会精确地近原问题的解\",{\"1\":{\"209\":1}}],[\"则误差的增长称为是指数的\",{\"1\":{\"209\":1}}],[\"则误差的增长称为是线性的\",{\"1\":{\"209\":1}}],[\"则域\",{\"1\":{\"205\":1}}],[\"则称\",{\"1\":{\"209\":1}}],[\"则称零解\",{\"1\":{\"205\":2}}],[\"则称方程组\",{\"1\":{\"205\":2}}],[\"则路径是通的\",{\"1\":{\"178\":1}}],[\"则路径被堵塞\",{\"1\":{\"178\":1}}],[\"则需要\",{\"1\":{\"172\":1}}],[\"被观测\",{\"1\":{\"178\":2}}],[\"若干个世纪以来\",{\"1\":{\"260\":1}}],[\"若稳定域为全空间\",{\"1\":{\"205\":1}}],[\"若\",{\"1\":{\"178\":2,\"181\":2}}],[\"已知的条件下\",{\"1\":{\"178\":2}}],[\"共果关系\",{\"1\":{\"178\":1}}],[\"共因关系\",{\"1\":{\"178\":1}}],[\"共需要\",{\"1\":{\"172\":1}}],[\"令\",{\"1\":{\"178\":1,\"268\":1,\"269\":1,\"270\":1}}],[\"贝叶斯网络\",{\"1\":{\"178\":1}}],[\"下一节中证明\",{\"1\":{\"268\":1}}],[\"下一篇\",{\"1\":{\"48\":1}}],[\"下面这个定理说明通过将维度增加一倍数可以表示任何同胚映射\",{\"1\":{\"270\":1}}],[\"下面个各小节介绍一些方法来提高模型的表达能力\",{\"1\":{\"269\":1}}],[\"下面给出一个最简单的一维上不能表示的函数\",{\"1\":{\"269\":1}}],[\"下面给出neural更一般形式的假设空间\",{\"1\":{\"268\":1}}],[\"下面给出更一般形式的含有node的网络架构\",{\"1\":{\"260\":1}}],[\"下面子节是其他的用于增维的方法来解决\",{\"1\":{\"263\":1}}],[\"下图给出了朴素贝叶斯分类器的图模型表示\",{\"1\":{\"181\":1}}],[\"下图中\",{\"1\":{\"178\":1}}],[\"连续函数介质定理\",{\"1\":{\"269\":1}}],[\"连续\",{\"1\":{\"260\":1}}],[\"连续归一化流\",{\"0\":{\"253\":1},\"1\":{\"170\":1}}],[\"连边表示两变量间的条件依赖关系\",{\"1\":{\"177\":1}}],[\"unaugmented\",{\"1\":{\"264\":1}}],[\"undirected\",{\"1\":{\"177\":1}}],[\"up\",{\"1\":{\"21\":1}}],[\"无穷范数\",{\"1\":{\"196\":1}}],[\"无向图上定义的概率分布可以表示为\",{\"1\":{\"184\":1}}],[\"无向图中的联合概率可以分解为一系列定义在最大团上的非负函数的乘积形式\",{\"1\":{\"184\":1}}],[\"无向图中的一个全连通子图\",{\"1\":{\"184\":1}}],[\"无向图模型和吉布斯分布是一致的\",{\"1\":{\"184\":1}}],[\"无向图模型与有向图模型的一个重要区别是有配分函数𝑍\",{\"1\":{\"184\":1}}],[\"无向图模型的联合概率一般以全连通子图为单位进行分解\",{\"1\":{\"184\":1}}],[\"无向图模型的概率分解\",{\"0\":{\"184\":1}}],[\"无向图模型\",{\"0\":{\"183\":1},\"1\":{\"183\":1}}],[\"无向图模型使用无向图\",{\"1\":{\"177\":1}}],[\"无重叠的\",{\"1\":{\"139\":1}}],[\"量条件独立\",{\"1\":{\"177\":1}}],[\"边表示这些随机变量之间的概率依赖关系\",{\"1\":{\"177\":1}}],[\"每一组都可以单独求解\",{\"1\":{\"270\":1}}],[\"每一层神经元数量为\",{\"1\":{\"200\":1}}],[\"每层参数化\",{\"1\":{\"260\":1}}],[\"每个元素的扰动都受到限制\",{\"1\":{\"196\":1}}],[\"每个可观测标量\",{\"1\":{\"182\":1}}],[\"每个随机变量在给定父节点的情况下\",{\"1\":{\"178\":1}}],[\"每个连接\",{\"1\":{\"178\":1}}],[\"每个节点都表示一个随机变量\",{\"1\":{\"177\":1}}],[\"每条边代表两个变量之间有概率依赖关系\",{\"1\":{\"177\":1}}],[\"每条连边表示变量之间的依赖关系\",{\"1\":{\"172\":1}}],[\"zhihu\",{\"1\":{\"176\":1,\"254\":1}}],[\"zoom\",{\"1\":{\"29\":1}}],[\"知乎\",{\"1\":{\"176\":1,\"254\":1}}],[\"哔哩哔哩\",{\"1\":{\"176\":1}}],[\"九\",{\"1\":{\"176\":2}}],[\"机器学习可解释化是优势\",{\"1\":{\"269\":1}}],[\"机器学习\",{\"1\":{\"176\":2}}],[\"资料\",{\"0\":{\"176\":1}}],[\"模型的解释性差等\",{\"1\":{\"270\":1}}],[\"模型的参数设为\",{\"1\":{\"196\":1}}],[\"模型可以对数据样本进行精确的最大似然估计\",{\"1\":{\"253\":1}}],[\"模型表示\",{\"0\":{\"177\":1},\"1\":{\"175\":1}}],[\"模拟法\",{\"0\":{\"140\":1}}],[\"比如全连接神经网络\",{\"1\":{\"260\":1}}],[\"比如使x在梯度方向上旋转一定的角度\",{\"1\":{\"196\":1}}],[\"比如sigmoid网络\",{\"1\":{\"196\":1}}],[\"比如对数线性模型\",{\"1\":{\"185\":1}}],[\"比如朴素贝叶斯分类器\",{\"1\":{\"179\":1}}],[\"比如了解不同机器学习模型之间的联系\",{\"1\":{\"174\":1}}],[\"比如0或1\",{\"1\":{\"172\":1}}],[\"推断问题\",{\"1\":{\"173\":1}}],[\"赖关系\",{\"1\":{\"173\":1}}],[\"变量\",{\"1\":{\"172\":1}}],[\"变红\",{\"1\":{\"25\":1}}],[\"简而言之\",{\"1\":{\"269\":1}}],[\"简称neuralode\",{\"1\":{\"260\":1}}],[\"简称\",{\"1\":{\"196\":1,\"256\":1}}],[\"简称图模型\",{\"1\":{\"172\":1}}],[\"简介\",{\"0\":{\"194\":1}}],[\"简单的方式描述随机变量之间的条件独立性\",{\"1\":{\"172\":1}}],[\"现在讨论二阶微分方程组\",{\"1\":{\"206\":1}}],[\"现在\",{\"1\":{\"172\":1,\"196\":1}}],[\"需要假设最少的解释往往是最接近真相解释\",{\"1\":{\"272\":1}}],[\"需要两个计算引理\",{\"1\":{\"210\":1}}],[\"需要4个参数\",{\"1\":{\"172\":1}}],[\"需要2个参数\",{\"1\":{\"172\":1}}],[\"例如添加一层全连接层或者非线性层\",{\"1\":{\"260\":1}}],[\"例如一个1080p像素点有个\",{\"1\":{\"260\":1}}],[\"例如存在连续偏导数\",{\"1\":{\"206\":1}}],[\"例如它们假定的高度非线性性质\",{\"1\":{\"195\":1}}],[\"例如\",{\"1\":{\"172\":1,\"260\":1,\"266\":1}}],[\"首先给出node的定义\",{\"1\":{\"260\":1}}],[\"首先\",{\"1\":{\"172\":1}}],[\"只要在最理想的训练情况下\",{\"1\":{\"270\":1}}],[\"只不过更复杂一些\",{\"1\":{\"210\":1}}],[\"只能够观察目标模型对输入样本的输出结果\",{\"1\":{\"192\":1}}],[\"只需要生成对抗样本\",{\"1\":{\"192\":1}}],[\"只需要知道的一个值的条件概率\",{\"1\":{\"172\":1}}],[\"只需要1个参数\",{\"1\":{\"172\":1}}],[\"只需要\",{\"1\":{\"172\":1}}],[\"只有大小\",{\"1\":{\"155\":1}}],[\"即高维数据通常存在于低维流形中\",{\"1\":{\"269\":1}}],[\"即初始条件的微小扰动可能导致完全不同的轨迹\",{\"1\":{\"265\":1}}],[\"即是说\",{\"1\":{\"205\":1}}],[\"即向量中的最大元素\",{\"1\":{\"196\":1}}],[\"即通过对输入图片进行一个微小的扰动\",{\"1\":{\"190\":1}}],[\"即团内的所有节点之间都连边\",{\"1\":{\"184\":1}}],[\"即一个变量\",{\"1\":{\"183\":1}}],[\"即不存在其他变量使得这两个节点对应的变\",{\"1\":{\"177\":1}}],[\"即建模输入和输出之间的条件概率分布\",{\"1\":{\"174\":1}}],[\"即参数估计问题\",{\"1\":{\"173\":1}}],[\"即\",{\"1\":{\"172\":1,\"178\":2,\"181\":1,\"184\":1,\"196\":1,\"205\":1,\"260\":1}}],[\"即有\",{\"1\":{\"172\":2}}],[\"即可以向此元素进行放大\",{\"1\":{\"40\":1}}],[\"即可在幻灯片获得焦点时进入全屏模式\",{\"1\":{\"38\":1}}],[\"即可在幻灯片获得焦点时进入预览模式\",{\"1\":{\"36\":1}}],[\"独立性假设的条件下运用贝叶斯公式来计算每个类别的条件概率\",{\"1\":{\"181\":1}}],[\"独立\",{\"1\":{\"172\":2,\"178\":4}}],[\"假设存在微分方程有两个解和满足\",{\"1\":{\"269\":1}}],[\"假设是层神经网络\",{\"1\":{\"260\":1}}],[\"假设全局\",{\"1\":{\"260\":1}}],[\"假设\",{\"1\":{\"209\":2,\"210\":1,\"260\":1}}],[\"假设方程右端的函数满足解的存在唯一性和连续性定理的条件\",{\"1\":{\"206\":1}}],[\"假设神经网络一共有\",{\"1\":{\"200\":1}}],[\"假设我们有一个小的扰动\",{\"1\":{\"196\":1}}],[\"假设在给定\",{\"1\":{\"181\":1}}],[\"假设在已知\",{\"1\":{\"172\":1}}],[\"假设变量\",{\"1\":{\"180\":1}}],[\"假设有四个二值变量\",{\"1\":{\"172\":1}}],[\"假设每个变量为离散变量并有\",{\"1\":{\"172\":1}}],[\"远远超出了目前计算机的存储能力\",{\"1\":{\"172\":1}}],[\"时满足初始条件\",{\"1\":{\"205\":1}}],[\"时的错误程度\",{\"1\":{\"196\":1}}],[\"时\",{\"1\":{\"172\":3,\"178\":1,\"205\":2,\"209\":1}}],[\"时间复杂度\",{\"1\":{\"129\":1}}],[\"从概率论的角度来看\",{\"1\":{\"265\":1}}],[\"从而提高了模型在未见数据上的泛化能力\",{\"1\":{\"265\":1}}],[\"从而限制了网络能够学习的功能\",{\"1\":{\"265\":1}}],[\"从而能够探索状态空间中的更多区域\",{\"1\":{\"265\":1}}],[\"从而\",{\"1\":{\"210\":1}}],[\"从而导致计算只能用实际数值的近似表示式来完成\",{\"1\":{\"209\":1}}],[\"从而降低模型的性能\",{\"1\":{\"196\":1}}],[\"从而给研究高维空间中的概率模型带来了很大的便捷性\",{\"1\":{\"172\":1}}],[\"从对抗样本的线性视角来看\",{\"1\":{\"196\":1}}],[\"从\",{\"1\":{\"178\":2}}],[\"从代码中可以看出我用了一个index来控制饼干数组的遍历\",{\"1\":{\"129\":1}}],[\"概率图模型基础笔记\",{\"1\":{\"176\":1}}],[\"概率图模型基础\",{\"1\":{\"176\":1}}],[\"概率图模型\",{\"1\":{\"172\":1}}],[\"概率图\",{\"0\":{\"172\":1}}],[\"概率论\",{\"1\":{\"152\":1}}],[\"神经常微分方程\",{\"0\":{\"256\":1},\"1\":{\"170\":1,\"256\":1}}],[\"神经微分方程稳定性概念\",{\"1\":{\"261\":1}}],[\"神经微分方程的稳定性\",{\"0\":{\"261\":1}}],[\"神经微分方程\",{\"0\":{\"170\":1},\"2\":{\"259\":1,\"271\":1}}],[\"绪论\",{\"0\":{\"171\":1},\"1\":{\"170\":1}}],[\"容器\",{\"0\":{\"158\":1}}],[\"维度为\",{\"1\":{\"270\":1}}],[\"维的结构\",{\"1\":{\"264\":1}}],[\"维特征的样本\",{\"1\":{\"181\":1}}],[\"维随机向量\",{\"1\":{\"172\":2,\"178\":1}}],[\"维\",{\"1\":{\"155\":1,\"195\":1}}],[\"维向量\",{\"1\":{\"155\":1}}],[\"表明\",{\"1\":{\"269\":1}}],[\"表示和逼近\",{\"1\":{\"263\":4}}],[\"表示和逼近能力\",{\"0\":{\"267\":1},\"1\":{\"256\":1}}],[\"表示网络的深度\",{\"1\":{\"260\":1}}],[\"表示能力等均和传统的神经网络例如cnn\",{\"1\":{\"256\":1}}],[\"表示初值问题\",{\"1\":{\"210\":1}}],[\"表示初始误差\",{\"1\":{\"209\":1}}],[\"表示在以后的\",{\"1\":{\"209\":1}}],[\"表示矩阵\",{\"1\":{\"200\":1}}],[\"表示第\",{\"1\":{\"200\":1}}],[\"表示目标输出\",{\"1\":{\"196\":1}}],[\"表示输入样本\",{\"1\":{\"196\":1}}],[\"表示模型参数\",{\"1\":{\"196\":1}}],[\"表示除\",{\"1\":{\"183\":1}}],[\"表示随机变量\",{\"1\":{\"183\":1}}],[\"表示每个随机变量的局部条件概率分布\",{\"1\":{\"178\":1}}],[\"表示两个随机变量\",{\"1\":{\"178\":1}}],[\"表示\",{\"1\":{\"178\":1,\"182\":1}}],[\"表示对应的两个变量为因果关系\",{\"1\":{\"177\":1}}],[\"表示问题\",{\"1\":{\"173\":1}}],[\"表示变量\",{\"1\":{\"172\":1,\"178\":1}}],[\"表示为\",{\"1\":{\"155\":1}}],[\"表格和分割线\",{\"1\":{\"12\":1}}],[\"个神经元\",{\"1\":{\"200\":1}}],[\"个团就是一个最大团\",{\"1\":{\"184\":1}}],[\"个团\",{\"1\":{\"184\":1}}],[\"个变量\",{\"1\":{\"183\":1}}],[\"个变量之间的条件独立性的图形化描述\",{\"1\":{\"172\":1}}],[\"个节点的无向图\",{\"1\":{\"183\":1}}],[\"个节点的有向非循环图\",{\"1\":{\"178\":1}}],[\"个独立参数\",{\"1\":{\"172\":1}}],[\"个条件概率的话\",{\"1\":{\"172\":1}}],[\"个条件概率的乘积\",{\"1\":{\"172\":1}}],[\"个表格来记录这\",{\"1\":{\"172\":1}}],[\"个局部条件概率的乘积\",{\"1\":{\"172\":1}}],[\"个参数\",{\"1\":{\"172\":1,\"180\":2}}],[\"个参数才能表示其概率分布\",{\"1\":{\"172\":1}}],[\"个取值\",{\"1\":{\"172\":1}}],[\"个分量\",{\"1\":{\"155\":1}}],[\"个有序实数组成\",{\"1\":{\"155\":1}}],[\"个人介绍\",{\"0\":{\"1\":1}}],[\"来提高训练的高效性\",{\"1\":{\"270\":1}}],[\"来存储前向计算中的\",{\"1\":{\"266\":1}}],[\"来实现这一点\",{\"1\":{\"196\":1}}],[\"来描述变量之间的关系\",{\"1\":{\"177\":2}}],[\"来描述这个条件概率\",{\"1\":{\"172\":1}}],[\"来表示其联合概率\",{\"1\":{\"184\":1}}],[\"来表示\",{\"1\":{\"155\":1}}],[\"来解析\",{\"1\":{\"57\":1}}],[\"没有方向\",{\"1\":{\"155\":1}}],[\"优化算法\",{\"0\":{\"257\":1},\"1\":{\"256\":1}}],[\"优化\",{\"1\":{\"152\":1}}],[\"优化版本\",{\"1\":{\"134\":1}}],[\"字符串\",{\"0\":{\"150\":1},\"1\":{\"149\":1}}],[\"剑指\",{\"1\":{\"147\":1}}],[\"扑克牌中的顺子\",{\"0\":{\"147\":1},\"1\":{\"147\":1}}],[\"旋转图像\",{\"0\":{\"145\":1}}],[\"旋转数组\",{\"0\":{\"135\":1}}],[\"螺旋矩阵\",{\"0\":{\"143\":1,\"144\":1}}],[\"矩阵置零\",{\"0\":{\"146\":1}}],[\"矩阵\",{\"0\":{\"142\":1}}],[\"环形子数组的最大和\",{\"1\":{\"141\":1}}],[\"环形数组\",{\"0\":{\"141\":1}}],[\"开始合并\",{\"1\":{\"140\":1}}],[\"直接加入\",{\"1\":{\"140\":1}}],[\"不妨设\",{\"1\":{\"270\":1}}],[\"不需要增加一倍的维度\",{\"1\":{\"264\":1}}],[\"不依赖与\",{\"1\":{\"260\":1}}],[\"不管\",{\"1\":{\"205\":1}}],[\"不是稳定时\",{\"1\":{\"205\":1}}],[\"不超过\",{\"1\":{\"196\":1}}],[\"不独立\",{\"1\":{\"178\":1}}],[\"不知的情况下\",{\"1\":{\"178\":1}}],[\"不带阴影的节点表示隐变量\",{\"1\":{\"177\":1}}],[\"不规则序列建模\",{\"1\":{\"170\":1}}],[\"不用管\",{\"1\":{\"140\":1}}],[\"不同元素可以有相同的动画顺序\",{\"1\":{\"27\":1}}],[\"重参数化技巧可以保证我们从\",{\"1\":{\"255\":1}}],[\"重参数化技巧\",{\"0\":{\"255\":1},\"1\":{\"254\":1,\"255\":1}}],[\"重叠\",{\"1\":{\"139\":1}}],[\"重要\",{\"1\":{\"94\":1}}],[\"重要信息\",{\"1\":{\"94\":2}}],[\"重要容器\",{\"0\":{\"94\":1}}],[\"重要的内容\",{\"1\":{\"66\":1}}],[\"8a所示是一个常用的最大熵模型\",{\"1\":{\"186\":1}}],[\"8\",{\"1\":{\"139\":4,\"205\":3}}],[\"6给出隐马尔可夫模型的图模型表示\",{\"1\":{\"182\":1}}],[\"61\",{\"1\":{\"147\":1}}],[\"6\",{\"1\":{\"139\":4,\"188\":1,\"196\":2,\"205\":3,\"209\":1}}],[\"给定一个有\",{\"1\":{\"181\":1}}],[\"给定一个非负整数数组\",{\"1\":{\"134\":1}}],[\"给你一个\",{\"1\":{\"139\":1}}],[\"插入区间\",{\"0\":{\"139\":1}}],[\"插件来实现\",{\"1\":{\"57\":1}}],[\"插件\",{\"1\":{\"34\":1}}],[\"插件后\",{\"1\":{\"10\":1,\"11\":1}}],[\"区间问题\",{\"0\":{\"138\":1}}],[\"koutn´ık\",{\"1\":{\"281\":1}}],[\"koller\",{\"1\":{\"188\":1}}],[\"kutta法\",{\"0\":{\"212\":1}}],[\"kdocs\",{\"1\":{\"191\":1}}],[\"k=k\",{\"1\":{\"137\":1}}],[\"k\",{\"1\":{\"136\":1,\"137\":1}}],[\"轮转数组\",{\"1\":{\"135\":1,\"141\":1}}],[\"奇数下标\",{\"1\":{\"134\":1}}],[\"偶数下标\",{\"1\":{\"134\":1}}],[\"输出\",{\"1\":{\"134\":1,\"139\":5}}],[\"输入图像通常都是8bits的\",{\"1\":{\"195\":1}}],[\"输入\",{\"1\":{\"134\":1,\"139\":5,\"200\":1}}],[\"7\",{\"1\":{\"134\":5,\"139\":6,\"184\":1,\"210\":1,\"260\":1}}],[\"4所示\",{\"1\":{\"180\":1}}],[\"4\",{\"0\":{\"228\":1,\"248\":1},\"1\":{\"134\":5,\"139\":3,\"172\":4,\"196\":1}}],[\"455\",{\"1\":{\"127\":1}}],[\"示例\",{\"1\":{\"134\":1,\"139\":5}}],[\"当然这种增强破坏了node的双射的性质\",{\"1\":{\"264\":1}}],[\"当固定时\",{\"1\":{\"260\":1}}],[\"当零解\",{\"1\":{\"205\":1}}],[\"当使用卷积maxout网络与cifar\",{\"1\":{\"196\":1}}],[\"当我们计算这个损失函数关于输入\",{\"1\":{\"196\":1}}],[\"当我们增加一个很小的扰动的时候\",{\"1\":{\"195\":1}}],[\"当且仅当\",{\"1\":{\"184\":1,\"205\":1}}],[\"当概率模型中的变量数量比较多时\",{\"1\":{\"172\":1}}],[\"当\",{\"1\":{\"134\":1,\"172\":1,\"195\":1,\"200\":1}}],[\"也能够在增广空间中产生不同的轨迹\",{\"1\":{\"265\":1}}],[\"也就是说对于不同的\",{\"1\":{\"201\":1}}],[\"也叫最大熵模型\",{\"1\":{\"185\":1}}],[\"也称为马尔可夫随机场\",{\"1\":{\"183\":1}}],[\"也称为贝叶斯网络\",{\"1\":{\"178\":1}}],[\"也需要2个参数\",{\"1\":{\"172\":1}}],[\"也和\",{\"1\":{\"172\":1}}],[\"也会被接受\",{\"1\":{\"134\":1}}],[\"也是二值变量\",{\"1\":{\"172\":1}}],[\"也是偶数\",{\"1\":{\"134\":1}}],[\"也是奇数\",{\"1\":{\"134\":1}}],[\"也可以使用服从某个随机分布\",{\"1\":{\"265\":1}}],[\"也可以解释为什么\",{\"1\":{\"195\":1}}],[\"也可以换一个思路\",{\"1\":{\"131\":1}}],[\"也可以通过在特定幻灯片添加\",{\"1\":{\"29\":1}}],[\"90065\",{\"1\":{\"188\":1}}],[\"92\",{\"1\":{\"188\":1}}],[\"922\",{\"1\":{\"134\":1}}],[\"9\",{\"1\":{\"139\":2,\"196\":1,\"210\":1}}],[\"99\",{\"1\":{\"74\":1}}],[\"按照区间起始端点排序的区间列表\",{\"1\":{\"139\":1}}],[\"按奇偶排序数组\",{\"1\":{\"134\":1}}],[\"按奇偶排序数组ii\",{\"0\":{\"134\":1}}],[\"按下\",{\"1\":{\"36\":1,\"38\":1,\"40\":1}}],[\"寻找数组的中心下标\",{\"0\":{\"133\":1}}],[\"有各种高效的数值解和现成的计算框架\",{\"1\":{\"272\":1}}],[\"有唯一解\",{\"1\":{\"260\":1}}],[\"有局部截断误差\",{\"1\":{\"211\":1}}],[\"有\",{\"1\":{\"210\":3,\"270\":1}}],[\"有关\",{\"1\":{\"205\":1}}],[\"有一个大小限制\",{\"1\":{\"196\":1}}],[\"有三种情况\",{\"1\":{\"178\":1}}],[\"有向图和无向图示例\",{\"1\":{\"177\":1}}],[\"有向图和无向图\",{\"1\":{\"177\":1}}],[\"有向图模型\",{\"0\":{\"178\":1},\"1\":{\"178\":1}}],[\"有向图模型使用有向非循环图\",{\"1\":{\"177\":1}}],[\"有向图模型和无向图模型\",{\"1\":{\"177\":1}}],[\"有重叠\",{\"1\":{\"140\":1}}],[\"有效的山脉数组\",{\"0\":{\"132\":1}}],[\"有的同学看到要遍历两个数组\",{\"1\":{\"129\":1}}],[\"其实目前大部分有效的流行的深度学习框架都类似于微分方程\",{\"1\":{\"260\":1}}],[\"其实是不可以的\",{\"1\":{\"130\":1}}],[\"其不可微\",{\"1\":{\"255\":1}}],[\"其在点\",{\"1\":{\"196\":1}}],[\"其分类准确性可以非常出色\",{\"1\":{\"190\":1}}],[\"其所有的父节点之间没有连接\",{\"1\":{\"180\":1}}],[\"其参数数量又可以大幅减少\",{\"1\":{\"180\":1}}],[\"其参数量就可以大幅减少\",{\"1\":{\"172\":1}}],[\"其条件概率分布表示为\",{\"1\":{\"180\":1}}],[\"其条件依赖关系也比较复杂\",{\"1\":{\"172\":1}}],[\"其局部马尔可夫性质为\",{\"1\":{\"178\":1}}],[\"其联合概率为高维空间中的分布\",{\"1\":{\"172\":1}}],[\"其中是一个维向量\",{\"1\":{\"272\":1}}],[\"其中是紧集\",{\"1\":{\"268\":1}}],[\"其中是神经网络架构\",{\"1\":{\"260\":1}}],[\"其中参数\",{\"1\":{\"266\":1}}],[\"其中参数是需要学习的\",{\"1\":{\"264\":1}}],[\"其中仿射层有界\",{\"1\":{\"260\":1}}],[\"其中函数\",{\"1\":{\"186\":1}}],[\"其中\",{\"1\":{\"155\":1,\"172\":1,\"178\":1,\"180\":1,\"181\":2,\"182\":2,\"183\":2,\"184\":3,\"186\":2,\"196\":2,\"200\":1,\"201\":1,\"209\":1,\"210\":1,\"268\":2}}],[\"其他\",{\"0\":{\"131\":1}}],[\"里面的if控制饼干\",{\"1\":{\"130\":1}}],[\"里的\",{\"1\":{\"130\":1}}],[\"一定存在着\",{\"1\":{\"269\":1}}],[\"一定要for\",{\"1\":{\"130\":1}}],[\"一些问题可能会从零初始化中受益\",{\"1\":{\"265\":1}}],[\"一般将neural以图像或者词向量作为输入在增加维度\",{\"1\":{\"270\":1}}],[\"一般将node作为深度学习网络框架中的一部分\",{\"1\":{\"260\":1}}],[\"一般与\",{\"1\":{\"205\":1}}],[\"一般难以直接建模\",{\"1\":{\"172\":1}}],[\"一种简单的参数化模型为sigmoid信念网络\",{\"1\":{\"180\":1}}],[\"一种有效减少参数量的方法是独立性假设\",{\"1\":{\"172\":1}}],[\"一直到最后也没有找到index\",{\"1\":{\"134\":1}}],[\"一半整数是偶数\",{\"1\":{\"134\":1}}],[\"一个resnet块具体定义为\",{\"1\":{\"260\":1}}],[\"一个被数字\",{\"1\":{\"238\":1}}],[\"一个被星标了的苹果文章\",{\"1\":{\"218\":1}}],[\"一个线性模型被迫只关注与权重相接近的信号\",{\"1\":{\"195\":1}}],[\"一个网络模型的权重为\",{\"1\":{\"195\":1}}],[\"一个\",{\"1\":{\"155\":1,\"172\":1}}],[\"一个折线图案例\",{\"1\":{\"75\":1}}],[\"一个散点图案例\",{\"1\":{\"74\":1}}],[\"一个拥有\",{\"1\":{\"64\":1,\"99\":2,\"167\":1}}],[\"一个链接\",{\"1\":{\"8\":1}}],[\"一个简单的幻灯片演示与各种小贴士\",{\"1\":{\"3\":1}}],[\"走不到s\",{\"1\":{\"130\":1}}],[\"持续向前移动\",{\"1\":{\"130\":2}}],[\"因为不同的路径可能会避开某些不良的局部最小\",{\"1\":{\"265\":1}}],[\"因为在没有额外信息的情况下\",{\"1\":{\"265\":1}}],[\"因为它限制了模型在训练数据上的完美拟合能力\",{\"1\":{\"265\":1}}],[\"因为它要求可逆\",{\"1\":{\"264\":1}}],[\"因为它只需要计算一次输入\",{\"1\":{\"196\":1}}],[\"因为最常见和有效的激活函数和网络例如relus\",{\"1\":{\"260\":1}}],[\"因为表示式中的任何舍人误差都使原问题摄动\",{\"1\":{\"209\":1}}],[\"因为另一个值的概率可以通过1减去已知的概率来得到\",{\"1\":{\"172\":1}}],[\"因为另一个可以通过1减去已知的条件概率来得到\",{\"1\":{\"172\":1}}],[\"因为也是二值变量\",{\"1\":{\"172\":1}}],[\"因为\",{\"1\":{\"130\":1}}],[\"因此定理从和定理实际上只是一种理论上表达通过提高维度可以模型的表达能力\",{\"1\":{\"270\":1}}],[\"因此假设空间\",{\"1\":{\"269\":1}}],[\"因此不存在能表示函数\",{\"1\":{\"269\":1}}],[\"因此如果作为假设空间表示能力和逼近能力都非常有限\",{\"1\":{\"268\":1}}],[\"因此作者猜测\",{\"1\":{\"195\":1}}],[\"因此我们一般定义为\",{\"1\":{\"184\":1}}],[\"因此在推断和参数学习时都需要重点考虑\",{\"1\":{\"184\":1}}],[\"因此无法用链式法则对\",{\"1\":{\"184\":1}}],[\"因此可以根据有向图写出因子分解的结果\",{\"1\":{\"178\":1}}],[\"因此可以借助于\",{\"1\":{\"57\":1}}],[\"因此\",{\"1\":{\"54\":1,\"172\":3,\"174\":1,\"178\":3,\"180\":1,\"184\":1,\"196\":2,\"265\":1}}],[\"胃口10\",{\"1\":{\"130\":1}}],[\"胃口\",{\"1\":{\"130\":2,\"131\":1}}],[\"控制\",{\"1\":{\"130\":1}}],[\"控制胃口\",{\"1\":{\"130\":1}}],[\"控制的是饼干\",{\"1\":{\"130\":1}}],[\"而且模型简单更容易设计\",{\"1\":{\"272\":1}}],[\"而且它的概率依赖于的值\",{\"1\":{\"172\":1}}],[\"而其他问题则可能需要随机噪声来提高性能\",{\"1\":{\"265\":1}}],[\"而神经微分方程就是参数共享的resnet网络模型的连续化\",{\"1\":{\"260\":1}}],[\"而该分布是带有参数\",{\"1\":{\"255\":1}}],[\"而不是直接使用梯度值\",{\"1\":{\"196\":1}}],[\"而非线性的模型\",{\"1\":{\"196\":1}}],[\"而非变量\",{\"1\":{\"180\":1}}],[\"而如果对抗扰动足够小的话\",{\"1\":{\"195\":1}}],[\"而\",{\"1\":{\"180\":1}}],[\"而index\",{\"1\":{\"130\":1}}],[\"而if里面的下标\",{\"1\":{\"130\":1}}],[\"而是采用自减的方式\",{\"1\":{\"129\":1}}],[\"饼干9\",{\"1\":{\"130\":1}}],[\"饼干\",{\"1\":{\"130\":1,\"131\":1}}],[\"饼干数组的下标\",{\"1\":{\"129\":1}}],[\"先前对对抗样本的解释引用了了神经网络的假设特性\",{\"1\":{\"195\":1}}],[\"先遍历\",{\"1\":{\"130\":1}}],[\"先将饼干数组和小孩数组排序\",{\"1\":{\"128\":1}}],[\"注意\",{\"1\":{\"178\":1,\"260\":1,\"269\":1}}],[\"注意版本一的代码中\",{\"1\":{\"130\":1}}],[\"注意事项\",{\"0\":{\"130\":1}}],[\"注释之前的内容被视为文章摘要\",{\"1\":{\"82\":1}}],[\"那么根据积分曲线的平移不变形\",{\"1\":{\"272\":1}}],[\"那么称微分方程是自治的\",{\"1\":{\"272\":1}}],[\"那么会大幅度降低参数有效性\",{\"1\":{\"270\":1}}],[\"那么显存占比也将翻倍\",{\"1\":{\"270\":1}}],[\"那么得到了直到阶的单项式\",{\"1\":{\"270\":1}}],[\"那么可以逼近任何函数\",{\"1\":{\"270\":1}}],[\"那么可不可以\",{\"1\":{\"130\":1}}],[\"那么h\",{\"1\":{\"269\":1}}],[\"那么需要提前告知分段点\",{\"1\":{\"266\":1}}],[\"那么如果采用的是自适应步长的ode求解器\",{\"1\":{\"266\":1}}],[\"那么它们可能会陷入相同的局部最小或鞍点\",{\"1\":{\"265\":1}}],[\"那么它们的轨迹也将是相同的\",{\"1\":{\"265\":1}}],[\"那么系统的状态将始终局限于一个低维的子空间\",{\"1\":{\"265\":1}}],[\"那么对于所有的初始点\",{\"1\":{\"265\":1}}],[\"那么对于第\",{\"1\":{\"200\":1}}],[\"那么下一章节的连续归一化流就不能使用\",{\"1\":{\"264\":1}}],[\"那么将\",{\"1\":{\"264\":1}}],[\"那么初值问题\",{\"1\":{\"260\":1}}],[\"那么在bp反向传播的时候就不会对参数梯度进行更新\",{\"1\":{\"255\":1}}],[\"那么他就会有对抗样本\",{\"1\":{\"195\":1}}],[\"那么激励就会增长\",{\"1\":{\"195\":1}}],[\"那么\",{\"1\":{\"178\":1,\"180\":1,\"183\":1,\"268\":1,\"269\":2,\"270\":1}}],[\"那么其联合概率\",{\"1\":{\"172\":1}}],[\"那么当i\",{\"1\":{\"130\":1}}],[\"那么就有\",{\"1\":{\"260\":1}}],[\"那么就可以撸代码了\",{\"1\":{\"128\":1}}],[\"那么就应该优先满足胃口大的\",{\"1\":{\"128\":1}}],[\"那样逻辑其实就复杂了\",{\"1\":{\"129\":1}}],[\"就是从一个分布\",{\"1\":{\"255\":1}}],[\"就是出现如下情况\",{\"1\":{\"130\":1}}],[\"就有问题\",{\"1\":{\"209\":1}}],[\"就会产生很大的改变\",{\"1\":{\"195\":1}}],[\"就可以产生对抗样本\",{\"1\":{\"196\":1}}],[\"就可以最大化的增加模型的激励\",{\"1\":{\"195\":1}}],[\"就可以在几乎肉眼看不出差距的前提下\",{\"1\":{\"190\":1}}],[\"就可以推断出另一个值\",{\"1\":{\"172\":1}}],[\"就构成了一个马尔可夫随机场\",{\"1\":{\"183\":1}}],[\"就想到用两个for循环\",{\"1\":{\"129\":1}}],[\"就不要造成饼干尺寸的浪费\",{\"1\":{\"128\":1}}],[\"遍历饼干并没有再起一个for循环\",{\"1\":{\"129\":1}}],[\"遍历饼干\",{\"1\":{\"129\":1}}],[\"遍历胃口\",{\"1\":{\"129\":1}}],[\"gallieri\",{\"1\":{\"281\":1}}],[\"generalized\",{\"1\":{\"201\":1}}],[\"goodfellow\",{\"1\":{\"196\":1}}],[\"github\",{\"1\":{\"193\":2}}],[\"gibbs\",{\"1\":{\"184\":1}}],[\"gm\",{\"1\":{\"172\":1}}],[\"g\",{\"1\":{\"129\":5,\"130\":1,\"131\":5}}],[\"gronwall\",{\"1\":{\"269\":1}}],[\"grow\",{\"1\":{\"23\":1}}],[\"gradient\",{\"1\":{\"196\":2}}],[\"graph\",{\"1\":{\"177\":2}}],[\"graphical\",{\"1\":{\"172\":2,\"178\":1,\"188\":1}}],[\"green\",{\"1\":{\"23\":2}}],[\"版本一\",{\"1\":{\"129\":1}}],[\"如单高斯分布\",{\"1\":{\"253\":1}}],[\"如何通过图结构来描述变量之间的依\",{\"1\":{\"173\":1}}],[\"如果微分方程是自治的\",{\"1\":{\"272\":1}}],[\"如果与时间无关\",{\"1\":{\"272\":1}}],[\"如果维度增加倍\",{\"1\":{\"270\":1}}],[\"如果所有的路径都从相同的点开始\",{\"1\":{\"265\":1}}],[\"如果增广维度总是初始化为零\",{\"1\":{\"265\":1}}],[\"如果增广的维度被初始化为零\",{\"1\":{\"265\":1}}],[\"如果它们的增广部分是相同的\",{\"1\":{\"265\":1}}],[\"如果我们有一个向量场\",{\"1\":{\"265\":1}}],[\"如果直接进行采样\",{\"1\":{\"255\":1}}],[\"如果原问题不是适定的\",{\"1\":{\"209\":1}}],[\"如果存在一个正常数\",{\"1\":{\"209\":1}}],[\"如果零解\",{\"1\":{\"205\":1}}],[\"如果对某个给定的\",{\"1\":{\"205\":1}}],[\"如果对任意给定的\",{\"1\":{\"205\":1}}],[\"如果对不同的变量的条件概率都共享使用一个参数化模型\",{\"1\":{\"180\":1}}],[\"如果梯度为零\",{\"1\":{\"196\":1}}],[\"如果他的输入有着足够的维度\",{\"1\":{\"195\":1}}],[\"如果用对数线性模型来建模条件概率\",{\"1\":{\"186\":1}}],[\"如果一个分布\",{\"1\":{\"184\":1}}],[\"如果一个团不能被其他的团包含\",{\"1\":{\"184\":1}}],[\"如果假设\",{\"1\":{\"180\":1}}],[\"如果使用参数化模型只需要\",{\"1\":{\"180\":1}}],[\"如果使用表格来记录条件概率需要\",{\"1\":{\"180\":1}}],[\"如果两个节点之间有连边\",{\"1\":{\"177\":1}}],[\"如果分别用\",{\"1\":{\"172\":1}}],[\"如果某些变量之间存在条件独立\",{\"1\":{\"172\":1}}],[\"如果有必要的话\",{\"1\":{\"139\":1}}],[\"如果\",{\"1\":{\"130\":1,\"178\":1,\"183\":1,\"205\":1,\"209\":4,\"268\":1}}],[\"如果你不了解它\",{\"1\":{\"56\":1}}],[\"如果你是一个新手\",{\"1\":{\"55\":1}}],[\"如图11\",{\"1\":{\"180\":1}}],[\"如图可以写出其因子分解的结果\",{\"1\":{\"178\":2}}],[\"如图\",{\"1\":{\"128\":1}}],[\"并不能表示所有的同胚\",{\"1\":{\"270\":1}}],[\"并且可以帮助我们设计更有效的学习算法\",{\"1\":{\"269\":1}}],[\"并且可以更好地表示数据的内在结构和特征\",{\"1\":{\"269\":1}}],[\"并且扰动的\",{\"1\":{\"196\":1}}],[\"并且整个扰动的\",{\"1\":{\"196\":1}}],[\"并且马尔可夫随机场的概率分布一定可以表示成吉布斯分布\",{\"1\":{\"184\":1}}],[\"并且模型简单\",{\"1\":{\"181\":1}}],[\"并且这种角度有很多优点\",{\"1\":{\"174\":1}}],[\"并且它的概率只依赖于的值\",{\"1\":{\"172\":1}}],[\"并且它会自动换行\",{\"1\":{\"8\":1}}],[\"并可以将一个复杂的联合概率模型分解为一些简单条件概率模型的组合\",{\"1\":{\"172\":1}}],[\"并将它们相加以得到总数\",{\"1\":{\"172\":1}}],[\"并想不出反例\",{\"1\":{\"128\":1}}],[\"并统计满足小孩数量\",{\"1\":{\"128\":1}}],[\"全连接网络等都是全局连续的\",{\"1\":{\"260\":1}}],[\"全局最优就是喂饱尽可能多的小孩\",{\"1\":{\"128\":1}}],[\"全屏模式\",{\"0\":{\"38\":1}}],[\"充分利用饼干尺寸喂饱一个\",{\"1\":{\"128\":1}}],[\"排序+贪心法+双指针\",{\"0\":{\"128\":1}}],[\"力扣题目链接\",{\"1\":{\"133\":1}}],[\"力扣\",{\"1\":{\"127\":1,\"134\":1,\"135\":1,\"141\":1,\"147\":1}}],[\"数据点可能分布在一个比观察到的维度更低的流形上\",{\"1\":{\"269\":1}}],[\"数据结构与算法\",{\"0\":{\"148\":1}}],[\"数组反转\",{\"0\":{\"137\":1}}],[\"数组\",{\"0\":{\"126\":1},\"1\":{\"133\":1,\"149\":1}}],[\"数学领域\",{\"1\":{\"260\":1}}],[\"数学基础\",{\"0\":{\"151\":1}}],[\"数学\",{\"0\":{\"104\":1}}],[\"蔬菜\",{\"2\":{\"124\":1}}],[\"本文只讨论基于一阶标准微分方程的神经网络架构\",{\"1\":{\"272\":1}}],[\"本文摘要\",{\"1\":{\"121\":1}}],[\"本章首先给出神经常微分方程\",{\"1\":{\"256\":1}}],[\"本章目录\",{\"0\":{\"175\":1}}],[\"本身存在的现象\",{\"1\":{\"178\":1}}],[\"本页面就是一个示例\",{\"1\":{\"48\":1}}],[\"番茄\",{\"0\":{\"121\":1}}],[\"草莓\",{\"0\":{\"116\":1},\"2\":{\"119\":1}}],[\"大尺寸的饼干既可以满足胃口大的孩子也可以满足胃口小的孩子\",{\"1\":{\"128\":1}}],[\"大\",{\"2\":{\"115\":1,\"217\":1,\"222\":1,\"227\":1,\"232\":1}}],[\"水果\",{\"2\":{\"114\":1,\"119\":1,\"226\":1,\"231\":1,\"236\":1,\"241\":1}}],[\"火龙果\",{\"0\":{\"111\":1},\"2\":{\"114\":1}}],[\"圆\",{\"2\":{\"110\":1,\"125\":1,\"217\":1,\"222\":1,\"227\":1,\"232\":1}}],[\"小饼干先喂饱小胃口\",{\"1\":{\"131\":1}}],[\"小\",{\"2\":{\"110\":1,\"120\":1}}],[\"红\",{\"2\":{\"110\":1,\"115\":1,\"120\":1,\"125\":1,\"217\":1,\"222\":1,\"227\":1,\"232\":1}}],[\"这意味着\",{\"1\":{\"269\":1}}],[\"这会需要额外的\",{\"1\":{\"266\":1}}],[\"这有助于防止过拟合\",{\"1\":{\"265\":1}}],[\"这在数学上意味着\",{\"1\":{\"265\":1}}],[\"这可以通过lyapunov指数来量化\",{\"1\":{\"265\":1}}],[\"这就更进一步降低参数量了\",{\"1\":{\"264\":1}}],[\"这就是为什么\",{\"1\":{\"196\":1}}],[\"这曲线称为积分曲线\",{\"1\":{\"206\":1}}],[\"这使得\",{\"1\":{\"196\":1}}],[\"这确保了每个元素的扰动都是等量的\",{\"1\":{\"196\":1}}],[\"这被称为\",{\"1\":{\"195\":1}}],[\"这也对于部分任务例如图形生成任务来\",{\"1\":{\"269\":1}}],[\"这也大幅提高neuralode的表达能力\",{\"1\":{\"260\":1}}],[\"这也就丟失了输入图像的1\",{\"1\":{\"195\":1}}],[\"这也是常用的技巧\",{\"1\":{\"129\":1}}],[\"这样的扰动通常很小\",{\"1\":{\"196\":1}}],[\"这样\",{\"1\":{\"195\":1,\"196\":1}}],[\"这样联合概率\",{\"1\":{\"186\":1}}],[\"这样才是整体最优解\",{\"1\":{\"128\":1}}],[\"这种隐藏术的意思是\",{\"1\":{\"195\":1}}],[\"这种形式的无向图模型也称为对数线性模型\",{\"1\":{\"186\":1}}],[\"这种形式的分布又称为玻尔兹曼分布\",{\"1\":{\"184\":1}}],[\"这种情况中\",{\"1\":{\"178\":1}}],[\"这\",{\"1\":{\"184\":1}}],[\"这两个模型的区别在于\",{\"1\":{\"180\":1}}],[\"这个理论上可以表示任何同胚映射\",{\"1\":{\"263\":1}}],[\"这个子集仅包含了正\",{\"1\":{\"209\":1}}],[\"这个方法由\",{\"1\":{\"196\":1}}],[\"这个公式是快速梯度符号方法\",{\"1\":{\"196\":1}}],[\"这个条件概率与类似\",{\"1\":{\"172\":1}}],[\"这个例子可以看出饼干9只有喂给胃口为7的小孩\",{\"1\":{\"128\":1}}],[\"这里\",{\"1\":{\"196\":1,\"200\":1,\"209\":1,\"260\":1}}],[\"这里用\",{\"1\":{\"182\":1}}],[\"这里的局部最优就是大饼干喂给胃口大的\",{\"1\":{\"128\":1}}],[\"这里是内容\",{\"1\":{\"107\":1,\"108\":1,\"112\":1,\"113\":1,\"117\":1,\"118\":1,\"122\":1,\"123\":1,\"214\":1,\"215\":1,\"219\":1,\"220\":1,\"224\":1,\"225\":1,\"229\":1,\"230\":1,\"234\":1,\"235\":1,\"239\":1,\"240\":1,\"244\":1,\"245\":1,\"249\":1,\"250\":1}}],[\"这是混沌理论的一个关键观点\",{\"1\":{\"265\":1}}],[\"这是梯度的基本性质\",{\"1\":{\"196\":1}}],[\"这是因为新的区间\",{\"1\":{\"139\":1}}],[\"这是脚注内容\",{\"1\":{\"79\":1,\"101\":1,\"169\":1}}],[\"这是一个条件概率\",{\"1\":{\"172\":2}}],[\"这是一个二值变量\",{\"1\":{\"172\":1}}],[\"这是一个有着\",{\"1\":{\"8\":1}}],[\"这是一个\",{\"0\":{\"8\":1}}],[\"这是一个博客主页的案例\",{\"1\":{\"0\":1}}],[\"樱桃\",{\"0\":{\"106\":1},\"2\":{\"109\":1}}],[\"跳转单词\",{\"1\":{\"99\":1,\"167\":1}}],[\"number\",{\"1\":{\"260\":1}}],[\"nums\",{\"1\":{\"136\":4,\"137\":9}}],[\"nf\",{\"1\":{\"253\":1}}],[\"n\",{\"1\":{\"188\":1}}],[\"nb\",{\"1\":{\"181\":1}}],[\"naive\",{\"1\":{\"181\":1}}],[\"negative\",{\"1\":{\"201\":1}}],[\"neural综述\",{\"1\":{\"266\":1}}],[\"neuralode的一个优点就在于\",{\"1\":{\"270\":1}}],[\"neuralode\",{\"1\":{\"256\":1}}],[\"neural\",{\"1\":{\"199\":1,\"256\":1,\"260\":1,\"264\":2,\"266\":1,\"281\":1}}],[\"networks\",{\"1\":{\"188\":1}}],[\"network\",{\"1\":{\"178\":1,\"180\":1,\"183\":1,\"199\":1}}],[\"newinterval\",{\"1\":{\"139\":5,\"140\":1}}],[\"new\",{\"1\":{\"133\":1}}],[\"n=k\",{\"1\":{\"136\":1}}],[\"nlogn\",{\"1\":{\"129\":1}}],[\"npm\",{\"1\":{\"96\":2,\"164\":2}}],[\"not\",{\"1\":{\"264\":1}}],[\"notation\",{\"0\":{\"200\":1,\"268\":1}}],[\"now\",{\"1\":{\"260\":1}}],[\"node描述了输入的流形如何随着深度流动到输出流形\",{\"1\":{\"269\":1}}],[\"node会连续的变形输入空间而不会撕裂一个连接的区域\",{\"1\":{\"269\":1}}],[\"node的输入是被前神经网络处理过的维度较低的数据\",{\"1\":{\"260\":1}}],[\"node模型的思想来源\",{\"1\":{\"256\":1}}],[\"node从网络架构\",{\"1\":{\"256\":1}}],[\"non\",{\"1\":{\"192\":1}}],[\"none\",{\"1\":{\"29\":1}}],[\"no\",{\"1\":{\"76\":1}}],[\"选项卡\",{\"0\":{\"96\":1,\"164\":1}}],[\"选项全局设置\",{\"1\":{\"29\":1}}],[\"```bash\",{\"1\":{\"96\":3,\"164\":3}}],[\"```\",{\"1\":{\"90\":1,\"96\":3,\"159\":1,\"164\":3}}],[\"```js\",{\"1\":{\"90\":1,\"159\":1}}],[\"`代码`\",{\"1\":{\"90\":1,\"159\":1}}],[\"测试\",{\"0\":{\"88\":1}}],[\"此表达式读作\",{\"1\":{\"209\":1}}],[\"此时空间的每一点都有一条且只有一条积分曲线经过\",{\"1\":{\"206\":1}}],[\"此规则并不是强加上去的\",{\"1\":{\"178\":1}}],[\"此页面应当包含\",{\"1\":{\"85\":1}}],[\"此文字有脚注\",{\"1\":{\"65\":1,\"100\":1,\"168\":1}}],[\"徽章\",{\"1\":{\"84\":1}}],[\"徽章文字\",{\"1\":{\"84\":1}}],[\"分段的node\",{\"0\":{\"266\":1}}],[\"分别是初值问题和的两个解\",{\"1\":{\"269\":1}}],[\"分别计算在每个求解相应的ode\",{\"1\":{\"266\":1}}],[\"分别表示两类条件概率的参数\",{\"1\":{\"182\":1}}],[\"分别表示了四个变量\",{\"1\":{\"177\":1}}],[\"分别为可观测变量和隐变量的取值\",{\"1\":{\"182\":1}}],[\"分类器是一类简单的概率分类器\",{\"1\":{\"181\":1}}],[\"分类为\",{\"1\":{\"83\":1}}],[\"分发饼干\",{\"0\":{\"127\":1},\"1\":{\"127\":1}}],[\"分割垂直幻灯片\",{\"1\":{\"5\":1}}],[\"日\",{\"1\":{\"83\":1}}],[\"月\",{\"1\":{\"83\":1}}],[\"年提出\",{\"1\":{\"196\":1}}],[\"年\",{\"1\":{\"83\":1}}],[\"写作日期为\",{\"1\":{\"83\":1}}],[\"↩︎\",{\"1\":{\"79\":1,\"101\":1,\"169\":1,\"188\":2,\"256\":1,\"266\":1}}],[\"操作\",{\"1\":{\"76\":1}}],[\"with\",{\"1\":{\"281\":1}}],[\"window\",{\"1\":{\"133\":1}}],[\"weierstrass\",{\"1\":{\"270\":1}}],[\"we\",{\"1\":{\"201\":1,\"266\":2}}],[\"wed\",{\"1\":{\"75\":1}}],[\"which\",{\"1\":{\"266\":1}}],[\"white\",{\"1\":{\"192\":1}}],[\"whether\",{\"1\":{\"264\":1}}],[\"where\",{\"1\":{\"69\":1}}],[\"www\",{\"1\":{\"188\":1}}],[\"word\",{\"1\":{\"99\":2}}],[\"warning\",{\"1\":{\"92\":1,\"161\":1}}],[\"p\",{\"1\":{\"268\":1}}],[\"paper\",{\"1\":{\"201\":1}}],[\"partition\",{\"1\":{\"184\":1}}],[\"pgd\",{\"0\":{\"198\":1},\"1\":{\"191\":1,\"193\":1}}],[\"pgm\",{\"1\":{\"172\":1}}],[\"preprint\",{\"1\":{\"281\":1}}],[\"preliminaries\",{\"0\":{\"254\":1}}],[\"principles\",{\"1\":{\"188\":1}}],[\"proof\",{\"1\":{\"266\":2}}],[\"property\",{\"1\":{\"264\":1}}],[\"probability\",{\"1\":{\"178\":1}}],[\"probabilistic\",{\"1\":{\"172\":1,\"188\":1}}],[\"programmercarl\",{\"1\":{\"128\":1}}],[\"process=>operation\",{\"1\":{\"76\":1}}],[\"pdf\",{\"1\":{\"188\":1}}],[\"pii\",{\"1\":{\"188\":1}}],[\"pietra\",{\"1\":{\"186\":1}}],[\"posts\",{\"0\":{\"282\":1}}],[\"position\",{\"1\":{\"74\":1}}],[\"potential\",{\"1\":{\"184\":1}}],[\"push\",{\"1\":{\"140\":5}}],[\"public\",{\"1\":{\"84\":1,\"129\":1,\"131\":1,\"134\":2,\"136\":1,\"137\":1,\"140\":1}}],[\"pnpm\",{\"1\":{\"96\":2,\"164\":2}}],[\"placed=true\",{\"1\":{\"140\":1}}],[\"placed=false\",{\"1\":{\"140\":1}}],[\"placed\",{\"1\":{\"140\":2}}],[\"playground\",{\"1\":{\"79\":1}}],[\"plugin\",{\"1\":{\"59\":1}}],[\"5\",{\"1\":{\"74\":4,\"134\":5,\"139\":10,\"209\":1,\"210\":2,\"211\":1}}],[\"yarn\",{\"1\":{\"96\":2,\"164\":2}}],[\"yaxis\",{\"1\":{\"75\":1}}],[\"yes\",{\"1\":{\"76\":1}}],[\"y\",{\"1\":{\"74\":4}}],[\"散点数据集\",{\"1\":{\"74\":1}}],[\"图\",{\"1\":{\"183\":1}}],[\"图中带阴影的节点表示可观测到的变量\",{\"1\":{\"177\":1}}],[\"图中每个节点表示一个变量\",{\"1\":{\"172\":1}}],[\"图1给出了两个代表性图模型\",{\"1\":{\"177\":1}}],[\"图11\",{\"1\":{\"172\":1,\"182\":1,\"186\":1}}],[\"图由一组节点和节点之间的边组成\",{\"1\":{\"177\":1}}],[\"图模型越来越多地用来设计和分析各种学习算法\",{\"1\":{\"174\":1}}],[\"图模型提供了一种新的角度来解释机器学习模型\",{\"1\":{\"174\":1}}],[\"图模型与机器学习\",{\"0\":{\"174\":1}}],[\"图模型的学习包括图结构的学习和参数的学习\",{\"1\":{\"173\":1}}],[\"图模型的基本问题\",{\"0\":{\"173\":1}}],[\"图模型有三个基本问题\",{\"1\":{\"173\":1}}],[\"图表\",{\"0\":{\"74\":1}}],[\"图片增强\",{\"0\":{\"68\":1}}],[\"交互演示\",{\"0\":{\"73\":1,\"79\":1},\"1\":{\"79\":1}}],[\"捐赠一杯咖啡\",{\"1\":{\"72\":1}}],[\"向图中的局部马尔可夫性质可以表示为\",{\"1\":{\"183\":1}}],[\"向量符号一般用黑斜体小写英文字母\",{\"1\":{\"155\":1}}],[\"向量\",{\"0\":{\"155\":1},\"1\":{\"155\":1}}],[\"向量和向量空间\",{\"0\":{\"154\":1}}],[\"向量空间\",{\"0\":{\"156\":1},\"1\":{\"153\":1}}],[\"向\",{\"1\":{\"72\":1}}],[\"样式化\",{\"0\":{\"72\":1}}],[\"导致梯度估计的误差\",{\"1\":{\"258\":1}}],[\"导致推出循环\",{\"1\":{\"134\":1}}],[\"导入文件\",{\"0\":{\"70\":1}}],[\"导航栏\",{\"1\":{\"48\":1,\"85\":1}}],[\"07038\",{\"1\":{\"281\":1}}],[\"07366\",{\"1\":{\"256\":1}}],[\"06083\",{\"1\":{\"198\":1}}],[\"01\",{\"1\":{\"172\":1}}],[\"0004\",{\"1\":{\"188\":1}}],[\"00\",{\"1\":{\"172\":1}}],[\"0\",{\"1\":{\"69\":1,\"74\":3,\"129\":3,\"131\":2,\"134\":4,\"140\":3,\"209\":1,\"210\":1,\"269\":1}}],[\"组件\",{\"0\":{\"69\":1}}],[\"支持为图片设置颜色模式和大小\",{\"1\":{\"68\":1}}],[\"计算的时间复杂仍然很高\",{\"1\":{\"260\":1}}],[\"计算其他变量的条件概率分布\",{\"1\":{\"173\":1}}],[\"计算过程\",{\"1\":{\"172\":1}}],[\"计算过程如下\",{\"1\":{\"172\":1}}],[\"计算机\",{\"0\":{\"42\":1}}],[\"计划二\",{\"1\":{\"101\":1,\"169\":1}}],[\"计划1\",{\"1\":{\"101\":1,\"169\":1}}],[\"计划\",{\"1\":{\"67\":2}}],[\"脚注\",{\"0\":{\"65\":1,\"100\":1,\"168\":1}}],[\"单词\",{\"1\":{\"64\":1,\"99\":2,\"167\":1}}],[\"我们支持\",{\"1\":{\"274\":1,\"278\":1}}],[\"我们从输出出发得到隐状态层\",{\"1\":{\"260\":1}}],[\"我们证明了其性能较差的一个原因是现有的梯度估计方法的不准确性\",{\"1\":{\"258\":1}}],[\"我们通常希望对输入的扰动\",{\"1\":{\"196\":1}}],[\"我们希望\",{\"1\":{\"196\":1}}],[\"我们来形式化这个直觉\",{\"1\":{\"196\":1}}],[\"我们把这个叫做fgsm\",{\"1\":{\"196\":1}}],[\"我们会很难优化\",{\"1\":{\"196\":1}}],[\"我们已知的一些模型\",{\"1\":{\"196\":1}}],[\"我们假设神经网络是十分线性的\",{\"1\":{\"196\":1}}],[\"我们得出了一个很快的生成对抗样本的方法\",{\"1\":{\"196\":1}}],[\"我们基于线性的假设更简单\",{\"1\":{\"195\":1}}],[\"我们知道\",{\"1\":{\"195\":1}}],[\"我们举个例子说明一下\",{\"1\":{\"178\":1}}],[\"我们可以减少增加维数\",{\"1\":{\"270\":1}}],[\"我们可以提高找到全局最小或更好局部最小的机会\",{\"1\":{\"265\":1}}],[\"我们可以总结一个规律\",{\"1\":{\"178\":1}}],[\"我们可以使用图结构的方式将概率模型可视化\",{\"1\":{\"172\":1}}],[\"我们在证明此现象存在后\",{\"1\":{\"178\":1}}],[\"我们只要将\",{\"1\":{\"195\":1}}],[\"我们只关注在给定图结构时的参数学习\",{\"1\":{\"173\":1}}],[\"我们只需要知道其中一个值\",{\"1\":{\"172\":1}}],[\"我们将这些参数加起来得到总数\",{\"1\":{\"172\":1}}],[\"我们将分别计算每个条件概率所需的参数数量\",{\"1\":{\"172\":1}}],[\"我们需要知道的一个值的概率\",{\"1\":{\"172\":1}}],[\"我在右对齐\",{\"1\":{\"63\":1,\"97\":2,\"165\":2}}],[\"我是居中的\",{\"1\":{\"63\":1,\"97\":2,\"165\":2}}],[\"查看详情\",{\"1\":{\"60\":1,\"61\":1,\"62\":1,\"63\":1,\"64\":1,\"65\":1,\"66\":1,\"67\":1,\"68\":1,\"69\":1,\"70\":1,\"71\":1,\"72\":1,\"73\":1,\"74\":1,\"75\":1,\"76\":1,\"77\":1,\"78\":1,\"101\":1,\"169\":1}}],[\"危险容器\",{\"0\":{\"93\":1,\"162\":1},\"1\":{\"60\":1,\"93\":2,\"162\":2}}],[\"警告容器\",{\"0\":{\"92\":1,\"161\":1},\"1\":{\"60\":1,\"92\":2,\"161\":2}}],[\"与任意序列\",{\"1\":{\"209\":1}}],[\"与前两种情况刚好相反\",{\"1\":{\"178\":1}}],[\"与\",{\"1\":{\"60\":1,\"90\":2,\"139\":1,\"159\":2,\"178\":4,\"193\":1}}],[\"vector\",{\"1\":{\"155\":1}}],[\"vector<vector<int>>\",{\"1\":{\"140\":3}}],[\"vector<int>\",{\"1\":{\"129\":2,\"131\":2,\"134\":4,\"136\":2,\"137\":1,\"140\":1}}],[\"void\",{\"1\":{\"136\":1,\"137\":1}}],[\"vue\",{\"0\":{\"79\":1},\"1\":{\"79\":2}}],[\"vuepress\",{\"0\":{\"58\":1},\"1\":{\"54\":2,\"56\":2,\"57\":1,\"58\":2,\"59\":1,\"84\":1,\"96\":3,\"164\":3}}],[\"validmountainarray\",{\"1\":{\"134\":1}}],[\"value\",{\"1\":{\"75\":1,\"264\":1}}],[\"variable\",{\"1\":{\"60\":1}}],[\"安全的在\",{\"1\":{\"60\":1}}],[\"提高模型的表达能力的同时\",{\"1\":{\"264\":1}}],[\"提示\",{\"1\":{\"84\":1}}],[\"提示容器\",{\"0\":{\"60\":1,\"89\":1,\"91\":1,\"160\":1},\"1\":{\"60\":1,\"90\":1,\"91\":2,\"159\":1,\"160\":2}}],[\"提供更加丰富的写作功能\",{\"1\":{\"59\":1}}],[\"主题包含了一个自定义徽章可以使用\",{\"1\":{\"84\":1}}],[\"主题扩展了更多\",{\"1\":{\"59\":1}}],[\"主题扩展\",{\"0\":{\"59\":1}}],[\"主要从\",{\"1\":{\"54\":1}}],[\"主要功能与配置演示\",{\"0\":{\"45\":1}}],[\"中描述的缺陷\",{\"1\":{\"263\":1}}],[\"中已经表述过\",{\"1\":{\"263\":1}}],[\"中采用的方法非常简单\",{\"1\":{\"263\":1}}],[\"中提到过对输入进行维度增加可以提高模型的表达能力\",{\"1\":{\"263\":1}}],[\"中进行采样\",{\"1\":{\"255\":1}}],[\"中定义的分布形式也称为吉布斯分布\",{\"1\":{\"184\":1}}],[\"中一半整数是奇数\",{\"1\":{\"134\":1}}],[\"中设置页面信息\",{\"1\":{\"83\":1}}],[\"中使用\",{\"1\":{\"60\":1}}],[\"中的都是同胚映射\",{\"1\":{\"268\":1}}],[\"中的最大团集合\",{\"1\":{\"184\":1}}],[\"中的局部马尔可夫性质\",{\"1\":{\"184\":1}}],[\"中的节点\",{\"1\":{\"183\":1}}],[\"中的变量取值为\",{\"1\":{\"180\":1}}],[\"中的每个节点都对应一个随机变量\",{\"1\":{\"178\":1}}],[\"中的\",{\"1\":{\"58\":1}}],[\"中很重要的一个概念\",{\"1\":{\"56\":1}}],[\"对单项式进行组合以逼近目标连续函数\",{\"1\":{\"270\":1}}],[\"对模型的表达能力很低\",{\"1\":{\"269\":1}}],[\"对输入做仿射变换\",{\"0\":{\"264\":1}}],[\"对ode的研究不管是理论还是数值分析\",{\"1\":{\"260\":1}}],[\"对所有\",{\"1\":{\"210\":1}}],[\"对一切\",{\"1\":{\"209\":1,\"210\":1}}],[\"对一个简单的线性网络来说\",{\"1\":{\"195\":1}}],[\"对一个更一般的贝叶斯网络\",{\"1\":{\"178\":1}}],[\"对任何同胚映射\",{\"1\":{\"270\":1}}],[\"对任何\",{\"1\":{\"209\":1}}],[\"对大的\",{\"1\":{\"209\":1}}],[\"对某个\",{\"1\":{\"209\":1}}],[\"对maxout网络\",{\"1\":{\"196\":1}}],[\"对softmax分类器攻击达到了99\",{\"1\":{\"196\":1}}],[\"对人类的感知影响不大\",{\"1\":{\"196\":1}}],[\"对抗扰动让网络的激励增加了\",{\"1\":{\"195\":1}}],[\"对抗样本的线性解释\",{\"0\":{\"195\":1}}],[\"对抗样本\",{\"1\":{\"193\":1,\"203\":1}}],[\"对抗鲁棒性\",{\"0\":{\"191\":1}}],[\"对抗攻击篇\",{\"1\":{\"193\":1}}],[\"对抗攻击的分类\",{\"0\":{\"192\":1}}],[\"对抗攻击\",{\"0\":{\"189\":1}}],[\"对数线性模型也称为条件最大熵模型或softmax\",{\"1\":{\"186\":1}}],[\"对数线性模型\",{\"0\":{\"186\":1}}],[\"对数组进行排序\",{\"1\":{\"134\":1}}],[\"对齐\",{\"0\":{\"97\":1,\"165\":1}}],[\"对于可测映射\",{\"1\":{\"268\":1}}],[\"对于非线性系统\",{\"1\":{\"265\":1}}],[\"对于给定的初值\",{\"1\":{\"264\":1}}],[\"对于node的表示能力用严格的数学理论进行详细论述\",{\"1\":{\"256\":1}}],[\"对于图中的\",{\"1\":{\"183\":1}}],[\"对于变量\",{\"1\":{\"180\":1}}],[\"对于每种组合\",{\"1\":{\"172\":1}}],[\"对于每个的值\",{\"1\":{\"172\":1}}],[\"对于的每个值\",{\"1\":{\"172\":1}}],[\"对于一个可微分函数\",{\"1\":{\"196\":1}}],[\"对于一个多分类网络\",{\"1\":{\"192\":1}}],[\"对于一个随机向量\",{\"1\":{\"183\":1}}],[\"对于一个概率模型\",{\"1\":{\"173\":1}}],[\"对于一个\",{\"1\":{\"172\":1,\"178\":1}}],[\"对于\",{\"1\":{\"84\":1,\"211\":1}}],[\"对\",{\"1\":{\"58\":1,\"210\":1,\"211\":1}}],[\"为推导\",{\"1\":{\"210\":1}}],[\"为大于零的某个数\",{\"1\":{\"209\":1}}],[\"为坐标的\",{\"1\":{\"206\":1}}],[\"为不稳定的\",{\"1\":{\"205\":1}}],[\"为全局渐近稳定的或简称全局稳定的\",{\"1\":{\"205\":1}}],[\"为渐近稳定的\",{\"1\":{\"205\":1}}],[\"为稳定的\",{\"1\":{\"205\":1}}],[\"为权重向量\",{\"1\":{\"186\":1}}],[\"为定义在\",{\"1\":{\"186\":1}}],[\"为能量函数\",{\"1\":{\"184\":1}}],[\"为随机向量\",{\"1\":{\"184\":1}}],[\"为除\",{\"1\":{\"183\":1}}],[\"为变量\",{\"1\":{\"183\":1}}],[\"为隐变量\",{\"1\":{\"182\":1}}],[\"为可观测变量\",{\"1\":{\"182\":1}}],[\"为离散值\",{\"1\":{\"181\":1}}],[\"为连续值\",{\"1\":{\"181\":1}}],[\"为概率分布的参数\",{\"1\":{\"181\":1}}],[\"为\",{\"1\":{\"178\":1,\"184\":1}}],[\"为偶数时\",{\"1\":{\"134\":1}}],[\"为奇数时\",{\"1\":{\"134\":1}}],[\"为了最大化损失增量\",{\"1\":{\"196\":1}}],[\"为了描述方便\",{\"1\":{\"182\":1}}],[\"为了减少模型参数\",{\"1\":{\"180\":1}}],[\"为了满足更多的小孩\",{\"1\":{\"128\":1}}],[\"为了丰富文档写作\",{\"1\":{\"58\":1}}],[\"为每个元素返回\",{\"1\":{\"196\":1}}],[\"为每个\",{\"1\":{\"56\":1}}],[\"内容\",{\"1\":{\"57\":1}}],[\"ian\",{\"1\":{\"196\":1}}],[\"io\",{\"1\":{\"193\":2}}],[\"i+n\",{\"1\":{\"136\":1}}],[\"i++\",{\"1\":{\"131\":1,\"134\":3,\"136\":1}}],[\"i<nums\",{\"1\":{\"136\":1}}],[\"i<arr\",{\"1\":{\"134\":2}}],[\"i=0\",{\"1\":{\"136\":1}}],[\"i=index+1\",{\"1\":{\"134\":1}}],[\"i=1\",{\"1\":{\"134\":1}}],[\"ii\",{\"0\":{\"144\":1},\"1\":{\"134\":1}}],[\"if\",{\"1\":{\"129\":1,\"130\":2,\"131\":1,\"134\":5,\"137\":1,\"140\":4}}],[\"image\",{\"1\":{\"178\":2,\"181\":1,\"183\":1,\"184\":1,\"211\":1,\"212\":3}}],[\"img\",{\"1\":{\"128\":1,\"130\":1,\"178\":4,\"190\":1}}],[\"important\",{\"1\":{\"94\":1}}],[\"i\",{\"1\":{\"96\":1,\"129\":4,\"130\":2,\"131\":3,\"134\":15,\"136\":1,\"164\":1,\"200\":1}}],[\"is\",{\"1\":{\"69\":2,\"260\":1,\"264\":1}}],[\"id\",{\"0\":{\"99\":1,\"167\":1},\"1\":{\"64\":1,\"99\":2,\"167\":1}}],[\"item\",{\"1\":{\"270\":4}}],[\"it\",{\"1\":{\"57\":2}}],[\"inequality\",{\"1\":{\"196\":1}}],[\"insert\",{\"1\":{\"140\":1}}],[\"into\",{\"1\":{\"264\":1}}],[\"interval在左边\",{\"1\":{\"140\":1}}],[\"interval\",{\"1\":{\"140\":8}}],[\"intervals\",{\"1\":{\"139\":5,\"140\":2}}],[\"int\",{\"1\":{\"129\":4,\"131\":3,\"134\":6,\"136\":4,\"137\":1,\"140\":2}}],[\"info\",{\"1\":{\"90\":1,\"159\":1}}],[\"index=\",{\"1\":{\"136\":1}}],[\"index==0||index==arr\",{\"1\":{\"134\":1}}],[\"index==0表明arr\",{\"1\":{\"134\":1}}],[\"index=arr\",{\"1\":{\"134\":1}}],[\"index=0\",{\"1\":{\"134\":1}}],[\"index++\",{\"1\":{\"131\":1,\"134\":1}}],[\"index\",{\"1\":{\"27\":1,\"129\":4,\"130\":3,\"131\":4,\"136\":1}}],[\"in\",{\"1\":{\"21\":3,\"201\":1,\"264\":1}}],[\"inline\",{\"1\":{\"9\":1}}],[\"会带来如下问题\",{\"1\":{\"270\":1}}],[\"会导致模型的损失增加\",{\"1\":{\"196\":1}}],[\"会让模型更容易受到攻击\",{\"1\":{\"196\":1}}],[\"会让文字在不超出幻灯片范围的情况下尽可能大\",{\"1\":{\"14\":1}}],[\"会使用\",{\"1\":{\"57\":1}}],[\"扩展\",{\"0\":{\"57\":1,\"58\":1},\"1\":{\"58\":1}}],[\"是机器学习和模式识别领域中的一个重要概念\",{\"1\":{\"269\":1}}],[\"是双射\",{\"1\":{\"269\":1}}],[\"是同胚映射\",{\"1\":{\"269\":1}}],[\"是的意义下的通用逼近器\",{\"1\":{\"268\":1}}],[\"是euclidean\",{\"1\":{\"268\":1}}],[\"是否使用随机噪声以及具体的噪声水平通常是基于经验和实验调整的\",{\"1\":{\"265\":1}}],[\"是否执行操作\",{\"1\":{\"76\":1}}],[\"是网络层数\",{\"1\":{\"260\":1}}],[\"是网络参数\",{\"1\":{\"196\":1}}],[\"是连续是非常合理的\",{\"1\":{\"260\":1}}],[\"是连续的\",{\"1\":{\"209\":1,\"210\":1,\"260\":1,\"269\":3}}],[\"是连续的且在\",{\"1\":{\"209\":1}}],[\"是该网络架构的参数\",{\"1\":{\"260\":1}}],[\"是没有梯度信息的\",{\"1\":{\"255\":1}}],[\"是适定的\",{\"1\":{\"209\":1}}],[\"是预激活值\",{\"1\":{\"200\":1}}],[\"是损失函数\",{\"1\":{\"196\":1}}],[\"是在给定大小限制下\",{\"1\":{\"196\":1}}],[\"是真实标签\",{\"1\":{\"196\":1}}],[\"是会被忽略的\",{\"1\":{\"195\":1}}],[\"是配分函数\",{\"1\":{\"184\":1}}],[\"是定义在团\",{\"1\":{\"184\":1}}],[\"是用来表示一种含有隐变量的马尔可夫过程\",{\"1\":{\"182\":1}}],[\"是条件概率分布\",{\"1\":{\"181\":1}}],[\"是可学习的参数\",{\"1\":{\"180\":1}}],[\"是我们用概率图的因子分解表示联合概率后\",{\"1\":{\"178\":1}}],[\"是一制度\",{\"1\":{\"260\":1}}],[\"是一系列高维数据上灵活可重参数化概率分布的方法\",{\"1\":{\"253\":1}}],[\"是一个\",{\"1\":{\"272\":2}}],[\"是一个含参的仿射变换\",{\"1\":{\"264\":1}}],[\"是一个收玫于\",{\"1\":{\"209\":1}}],[\"是一个不依赖于\",{\"1\":{\"209\":1}}],[\"是一个小的扰动量\",{\"1\":{\"196\":1}}],[\"是一个小常数\",{\"1\":{\"196\":1}}],[\"是一个实数\",{\"1\":{\"155\":1}}],[\"是一类用无向图来描述一组具有局部马尔可夫性质的随机向量\",{\"1\":{\"183\":1}}],[\"是一类用有向图来描述随机向量概率分布的模型\",{\"1\":{\"178\":1}}],[\"是一种通过使用神经网络参数化向量场来结合常微分方程和神经网络的一种全新的深度学习模型\",{\"1\":{\"256\":1}}],[\"是一种快速而简单的方法\",{\"1\":{\"196\":1}}],[\"是一种生成模型\",{\"1\":{\"180\":1}}],[\"是一种判别模型\",{\"1\":{\"180\":1}}],[\"是指一种用图结构来描述多元随机变量之间条件独立关系的概率模型\",{\"1\":{\"172\":1}}],[\"是由于模型的线性所导致的\",{\"1\":{\"195\":1}}],[\"是由\",{\"1\":{\"155\":1,\"210\":1}}],[\"是由一组实数组成的有序数组\",{\"1\":{\"155\":1}}],[\"是符合条件才移动的\",{\"1\":{\"130\":1}}],[\"是固定移动的\",{\"1\":{\"130\":1}}],[\"是里的下标i\",{\"1\":{\"130\":1}}],[\"是先遍历的胃口\",{\"1\":{\"130\":1}}],[\"是\",{\"1\":{\"56\":1,\"178\":2,\"180\":1,\"181\":1,\"196\":1,\"268\":1}}],[\"是最爱聪聪园的笨丁呢\",{\"1\":{\"1\":1}}],[\"演示\",{\"1\":{\"55\":1}}],[\"请使用绝对链接\",{\"1\":{\"84\":1}}],[\"请阅读\",{\"1\":{\"58\":1}}],[\"请先阅读\",{\"1\":{\"55\":1}}],[\"请滚动鼠标滚轮进入下一页\",{\"1\":{\"3\":1}}],[\"介绍\",{\"0\":{\"55\":1,\"157\":1,\"274\":1,\"278\":1},\"1\":{\"55\":1,\"56\":1,\"171\":1}}],[\"以为输入\",{\"1\":{\"268\":1}}],[\"以找到最适合他们特定问题的方法\",{\"1\":{\"265\":1}}],[\"以后简称node\",{\"1\":{\"256\":1}}],[\"以收玫速度\",{\"1\":{\"209\":1}}],[\"以确保扰动是微小的\",{\"1\":{\"196\":1}}],[\"以下\",{\"1\":{\"178\":1}}],[\"以一种直观\",{\"1\":{\"172\":1}}],[\"以及初值条件也有可能存在误差\",{\"1\":{\"209\":1}}],[\"以及96\",{\"1\":{\"196\":1}}],[\"以及向量的线性变换和有限维的线性方程组\",{\"1\":{\"153\":1}}],[\"以及所有不在\",{\"1\":{\"12\":1}}],[\"以便当\",{\"1\":{\"134\":1}}],[\"以便\",{\"1\":{\"54\":1}}],[\"文章标题列表\",{\"1\":{\"85\":1}}],[\"文章加密\",{\"2\":{\"53\":1}}],[\"文件夹的图片\",{\"1\":{\"84\":1}}],[\"文件放置在一起\",{\"1\":{\"84\":1}}],[\"文件\",{\"1\":{\"54\":1}}],[\"文件生成页面\",{\"1\":{\"54\":1}}],[\"文字结尾应该有深蓝色的\",{\"1\":{\"84\":1}}],[\"文字\",{\"1\":{\"51\":2}}],[\"文字段落\",{\"1\":{\"51\":24}}],[\"文字并包含\",{\"1\":{\"8\":1}}],[\"段落\",{\"1\":{\"51\":2}}],[\"密码加密的文章\",{\"0\":{\"51\":1}}],[\"返回顶部按钮\",{\"1\":{\"48\":1,\"85\":1}}],[\"页脚\",{\"1\":{\"48\":1,\"85\":1}}],[\"页面结构\",{\"0\":{\"85\":1}}],[\"页面内容\",{\"0\":{\"84\":1}}],[\"页面配置\",{\"0\":{\"82\":1},\"1\":{\"83\":1},\"2\":{\"87\":1}}],[\"页面引入配置\",{\"1\":{\"56\":1}}],[\"页面信息\",{\"0\":{\"83\":1},\"1\":{\"48\":1}}],[\"页面展示\",{\"1\":{\"46\":1,\"70\":1}}],[\"评论\",{\"1\":{\"48\":1,\"85\":1}}],[\"链接\",{\"1\":{\"48\":1,\"60\":1,\"90\":2,\"159\":2}}],[\"上计算\",{\"1\":{\"266\":1}}],[\"上满足常数为\",{\"1\":{\"210\":1}}],[\"上关于变量\",{\"1\":{\"209\":1}}],[\"上时\",{\"1\":{\"196\":1}}],[\"上\",{\"1\":{\"196\":1,\"209\":1}}],[\"上述的解释说明\",{\"1\":{\"195\":1}}],[\"上的\",{\"1\":{\"272\":1}}],[\"上的特征向量\",{\"1\":{\"186\":1}}],[\"上的势能函数\",{\"1\":{\"184\":1}}],[\"上下角标\",{\"0\":{\"62\":1}}],[\"上一篇\",{\"1\":{\"48\":1}}],[\"上使用\",{\"1\":{\"40\":1}}],[\"编辑此页链接\",{\"1\":{\"48\":1}}],[\"贡献者\",{\"1\":{\"48\":1,\"85\":1}}],[\"侧边栏\",{\"1\":{\"48\":1,\"85\":1}}],[\"禁用\",{\"2\":{\"50\":1}}],[\"禁用了如下功能\",{\"1\":{\"48\":1}}],[\"禁用展示\",{\"1\":{\"46\":1,\"70\":1}}],[\"展示\",{\"0\":{\"54\":1},\"1\":{\"46\":1,\"70\":1}}],[\"的形式如下\",{\"1\":{\"270\":1}}],[\"的可测子集\",{\"1\":{\"268\":1}}],[\"的基本架构是一样的\",{\"1\":{\"266\":1}}],[\"的随机变量来初始化额外维度的初始值\",{\"1\":{\"265\":1}}],[\"的定义\",{\"1\":{\"256\":1}}],[\"的局部截断误差是\",{\"1\":{\"211\":1}}],[\"的局部条件概率的连乘形式\",{\"1\":{\"178\":1}}],[\"的唯一解\",{\"1\":{\"210\":1}}],[\"的大\",{\"1\":{\"209\":1}}],[\"的已知序列\",{\"1\":{\"209\":1}}],[\"的常数\",{\"1\":{\"209\":1}}],[\"的解\",{\"1\":{\"205\":2}}],[\"的零解\",{\"1\":{\"205\":2}}],[\"的由初始条件\",{\"1\":{\"205\":1}}],[\"的上界和下界\",{\"1\":{\"200\":1}}],[\"的平均置信度\",{\"1\":{\"196\":1}}],[\"的攻击成功率\",{\"1\":{\"196\":3}}],[\"的扰动值\",{\"1\":{\"200\":1}}],[\"的扰动\",{\"1\":{\"196\":1}}],[\"的设计基于以下直觉\",{\"1\":{\"196\":1}}],[\"的梯度\",{\"1\":{\"196\":2}}],[\"的梯度时\",{\"1\":{\"196\":1}}],[\"的核心\",{\"1\":{\"196\":1}}],[\"的正比例\",{\"1\":{\"196\":1}}],[\"的对数形式为\",{\"1\":{\"186\":1}}],[\"的邻居集合\",{\"1\":{\"183\":1}}],[\"的参数\",{\"1\":{\"181\":1}}],[\"的先验概率分布的参数\",{\"1\":{\"181\":1}}],[\"的情况下\",{\"1\":{\"181\":1}}],[\"的条件概率为\",{\"1\":{\"181\":1}}],[\"的父节点数量为\",{\"1\":{\"180\":1}}],[\"的父类\",{\"1\":{\"178\":1}}],[\"的非后代变量\",{\"1\":{\"178\":1}}],[\"的头相连\",{\"1\":{\"178\":1}}],[\"的头和\",{\"1\":{\"178\":2}}],[\"的尾巴相连\",{\"1\":{\"178\":1}}],[\"的角度来看\",{\"1\":{\"178\":2}}],[\"的联合概率分布的模型\",{\"1\":{\"183\":1}}],[\"的联合概率分布可以分解为每个随机变量\",{\"1\":{\"178\":1}}],[\"的联合概率分解为\",{\"1\":{\"172\":1}}],[\"的所有父节点变量集合\",{\"1\":{\"178\":1}}],[\"的示例\",{\"1\":{\"177\":1}}],[\"的概率依赖于和的组合\",{\"1\":{\"172\":1}}],[\"的取值空间\",{\"1\":{\"184\":1}}],[\"的取值\",{\"1\":{\"172\":1}}],[\"的第\",{\"1\":{\"155\":1,\"200\":1}}],[\"的逻辑\",{\"1\":{\"130\":1}}],[\"的\",{\"1\":{\"64\":1,\"83\":1,\"99\":2,\"167\":1,\"210\":1,\"255\":1}}],[\"的同时点击幻灯片的任何元素\",{\"1\":{\"40\":1}}],[\"的段落\",{\"1\":{\"8\":1}}],[\"缩放\",{\"0\":{\"40\":1}}],[\"odes\",{\"1\":{\"266\":1,\"281\":1}}],[\"ode\",{\"1\":{\"260\":1,\"264\":1,\"269\":1}}],[\"oddindex\",{\"1\":{\"134\":3}}],[\"or\",{\"1\":{\"264\":1}}],[\"ordinary\",{\"1\":{\"256\":1}}],[\"org\",{\"1\":{\"198\":1,\"256\":1}}],[\"oh\",{\"1\":{\"209\":1}}],[\"of\",{\"1\":{\"188\":1,\"201\":2,\"260\":2,\"264\":3,\"266\":2}}],[\"offer\",{\"1\":{\"147\":1}}],[\"opens\",{\"1\":{\"133\":1}}],[\"options\",{\"1\":{\"74\":1}}],[\"one\",{\"1\":{\"77\":2,\"266\":1}}],[\"o\",{\"1\":{\"36\":1,\"129\":2}}],[\"output\",{\"1\":{\"264\":2}}],[\"out\",{\"1\":{\"21\":3}}],[\"或者其他激活函数例如sigmoid\",{\"1\":{\"260\":1}}],[\"或最大熵模型\",{\"1\":{\"186\":1}}],[\"或马尔可夫网络\",{\"1\":{\"183\":1}}],[\"或信念网络\",{\"1\":{\"178\":1}}],[\"或一组随机变量\",{\"1\":{\"177\":1}}],[\"或小写希腊字母\",{\"1\":{\"155\":1}}],[\"或第\",{\"1\":{\"155\":1}}],[\"或称线性空间\",{\"1\":{\"153\":1}}],[\"或\",{\"1\":{\"36\":1,\"38\":1,\"196\":2,\"272\":1}}],[\"equations\",{\"1\":{\"256\":1}}],[\"euler\",{\"1\":{\"210\":2,\"211\":1}}],[\"euler法\",{\"0\":{\"210\":1}}],[\"easily\",{\"1\":{\"201\":1}}],[\"ease\",{\"1\":{\"201\":1}}],[\"exposition\",{\"1\":{\"201\":1}}],[\"e\",{\"1\":{\"200\":1}}],[\"efficient\",{\"1\":{\"199\":1}}],[\"edu\",{\"1\":{\"188\":2}}],[\"et\",{\"1\":{\"182\":1,\"186\":2}}],[\"else\",{\"1\":{\"134\":2,\"140\":2}}],[\"elements\",{\"1\":{\"281\":1}}],[\"element\",{\"1\":{\"5\":1}}],[\"evenindex\",{\"1\":{\"134\":3}}],[\"enumerate\",{\"1\":{\"270\":2}}],[\"entropy\",{\"1\":{\"186\":1}}],[\"energy\",{\"1\":{\"184\":1}}],[\"end\",{\"1\":{\"77\":3,\"129\":2,\"131\":2,\"137\":2,\"270\":2}}],[\"enhance\",{\"1\":{\"59\":1}}],[\"e=>end\",{\"1\":{\"76\":1}}],[\"echarts\",{\"0\":{\"75\":1},\"1\":{\"75\":1}}],[\"esc\",{\"1\":{\"36\":1}}],[\"+k\",{\"1\":{\"137\":2}}],[\"+=\",{\"1\":{\"134\":2}}],[\"+\",{\"1\":{\"34\":2}}],[\"xaxis\",{\"1\":{\"75\":1}}],[\"x\",{\"1\":{\"34\":2,\"74\":5}}],[\"语法\",{\"0\":{\"78\":1},\"1\":{\"59\":1}}],[\"语法进行了扩展\",{\"1\":{\"58\":1}}],[\"语法扩展\",{\"1\":{\"57\":1}}],[\"语法来分布高亮特定行\",{\"1\":{\"34\":1}}],[\"语法的各种标记\",{\"1\":{\"6\":1,\"7\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":1}}],[\"功能详情\",{\"1\":{\"276\":1,\"280\":1}}],[\"功能\",{\"0\":{\"32\":1,\"33\":1,\"35\":1,\"37\":1,\"39\":1,\"273\":1,\"277\":1},\"1\":{\"274\":1,\"278\":1}}],[\"过渡动画\",{\"0\":{\"31\":1}}],[\"可能会轻易被对抗攻击打破\",{\"1\":{\"190\":1}}],[\"可能的值\",{\"1\":{\"29\":1}}],[\"可以找到仿射函数\",{\"1\":{\"270\":1}}],[\"可以减少数据的维度\",{\"1\":{\"269\":1}}],[\"可以让一个node由若干的不同范围的的node表示\",{\"1\":{\"266\":1}}],[\"可以出现更高维度\",{\"1\":{\"260\":1}}],[\"可以帮助我们更好的进行深度学习的研究\",{\"1\":{\"260\":1}}],[\"可以选择不同的参数\",{\"1\":{\"201\":1}}],[\"可以引入任意一个错误类别\",{\"1\":{\"192\":1}}],[\"可以表示为一系列定义在最大团上的非负函数的乘积形式\",{\"1\":{\"184\":1}}],[\"可以得到\",{\"1\":{\"183\":1}}],[\"可以存在循环\",{\"1\":{\"183\":1}}],[\"可以有效防止过拟合\",{\"1\":{\"181\":1}}],[\"可以用多项分布建模\",{\"1\":{\"181\":1}}],[\"可以用高斯分布建模\",{\"1\":{\"181\":1}}],[\"可以用一个联合概率表来记录每一种取值的概率\",{\"1\":{\"172\":1}}],[\"可以使用参数化模型来建模有向图模型中的条件概率分布\",{\"1\":{\"180\":1}}],[\"可以写出其因子分解的结果\",{\"1\":{\"178\":1}}],[\"可以分解为\",{\"1\":{\"172\":1,\"181\":1}}],[\"可以合并区间\",{\"1\":{\"139\":1}}],[\"可以看出来\",{\"1\":{\"130\":1}}],[\"可以尝试使用贪心策略\",{\"1\":{\"128\":1}}],[\"可以根据文件结构将它们转换为不同的页面\",{\"1\":{\"54\":1}}],[\"可以通过配置中的\",{\"1\":{\"29\":1}}],[\"第\",{\"1\":{\"200\":1}}],[\"第一个显示\",{\"1\":{\"27\":1}}],[\"第二个显示\",{\"1\":{\"27\":2}}],[\"属性支持\",{\"0\":{\"98\":1,\"166\":1}}],[\"属性局部设置\",{\"1\":{\"29\":1}}],[\"属性改变元素的动画顺序\",{\"1\":{\"27\":1}}],[\"属性自定义幻灯片背景\",{\"1\":{\"17\":1}}],[\"顺序\",{\"0\":{\"27\":1}}],[\"渐近\",{\"1\":{\"205\":1}}],[\"渐近稳定\",{\"1\":{\"205\":1}}],[\"渐变\",{\"0\":{\"28\":1,\"29\":1,\"30\":1}}],[\"渐出\",{\"1\":{\"25\":1}}],[\"渐入\",{\"1\":{\"25\":1}}],[\"元素产生过渡动画效果\",{\"1\":{\"31\":1}}],[\"元素使其拥有多个动画片段\",{\"1\":{\"25\":1}}],[\"元素上添加属性\",{\"1\":{\"5\":1}}],[\"多个动画片段\",{\"0\":{\"25\":1}}],[\"does\",{\"1\":{\"264\":2}}],[\"down\",{\"1\":{\"21\":1}}],[\"dimensional\",{\"1\":{\"264\":1}}],[\"differential\",{\"1\":{\"256\":1}}],[\"distribution\",{\"1\":{\"178\":1,\"184\":2}}],[\"directed\",{\"1\":{\"177\":1,\"178\":1}}],[\"dag\",{\"1\":{\"177\":1}}],[\"datasets\",{\"1\":{\"74\":1}}],[\"data\",{\"1\":{\"17\":1,\"27\":1,\"29\":1,\"31\":1,\"74\":2,\"75\":2}}],[\"design\",{\"1\":{\"270\":1}}],[\"desc\",{\"1\":{\"69\":1}}],[\"determine\",{\"1\":{\"264\":2}}],[\"details\",{\"1\":{\"95\":1,\"163\":1}}],[\"deep\",{\"1\":{\"198\":1}}],[\"della\",{\"1\":{\"186\":1}}],[\"d\",{\"1\":{\"34\":1,\"96\":3,\"164\":3,\"188\":1}}],[\"foo\",{\"0\":{\"277\":1},\"1\":{\"278\":1}}],[\"follows\",{\"1\":{\"266\":1}}],[\"for里的i指向饼干9\",{\"1\":{\"130\":1}}],[\"for\",{\"1\":{\"129\":1,\"130\":1,\"131\":1,\"134\":3,\"136\":1,\"140\":1,\"193\":1,\"201\":1,\"264\":1}}],[\"flows\",{\"1\":{\"253\":1}}],[\"flowchart\",{\"1\":{\"77\":2}}],[\"fgsm\",{\"0\":{\"193\":1},\"1\":{\"193\":2,\"196\":7}}],[\"function\",{\"1\":{\"184\":3}}],[\"fast\",{\"1\":{\"196\":2}}],[\"false\",{\"1\":{\"134\":3}}],[\"fade\",{\"1\":{\"21\":8,\"29\":1}}],[\"finite\",{\"1\":{\"260\":1}}],[\"findcontentchildren\",{\"1\":{\"129\":1,\"131\":1}}],[\"field\",{\"1\":{\"183\":1}}],[\"fit\",{\"1\":{\"14\":1}}],[\"from\",{\"1\":{\"266\":1}}],[\"frontmatter\",{\"1\":{\"48\":1,\"56\":3,\"83\":1,\"85\":1}}],[\"friedman\",{\"1\":{\"188\":1}}],[\"fri\",{\"1\":{\"75\":1}}],[\"fragment\",{\"1\":{\"19\":1,\"27\":1}}],[\"f11\",{\"1\":{\"38\":1}}],[\"f\",{\"1\":{\"38\":1}}],[\"bi\",{\"1\":{\"269\":1}}],[\"bilibili\",{\"1\":{\"176\":1}}],[\"by\",{\"1\":{\"266\":2}}],[\"bn\",{\"1\":{\"178\":1}}],[\"be\",{\"1\":{\"201\":1,\"264\":1}}],[\"berger\",{\"1\":{\"186\":1}}],[\"belief\",{\"1\":{\"178\":1,\"180\":1,\"188\":1}}],[\"begin\",{\"1\":{\"129\":2,\"131\":2,\"137\":4,\"270\":1}}],[\"banana\",{\"0\":{\"284\":1}}],[\"baz\",{\"0\":{\"276\":1},\"1\":{\"275\":1}}],[\"bar\",{\"0\":{\"273\":1},\"1\":{\"274\":1}}],[\"baidinghub\",{\"1\":{\"193\":1}}],[\"baiding\",{\"1\":{\"193\":1}}],[\"baum\",{\"1\":{\"182\":1}}],[\"bayes\",{\"1\":{\"181\":1}}],[\"bayesiannetwork\",{\"1\":{\"178\":1}}],[\"back\",{\"1\":{\"140\":5}}],[\"backgroundcolor\",{\"1\":{\"74\":1}}],[\"background\",{\"1\":{\"17\":1}}],[\"break\",{\"1\":{\"134\":1}}],[\"box\",{\"1\":{\"192\":2}}],[\"boltzmann\",{\"1\":{\"184\":1}}],[\"bool\",{\"1\":{\"134\":1,\"140\":1}}],[\"bottom\",{\"1\":{\"74\":1}}],[\"b1\",{\"1\":{\"77\":1}}],[\"b\",{\"1\":{\"34\":1}}],[\"b|c\",{\"1\":{\"34\":1}}],[\"black\",{\"1\":{\"192\":1}}],[\"blue\",{\"1\":{\"23\":2}}],[\"blog\",{\"1\":{\"193\":1}}],[\"bloghome\",{\"1\":{\"0\":1}}],[\"block\",{\"1\":{\"9\":1}}],[\"背景\",{\"0\":{\"17\":1}}],[\"使由初始条件\",{\"1\":{\"205\":1}}],[\"使当\",{\"1\":{\"205\":1}}],[\"使当任一\",{\"1\":{\"205\":1}}],[\"使得即使是相同的原始输入\",{\"1\":{\"265\":1}}],[\"使得只要当\",{\"1\":{\"209\":1}}],[\"使得\",{\"1\":{\"201\":1,\"205\":1,\"209\":1,\"210\":1,\"269\":1,\"270\":2}}],[\"使得当它加到输入样本\",{\"1\":{\"196\":1}}],[\"使得损失函数增加最快的方向\",{\"1\":{\"196\":1}}],[\"使相同的\",{\"1\":{\"31\":1}}],[\"使它们填充满幻灯片垂直方向上的剩余空间\",{\"1\":{\"15\":1}}],[\"使用其他的简单的方法也可以产生对抗样本\",{\"1\":{\"196\":1}}],[\"使用相同的配置\",{\"1\":{\"196\":1}}],[\"使用了\",{\"1\":{\"196\":1}}],[\"使用这种特定形式的扰动来生成对抗样本的原因\",{\"1\":{\"196\":1}}],[\"使用额外的空间\",{\"0\":{\"136\":1}}],[\"使用指南\",{\"1\":{\"83\":2},\"2\":{\"47\":1,\"49\":1,\"52\":1,\"80\":1,\"86\":1,\"87\":1,\"102\":1}}],[\"使用\",{\"1\":{\"5\":3,\"196\":2}}],[\"帮助你控制注入图片或视频的大小\",{\"1\":{\"15\":1}}],[\"spectral\",{\"1\":{\"281\":1}}],[\"space\",{\"1\":{\"264\":1}}],[\"s都表示不同的网络\",{\"1\":{\"266\":1}}],[\"schwarz\",{\"1\":{\"196\":1}}],[\"scalar\",{\"1\":{\"155\":1}}],[\"scales\",{\"1\":{\"74\":1}}],[\"scatter\",{\"1\":{\"74\":1}}],[\"stone\",{\"1\":{\"270\":1}}],[\"stacked\",{\"1\":{\"266\":1}}],[\"steganography\",{\"1\":{\"195\":1}}],[\"strike\",{\"1\":{\"23\":1}}],[\"stretch\",{\"1\":{\"15\":1}}],[\"sbn\",{\"1\":{\"180\":1}}],[\"since\",{\"1\":{\"266\":1}}],[\"similar\",{\"1\":{\"266\":1}}],[\"sign\",{\"1\":{\"196\":2}}],[\"sigmoid\",{\"1\":{\"180\":6}}],[\"sigmoid信念网络和logistic回归模型的比较\",{\"1\":{\"180\":1}}],[\"sigmoid信念网络\",{\"0\":{\"180\":1}}],[\"sidebar\",{\"1\":{\"177\":1}}],[\"size\",{\"1\":{\"129\":2,\"131\":2,\"134\":6,\"136\":3,\"137\":2}}],[\"softmax回归容易受到对抗性例子的影响\",{\"1\":{\"195\":1}}],[\"sortarraybyparityii\",{\"1\":{\"134\":1}}],[\"sort\",{\"1\":{\"129\":2,\"131\":2}}],[\"solution\",{\"1\":{\"129\":1,\"131\":1,\"134\":2,\"136\":1,\"137\":1,\"140\":1,\"266\":1}}],[\"s\",{\"1\":{\"129\":5,\"131\":5,\"193\":1,\"268\":1,\"269\":1}}],[\"sup范数\",{\"1\":{\"268\":1}}],[\"suppose\",{\"1\":{\"260\":1}}],[\"subgraph\",{\"1\":{\"77\":3}}],[\"sun\",{\"1\":{\"75\":1}}],[\"sec\",{\"1\":{\"270\":1}}],[\"sensitivity\",{\"1\":{\"256\":1}}],[\"series\",{\"1\":{\"75\":1}}],[\"semi\",{\"1\":{\"21\":1}}],[\"satisfy\",{\"1\":{\"266\":1}}],[\"sat\",{\"1\":{\"75\":1}}],[\"svg\",{\"1\":{\"69\":1}}],[\"shrink\",{\"1\":{\"23\":1}}],[\"slideend\",{\"1\":{\"41\":1}}],[\"slide\",{\"1\":{\"5\":1,\"29\":1}}],[\"slidestart\",{\"1\":{\"2\":1}}],[\"lstm\",{\"1\":{\"196\":1}}],[\"l\",{\"1\":{\"191\":1}}],[\"log\",{\"1\":{\"186\":1}}],[\"logistic\",{\"1\":{\"180\":6}}],[\"logo\",{\"1\":{\"15\":1,\"69\":2}}],[\"local\",{\"1\":{\"178\":1}}],[\"latent\",{\"1\":{\"264\":1}}],[\"label\",{\"1\":{\"74\":1}}],[\"layout\",{\"1\":{\"0\":1}}],[\"lifting\",{\"1\":{\"264\":1}}],[\"life\",{\"1\":{\"193\":1}}],[\"line\",{\"1\":{\"75\":1}}],[\"linear\",{\"1\":{\"74\":1,\"186\":1,\"260\":1}}],[\"link\",{\"1\":{\"69\":1}}],[\"linux\",{\"1\":{\"40\":1}}],[\"light\",{\"1\":{\"69\":1}}],[\"leads\",{\"1\":{\"266\":1}}],[\"learning\",{\"1\":{\"188\":1,\"198\":1}}],[\"lemma\",{\"1\":{\"260\":1}}],[\"leetcode\",{\"1\":{\"127\":1,\"134\":1,\"135\":1,\"141\":1,\"147\":1}}],[\"let\",{\"1\":{\"34\":3,\"200\":1}}],[\"left=min\",{\"1\":{\"140\":1}}],[\"left=newinterval\",{\"1\":{\"140\":1}}],[\"left\",{\"1\":{\"21\":1,\"140\":3}}],[\"certification\",{\"1\":{\"199\":1}}],[\"center\",{\"1\":{\"97\":1,\"165\":1}}],[\"cnn\",{\"1\":{\"260\":1}}],[\"cn\",{\"1\":{\"191\":1}}],[\"csbkpthtet4r\",{\"1\":{\"191\":1}}],[\"csc321\",{\"1\":{\"188\":1}}],[\"cs\",{\"1\":{\"188\":1}}],[\"clifford\",{\"1\":{\"184\":2}}],[\"clifford定理\",{\"1\":{\"184\":1}}],[\"clique\",{\"1\":{\"184\":2}}],[\"class\",{\"0\":{\"21\":1,\"23\":1},\"1\":{\"14\":1,\"15\":1,\"19\":1,\"129\":1,\"131\":1,\"134\":2,\"136\":1,\"137\":1,\"140\":1}}],[\"case\",{\"1\":{\"201\":1}}],[\"can\",{\"1\":{\"201\":1,\"266\":1}}],[\"cauchy\",{\"1\":{\"196\":1}}],[\"caution\",{\"1\":{\"93\":1,\"162\":1}}],[\"category\",{\"1\":{\"75\":1}}],[\"c2\",{\"1\":{\"77\":1}}],[\"c1\",{\"1\":{\"77\":2}}],[\"chart\",{\"1\":{\"74\":1}}],[\"courses\",{\"1\":{\"188\":1}}],[\"cout<<index<<endl\",{\"1\":{\"134\":1}}],[\"code\",{\"1\":{\"96\":1,\"164\":1}}],[\"color\",{\"1\":{\"69\":1}}],[\"completely\",{\"1\":{\"264\":1}}],[\"composed\",{\"1\":{\"260\":1}}],[\"com\",{\"1\":{\"69\":2,\"128\":1,\"176\":1,\"254\":1}}],[\"contrast\",{\"1\":{\"264\":1}}],[\"continue\",{\"1\":{\"140\":1}}],[\"consider\",{\"1\":{\"260\":1}}],[\"const\",{\"1\":{\"10\":1,\"60\":1,\"90\":2,\"140\":1,\"159\":2}}],[\"connectionist\",{\"1\":{\"188\":1}}],[\"conditional\",{\"1\":{\"178\":1}}],[\"cond\",{\"1\":{\"76\":2}}],[\"cond=>condition\",{\"1\":{\"76\":1}}],[\"concave\",{\"1\":{\"29\":1}}],[\"convex\",{\"1\":{\"29\":1}}],[\"ctrl\",{\"1\":{\"40\":1}}],[\"c\",{\"1\":{\"34\":2}}],[\"current\",{\"1\":{\"23\":3}}],[\"ray\",{\"0\":{\"280\":1},\"1\":{\"279\":1}}],[\"random\",{\"1\":{\"183\":1}}],[\"rnn等有所不同\",{\"1\":{\"256\":1}}],[\"runge\",{\"0\":{\"212\":1}}],[\"robustness\",{\"1\":{\"199\":1}}],[\"rotate\",{\"1\":{\"136\":1,\"137\":1}}],[\"ref\",{\"1\":{\"269\":2,\"270\":1}}],[\"recover\",{\"1\":{\"266\":1}}],[\"recalling\",{\"1\":{\"266\":1}}],[\"relation\",{\"1\":{\"266\":1}}],[\"relaxation\",{\"1\":{\"264\":1}}],[\"relu\",{\"1\":{\"196\":1,\"260\":2}}],[\"regarded\",{\"1\":{\"264\":1}}],[\"readings\",{\"1\":{\"188\":1}}],[\"resnet前向传播可以看做时欧拉法解神经微分方程\",{\"1\":{\"260\":1}}],[\"restrict\",{\"1\":{\"201\":1}}],[\"resistant\",{\"1\":{\"198\":1}}],[\"res\",{\"1\":{\"140\":7}}],[\"result++\",{\"1\":{\"129\":1}}],[\"result\",{\"1\":{\"129\":2,\"134\":4,\"266\":1}}],[\"reverse\",{\"1\":{\"137\":3}}],[\"return\",{\"1\":{\"129\":1,\"131\":1,\"134\":5,\"136\":1,\"137\":1,\"140\":1}}],[\"red\",{\"1\":{\"23\":2}}],[\"rgb\",{\"1\":{\"74\":1}}],[\"rgba\",{\"1\":{\"69\":1}}],[\"right=max\",{\"1\":{\"140\":1}}],[\"right=newinterval\",{\"1\":{\"140\":1}}],[\"right\",{\"1\":{\"21\":1,\"97\":1,\"140\":3,\"165\":1}}],[\"r\",{\"1\":{\"14\":1,\"15\":1}}],[\"👆\",{\"1\":{\"14\":1,\"15\":1}}],[\"👇\",{\"1\":{\"4\":1}}],[\"布局与功能禁用\",{\"0\":{\"48\":1}}],[\"布局\",{\"0\":{\"13\":1,\"14\":1,\"15\":1,\"16\":1}}],[\"⚠请注意\",{\"1\":{\"12\":1}}],[\"格式使用数学公式\",{\"1\":{\"11\":1}}],[\"t\",{\"1\":{\"268\":1,\"269\":1}}],[\"tongpei\",{\"1\":{\"269\":1}}],[\"towards\",{\"1\":{\"198\":1}}],[\"toronto\",{\"1\":{\"188\":2}}],[\"to\",{\"1\":{\"178\":2,\"198\":1,\"201\":1,\"266\":3}}],[\"toc\",{\"1\":{\"85\":1}}],[\"talyot法\",{\"0\":{\"211\":1}}],[\"taylor\",{\"1\":{\"210\":1}}],[\"target\",{\"1\":{\"192\":2}}],[\"tail\",{\"1\":{\"178\":1}}],[\"tail2tail\",{\"1\":{\"178\":1}}],[\"tab\",{\"1\":{\"96\":3,\"164\":3}}],[\"tabs\",{\"1\":{\"96\":1,\"164\":1}}],[\"techniques\",{\"1\":{\"188\":1}}],[\"temp=nums\",{\"1\":{\"136\":1}}],[\"text\",{\"1\":{\"14\":1}}],[\"tex\",{\"0\":{\"78\":1},\"1\":{\"11\":1}}],[\"tip\",{\"1\":{\"91\":1,\"160\":1}}],[\"title\",{\"1\":{\"69\":1,\"77\":1}}],[\"two\",{\"1\":{\"77\":4}}],[\"tb\",{\"1\":{\"77\":1}}],[\"this\",{\"1\":{\"201\":1}}],[\"three\",{\"1\":{\"77\":2}}],[\"thu\",{\"1\":{\"75\":1}}],[\"the\",{\"1\":{\"201\":1,\"260\":1,\"264\":4,\"266\":5}}],[\"theorems\",{\"1\":{\"266\":1}}],[\"theorem\",{\"1\":{\"201\":1,\"270\":1}}],[\"theme\",{\"1\":{\"96\":3,\"164\":3}}],[\"there\",{\"1\":{\"69\":2}}],[\"then\",{\"1\":{\"21\":2,\"264\":1}}],[\"tue\",{\"1\":{\"75\":1}}],[\"type\",{\"1\":{\"74\":2,\"75\":3}}],[\"transforms\",{\"1\":{\"260\":1}}],[\"transition\",{\"1\":{\"29\":3}}],[\"true\",{\"1\":{\"0\":1,\"134\":1}}],[\"=2\",{\"1\":{\"269\":1}}],[\"=temp\",{\"1\":{\"136\":1}}],[\"==arr\",{\"1\":{\"134\":1}}],[\"==\",{\"1\":{\"134\":1}}],[\"=>\",{\"1\":{\"34\":1}}],[\"=\",{\"1\":{\"10\":1,\"34\":3,\"60\":1,\"90\":2,\"129\":3,\"131\":2,\"134\":5,\"139\":10,\"159\":2,\"269\":1}}],[\"apple\",{\"0\":{\"283\":1}}],[\"augmented\",{\"1\":{\"264\":1}}],[\"auto\",{\"1\":{\"31\":1,\"140\":1}}],[\"assuming\",{\"1\":{\"266\":1}}],[\"as\",{\"1\":{\"264\":1}}],[\"arxiv\",{\"1\":{\"198\":1,\"256\":1,\"281\":2}}],[\"arr\",{\"1\":{\"134\":4}}],[\"adjoint\",{\"1\":{\"256\":1}}],[\"adversarial\",{\"1\":{\"198\":1}}],[\"add\",{\"1\":{\"96\":2,\"164\":2}}],[\"attacks\",{\"1\":{\"198\":1}}],[\"attack\",{\"1\":{\"192\":4}}],[\"attrs\",{\"0\":{\"64\":1}}],[\"an\",{\"1\":{\"264\":2}}],[\"and\",{\"1\":{\"188\":1,\"201\":2,\"260\":1,\"266\":1,\"281\":1}}],[\"animate\",{\"1\":{\"31\":1}}],[\"alessio\",{\"1\":{\"281\":1}}],[\"also\",{\"1\":{\"201\":1}}],[\"al\",{\"1\":{\"182\":1,\"186\":2}}],[\"alt\",{\"1\":{\"40\":1}}],[\"accelerating\",{\"1\":{\"281\":1}}],[\"accidental\",{\"1\":{\"195\":1}}],[\"activations\",{\"1\":{\"260\":1}}],[\"active\",{\"1\":{\"96\":1,\"164\":1}}],[\"acyclic\",{\"1\":{\"177\":1}}],[\"a>\",{\"1\":{\"99\":1}}],[\"a1\",{\"1\":{\"77\":1}}],[\"a\",{\"1\":{\"10\":1,\"34\":2,\"60\":1,\"90\":2,\"133\":1,\"134\":10,\"159\":2,\"260\":1,\"264\":2,\"266\":1}}],[\"3702\",{\"1\":{\"188\":1}}],[\"3\",{\"0\":{\"108\":1,\"113\":1,\"118\":1,\"123\":1,\"215\":1,\"220\":1,\"223\":1,\"225\":1,\"230\":1,\"235\":1,\"240\":1,\"243\":1,\"245\":1,\"250\":1},\"1\":{\"9\":1,\"34\":1,\"139\":6,\"196\":1,\"201\":1}}],[\"2019\",{\"1\":{\"281\":1}}],[\"2014\",{\"1\":{\"196\":1}}],[\"2016s\",{\"1\":{\"188\":1}}],[\"2009\",{\"1\":{\"188\":1}}],[\"20231211152930899\",{\"1\":{\"212\":1}}],[\"20231211152029421\",{\"1\":{\"212\":1}}],[\"20231211152044454\",{\"1\":{\"212\":1}}],[\"20231211151256664\",{\"1\":{\"211\":1}}],[\"20231216153149245\",{\"1\":{\"184\":1}}],[\"20231216152932251\",{\"1\":{\"183\":1}}],[\"20231216150648772\",{\"1\":{\"181\":1}}],[\"20231216143808424\",{\"1\":{\"178\":1}}],[\"20231216143312896\",{\"1\":{\"178\":1}}],[\"2020\",{\"1\":{\"83\":1}}],[\"260\",{\"1\":{\"75\":1}}],[\"218\",{\"1\":{\"75\":1}}],[\"224\",{\"1\":{\"75\":1}}],[\"255之间的信息\",{\"1\":{\"195\":1}}],[\"255\",{\"1\":{\"74\":1}}],[\"253\",{\"1\":{\"69\":1}}],[\"230\",{\"1\":{\"69\":1,\"75\":1}}],[\"2\",{\"0\":{\"107\":1,\"112\":1,\"117\":1,\"122\":1,\"214\":1,\"218\":1,\"219\":1,\"224\":1,\"229\":1,\"234\":1,\"238\":1,\"239\":1,\"244\":1,\"249\":1},\"1\":{\"9\":1,\"34\":2,\"51\":14,\"67\":1,\"134\":8,\"139\":6,\"177\":1,\"184\":1,\"201\":1,\"269\":1}}],[\"1806\",{\"1\":{\"256\":1}}],[\"18\",{\"1\":{\"209\":2}}],[\"189\",{\"1\":{\"135\":1,\"141\":1}}],[\"17\",{\"1\":{\"209\":1}}],[\"1706\",{\"1\":{\"198\":1}}],[\"1906\",{\"1\":{\"281\":1}}],[\"1997\",{\"1\":{\"186\":1}}],[\"1996\",{\"1\":{\"186\":1}}],[\"1966\",{\"1\":{\"182\":1}}],[\"19th\",{\"1\":{\"62\":1}}],[\"1给出了上述例子中\",{\"1\":{\"172\":1}}],[\"11\",{\"1\":{\"172\":1,\"211\":1}}],[\"16\",{\"1\":{\"139\":2}}],[\"12\",{\"1\":{\"139\":2,\"266\":1}}],[\"147\",{\"1\":{\"75\":1}}],[\"135\",{\"1\":{\"75\":1}}],[\"132\",{\"1\":{\"74\":1}}],[\"138\",{\"1\":{\"69\":1}}],[\"10数据集时\",{\"1\":{\"196\":1}}],[\"10\",{\"1\":{\"74\":3,\"130\":1,\"139\":3,\"172\":1,\"238\":1}}],[\"150\",{\"1\":{\"75\":1}}],[\"15\",{\"1\":{\"69\":1,\"196\":1}}],[\"1\",{\"0\":{\"213\":1,\"233\":1},\"1\":{\"9\":1,\"10\":1,\"34\":2,\"51\":12,\"60\":1,\"65\":1,\"67\":1,\"83\":2,\"90\":2,\"100\":1,\"129\":3,\"134\":8,\"139\":9,\"140\":3,\"159\":2,\"168\":1,\"180\":2,\"209\":3,\"256\":1,\"260\":1,\"264\":1,\"266\":2}}],[\"项目\",{\"1\":{\"9\":6}}],[\"列表默认为\",{\"1\":{\"9\":1}}],[\"删除线\",{\"1\":{\"8\":1}}],[\"斜体\",{\"1\":{\"8\":1}}],[\"粗体\",{\"1\":{\"8\":1}}],[\"标准化流normalizing\",{\"1\":{\"253\":1}}],[\"标准语法中的内容均不受支持\",{\"1\":{\"12\":1}}],[\"标量一般用斜体小写英文字母\",{\"1\":{\"155\":1}}],[\"标量\",{\"1\":{\"155\":1}}],[\"标题\",{\"0\":{\"107\":1,\"108\":1,\"112\":1,\"113\":1,\"117\":1,\"118\":1,\"122\":1,\"123\":1,\"214\":1,\"215\":1,\"219\":1,\"220\":1,\"224\":1,\"225\":1,\"229\":1,\"230\":1,\"234\":1,\"235\":1,\"239\":1,\"240\":1,\"244\":1,\"245\":1,\"249\":1,\"250\":1}}],[\"标题和页面信息\",{\"1\":{\"85\":1}}],[\"标题默认会自动转换为大写\",{\"1\":{\"8\":1}}],[\"标签为\",{\"1\":{\"83\":1}}],[\"标记\",{\"0\":{\"66\":1}}],[\"标注水平幻灯片\",{\"1\":{\"5\":1}}],[\"标注幻灯片\",{\"0\":{\"4\":1,\"5\":1}}],[\"你需要确保列表中的区间仍然有序且不重叠\",{\"1\":{\"139\":1}}],[\"你需要阅读\",{\"1\":{\"56\":1}}],[\"你需要在元素上添加\",{\"1\":{\"19\":1}}],[\"你应该创建和编写\",{\"1\":{\"54\":1}}],[\"你应该在页面前端设置\",{\"1\":{\"0\":1}}],[\"你可以返回任何满足上述条件的数组作为答案\",{\"1\":{\"134\":1}}],[\"你可以将图片和\",{\"1\":{\"84\":1}}],[\"你可以自由在这里书写你的\",{\"1\":{\"84\":1}}],[\"你可以标记\",{\"1\":{\"66\":1}}],[\"你可以通过主题选项和页面\",{\"1\":{\"85\":1}}],[\"你可以通过设置页面的\",{\"1\":{\"48\":1}}],[\"你可以通过向特定幻灯片添加\",{\"1\":{\"17\":1}}],[\"你可以对代码块进行高亮\",{\"1\":{\"34\":1}}],[\"你可以在\",{\"1\":{\"83\":1}}],[\"你可以在相邻的幻灯片上添加\",{\"1\":{\"31\":1}}],[\"你可以在幻灯片中使用\",{\"1\":{\"6\":1,\"7\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":1}}],[\"你可以使用它轻松生成文档或博客站点\",{\"1\":{\"54\":1}}],[\"你可以使用\",{\"1\":{\"27\":1,\"34\":1}}],[\"你可以按照顺序包裹一个\",{\"1\":{\"25\":1}}],[\"你也可以使用\",{\"1\":{\"11\":1}}],[\"mlp\",{\"1\":{\"256\":1}}],[\"method\",{\"1\":{\"196\":2}}],[\"mermaid\",{\"0\":{\"77\":1}}],[\"muyuuuu\",{\"1\":{\"193\":1}}],[\"mitpress\",{\"1\":{\"188\":1}}],[\"mister\",{\"1\":{\"69\":2}}],[\"m\",{\"1\":{\"188\":1}}],[\"ms\",{\"1\":{\"83\":1}}],[\"models\",{\"1\":{\"188\":1,\"198\":1}}],[\"model\",{\"1\":{\"172\":2,\"178\":1,\"182\":1,\"186\":2}}],[\"more\",{\"1\":{\"82\":1}}],[\"mon\",{\"1\":{\"75\":1}}],[\"md\",{\"1\":{\"59\":1,\"152\":4,\"170\":4,\"256\":5,\"263\":4}}],[\"masci\",{\"1\":{\"281\":1}}],[\"marco\",{\"1\":{\"281\":1}}],[\"markov\",{\"1\":{\"182\":1,\"183\":2,\"264\":1}}],[\"markdown\",{\"0\":{\"6\":1,\"7\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":1,\"54\":1,\"55\":1,\"56\":1,\"57\":1,\"88\":1},\"1\":{\"6\":1,\"7\":1,\"9\":1,\"10\":1,\"11\":1,\"12\":2,\"46\":1,\"54\":2,\"55\":3,\"56\":1,\"57\":3,\"58\":2,\"59\":1,\"60\":1,\"70\":1,\"83\":1,\"84\":2},\"2\":{\"81\":1,\"103\":1}}],[\"manifold\",{\"1\":{\"269\":1}}],[\"may\",{\"1\":{\"264\":1}}],[\"max\",{\"1\":{\"260\":1}}],[\"maxout网络都是被设计用线性的方式来运作的\",{\"1\":{\"196\":1}}],[\"maximum\",{\"1\":{\"186\":1}}],[\"maximal\",{\"1\":{\"184\":1}}],[\"math\",{\"1\":{\"11\":1}}],[\"mrf\",{\"1\":{\"183\":1}}],[\"mr\",{\"1\":{\"3\":1,\"69\":1,\"72\":1}}],[\"hypothesis\",{\"1\":{\"269\":1}}],[\"h\",{\"1\":{\"269\":1}}],[\"have\",{\"1\":{\"266\":1}}],[\"hammersley\",{\"1\":{\"184\":3}}],[\"hmm\",{\"1\":{\"182\":1}}],[\"higher\",{\"1\":{\"264\":1}}],[\"highlight\",{\"1\":{\"10\":1,\"23\":6,\"34\":1}}],[\"hidden\",{\"1\":{\"182\":1}}],[\"head\",{\"1\":{\"178\":1}}],[\"head2head\",{\"1\":{\"178\":1}}],[\"head2tail\",{\"1\":{\"178\":1}}],[\"heading\",{\"1\":{\"177\":1}}],[\"headerdepth\",{\"1\":{\"177\":1}}],[\"href=\",{\"1\":{\"99\":1}}],[\"https\",{\"1\":{\"69\":2,\"188\":1,\"191\":1}}],[\"html\",{\"1\":{\"5\":1,\"25\":1,\"31\":1}}],[\"h2o\",{\"1\":{\"62\":1}}],[\"h3\",{\"0\":{\"8\":1}}],[\"however\",{\"1\":{\"201\":1}}],[\"hope\",{\"1\":{\"3\":1,\"69\":4,\"72\":1,\"83\":1,\"96\":3,\"164\":3}}],[\"home\",{\"1\":{\"0\":1}}],[\"在优化算法上有丰富的理论来源\",{\"1\":{\"272\":1}}],[\"在优化理论中\",{\"1\":{\"265\":1}}],[\"在$\",{\"1\":{\"270\":1}}],[\"在定理中虽然对的要求降低了\",{\"1\":{\"270\":1}}],[\"在意义上逼近\",{\"1\":{\"270\":1}}],[\"在增加维度的neuralode后添加一个线性层\",{\"1\":{\"270\":1}}],[\"在高维空间中\",{\"1\":{\"269\":1}}],[\"在这个更加广义的集合中\",{\"1\":{\"268\":1}}],[\"在这个公式中\",{\"1\":{\"196\":1}}],[\"在统计学习理论中\",{\"1\":{\"265\":1}}],[\"在数学上\",{\"1\":{\"265\":1}}],[\"在数学上阐述为什么使用随机噪声初始化增广维度比使用零初始化更有利的原因可以从以下几个角度来考虑\",{\"1\":{\"265\":1}}],[\"在后续会深入讨论网络架构的选择和设计\",{\"1\":{\"260\":1}}],[\"在常规神经网络中\",{\"1\":{\"260\":1}}],[\"在上关于\",{\"1\":{\"260\":1}}],[\"在2018年首次被提出和使用\",{\"1\":{\"256\":1}}],[\"在第\",{\"1\":{\"211\":1}}],[\"在下面各节所考虑的更精确方法的误差分析按照同样的模式\",{\"1\":{\"210\":1}}],[\"在下图所示的无向图中共有\",{\"1\":{\"184\":1}}],[\"在典型的计算机中\",{\"1\":{\"209\":1}}],[\"在以\",{\"1\":{\"206\":1}}],[\"在平面上的示意图如下图\",{\"1\":{\"205\":1}}],[\"在二维情形零解的稳定形态\",{\"1\":{\"205\":1}}],[\"在minst测试集上\",{\"1\":{\"196\":1}}],[\"在对抗性攻击的背景下\",{\"1\":{\"196\":1}}],[\"在黑箱攻击中\",{\"1\":{\"192\":1}}],[\"在白箱攻击中攻击者知道目标模型的所有信息\",{\"1\":{\"192\":1}}],[\"在所有团中\",{\"1\":{\"184\":1}}],[\"在朴素贝叶斯分类器中\",{\"1\":{\"181\":1}}],[\"在强\",{\"1\":{\"181\":1}}],[\"在给定它的邻居的情况下独立于所有其他变量\",{\"1\":{\"183\":1}}],[\"在给定\",{\"1\":{\"178\":1}}],[\"在\",{\"1\":{\"178\":3,\"196\":1,\"263\":1}}],[\"在概率图模型中\",{\"1\":{\"177\":1}}],[\"在机器学习中\",{\"1\":{\"174\":1,\"196\":1}}],[\"在本章中\",{\"1\":{\"173\":1}}],[\"在已知部分变量时\",{\"1\":{\"173\":1}}],[\"在已知\",{\"1\":{\"172\":1}}],[\"在不知道这几个变量依赖关系的情况下\",{\"1\":{\"172\":1}}],[\"在不作任何独立假设条件下\",{\"1\":{\"172\":1}}],[\"在列表中插入一个新的区间\",{\"1\":{\"139\":1}}],[\"在遍历胃口呢\",{\"1\":{\"130\":1}}],[\"在遍历的饼干\",{\"1\":{\"130\":1}}],[\"在页面禁用功能与布局\",{\"1\":{\"48\":1}}],[\"在你启用\",{\"1\":{\"10\":1,\"11\":1}}],[\"在前一个\",{\"1\":{\"5\":1}}],[\"在幻灯片上添加属性\",{\"1\":{\"5\":1}}],[\"在水平幻灯片中使用\",{\"1\":{\"5\":1}}],[\">right\",{\"1\":{\"140\":1}}],[\">arr\",{\"1\":{\"134\":1}}],[\">a2\",{\"1\":{\"77\":2}}],[\">=arr\",{\"1\":{\"134\":1}}],[\">=\",{\"1\":{\"129\":3,\"130\":1}}],[\">跳转单词<\",{\"1\":{\"99\":1}}],[\">c2\",{\"1\":{\"77\":1}}],[\">b2\",{\"1\":{\"77\":1}}],[\">e\",{\"1\":{\"76\":2}}],[\">process\",{\"1\":{\"76\":1}}],[\">\",{\"1\":{\"5\":2,\"25\":2,\"77\":3}}],[\"<left\",{\"1\":{\"140\":1}}],[\"<=1\",{\"1\":{\"137\":1}}],[\"<=\",{\"1\":{\"131\":1}}],[\"<arrp\",{\"1\":{\"134\":1}}],[\"<a\",{\"1\":{\"99\":1}}],[\"<\",{\"1\":{\"5\":2,\"131\":2,\"134\":1}}],[\"幻灯片演示\",{\"0\":{\"3\":1}}],[\"幻灯片页\",{\"0\":{\"2\":1}}],[\"和是直接设为0相比\",{\"1\":{\"265\":1}}],[\"和任何正整数\",{\"1\":{\"210\":1}}],[\"和类别\",{\"1\":{\"181\":1}}],[\"和它的父节点集合\",{\"1\":{\"180\":1}}],[\"和一个有\",{\"1\":{\"178\":1,\"183\":1}}],[\"和动画\",{\"1\":{\"19\":1}}],[\"和\",{\"1\":{\"0\":1,\"55\":1,\"83\":1,\"172\":3,\"178\":3,\"182\":2,\"183\":2,\"205\":1,\"210\":2,\"269\":1}}],[\"博客主页\",{\"0\":{\"0\":1},\"1\":{\"0\":1}}]],\"serializationVersion\":2}}")).map(([e,t])=>[e,zt(t,{fields:["h","t","c"],storeFields:["h","t","c"]})]));self.onmessage=({data:{type:e="all",query:t,locale:s,options:n}})=>{e==="suggest"?self.postMessage(st(t,v[s],n)):e==="search"?self.postMessage(et(t,v[s],n)):self.postMessage({suggestions:st(t,v[s],n),results:et(t,v[s],n)})};
//# sourceMappingURL=index.js.map
