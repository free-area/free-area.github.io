---
dir.order: 100
---







# 网络设计

## 增维的的NODE

再 [表示和逼近.md](表示和逼近.md) 中提到过对输入进行维度增加可以提高模型的表达能力，再 [表示和逼近.md](表示和逼近.md)  中采用的方法非常简单：将输入的维度增加一倍 $x\in  R^d \rightarrow  y \in R^{2d}$，然后在额外的维度上补0， 这个理论上可以表示任何同胚映射，但是它也有很大的缺陷，在 [表示和逼近.md](表示和逼近.md) 中已经表述过。下面子节是其他的用于增维的方法来解决 [表示和逼近.md](表示和逼近.md) 中描述的缺陷。

### 对输入做仿射变换

对于给定的初值 $x\in R^d$ ,   设$l_\theta:R^d\rightarrow R^l$ 是一个含参的仿射变换，那么将 $x_{aug}=l_\theta(x)$作为微分方程的初值，然后的到 $\varphi(y ,T)$作为NODE的输出，其中参数是需要学习的。
$$
h(0)=l_\theta(x), \quad \frac{d h}{dt}(t)=f_\theta(t, h(t)) .
$$
采用仿射的目的是 提高模型的表达能力的同时，做到高效的训练，不需要增加一倍的维度，更具体点可以设 $x_{aug}=(x,l_\theta(x))$,这就更进一步降低参数量了,同时也保证了前 $n$ 维的结构。当然这种增强破坏了NODE的双射的性质，那么下一章节的连续归一化流就不能使用，因为它要求可逆。



Lifting into a higher-dimensional space may be regarded as a relaxation of the Markov property[^1]. For $s<t$ then the output $\ell_\theta(y(s))$ does not completely determine $\ell_\theta(y(t))$. In contrast $y(s)$ does determine $y(t)$. (Whether $y$ is the output of an unaugmented neural $O D E$ or the latent value of an augmented neural ODE.)









[^1]: Neural综述

